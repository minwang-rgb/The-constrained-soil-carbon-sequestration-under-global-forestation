{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca2311f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost modeling: active fractions and soil organic carbon in topsoil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import builtins\n",
    "from scipy import stats\n",
    "open = builtins.open\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# SHAP availability check\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SHAP_AVAILABLE = False\n",
    "\n",
    "class XGBoostTuner:\n",
    "    def __init__(self, seed=42, n_jobs=-1):\n",
    "        self.seed = seed\n",
    "        self.n_jobs = n_jobs if n_jobs != -1 else None\n",
    "        self.study = None\n",
    "        self.best_model = None\n",
    "        self.best_params = None\n",
    "        self.feature_names = None  # Store feature names\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_numeric_value(value):\n",
    "        \"\"\"Convert string values to numeric, handling special cases\"\"\"\n",
    "        if pd.isna(value):\n",
    "            return np.nan\n",
    "        if isinstance(value, str):\n",
    "            # Remove any non-numeric characters except minus, decimal point\n",
    "            cleaned = re.sub(r'[^\\d.-]', '', value)\n",
    "            try:\n",
    "                return float(cleaned) if cleaned else np.nan\n",
    "            except ValueError:\n",
    "                return np.nan\n",
    "        return float(value)\n",
    "\n",
    "    def objective(self, trial, dtrain, num_boost_round=500):\n",
    "        \"\"\"Objective function with enhanced regularization\"\"\"\n",
    "        params = {\n",
    "            'eta': trial.suggest_float('eta', 0.005, 0.1, log=True),  # Lower learning rate\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 4),  # Shallower trees\n",
    "            'subsample': trial.suggest_float('subsample', 0.4, 0.7),  # Lower subsampling\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 0.7),  # Lower feature sampling\n",
    "            'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.4, 0.7),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 10, 20),  # Higher min child weight\n",
    "            'lambda': trial.suggest_float('lambda', 10, 25.0),  # Stronger L2 regularization\n",
    "            'alpha': trial.suggest_float('alpha', 5.0, 15.0),  # Stronger L1 regularization\n",
    "            'gamma': trial.suggest_float('gamma', 0.5, 2.0),  # Higher pruning parameter\n",
    "            'max_delta_step': trial.suggest_int('max_delta_step', 0, 1),\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'verbosity': 0,\n",
    "            'seed': self.seed,\n",
    "            'nthread': 1\n",
    "        }\n",
    "\n",
    "        cv_results = xgb.cv(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=800,  # More rounds but more conservative early stopping\n",
    "            nfold=5,\n",
    "            metrics='rmse',\n",
    "            early_stopping_rounds=25,  # More conservative early stopping\n",
    "            as_pandas=True,\n",
    "            seed=self.seed,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        # Stronger overfitting penalty\n",
    "        train_rmse = cv_results['train-rmse-mean'].iloc[-1]\n",
    "        val_rmse = cv_results['test-rmse-mean'].iloc[-1]\n",
    "        \n",
    "        # Calculate overfitting degree\n",
    "        overfitting_ratio = (train_rmse - val_rmse) / train_rmse\n",
    "        gap_penalty = max(0, overfitting_ratio) * 0.3  # Stronger penalty\n",
    "        \n",
    "        # Add extra penalty if severe overfitting\n",
    "        if overfitting_ratio > 0.1:\n",
    "            gap_penalty += (overfitting_ratio - 0.1) * 0.5\n",
    "            \n",
    "        return val_rmse + gap_penalty\n",
    "    \n",
    "    def tune_hyperparameters(self, dtrain, n_trials=20):  # Increased number of trials\n",
    "        \"\"\"Hyperparameter tuning focused on generalization\"\"\"\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        \n",
    "        print(\"Tuning hyperparameters with aggressive overfitting prevention...\")\n",
    "        print(\"Using very strong regularization and shallow trees\")\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=self.n_jobs) as executor:\n",
    "            futures = [executor.submit(lambda: study.optimize(\n",
    "                lambda trial: self.objective(trial, dtrain),\n",
    "                n_trials=5,\n",
    "                n_jobs=1\n",
    "            )) for _ in range(n_trials//5)]\n",
    "\n",
    "            for future in futures:\n",
    "                future.result()\n",
    "\n",
    "        self.study = study\n",
    "        self.best_params = study.best_params\n",
    "        self.best_params.update({\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'seed': self.seed,\n",
    "            'nthread': self.n_jobs\n",
    "        })\n",
    "\n",
    "        print(f\"Best parameters found: {self.best_params}\")\n",
    "        return self.best_params\n",
    "\n",
    "\n",
    "    def train_model(self, params, dtrain, dvalid=None, num_boost_round=500):\n",
    "        \"\"\"Train model with focus on preventing overfitting\"\"\"\n",
    "        evals = [(dtrain, 'train')]\n",
    "        if dvalid is not None:\n",
    "            evals.append((dvalid, 'valid'))\n",
    "\n",
    "        evals_result = {}\n",
    "        model = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            evals=evals,\n",
    "            early_stopping_rounds=25,  # More conservative early stopping\n",
    "            verbose_eval=100,  # Reduced output frequency\n",
    "            evals_result=evals_result\n",
    "        )\n",
    "\n",
    "        self.feature_names = dtrain.feature_names\n",
    "        if self.feature_names is None:\n",
    "            self.feature_names = [f'f{i}' for i in range(dtrain.num_col())]\n",
    "            model.feature_names = self.feature_names\n",
    "\n",
    "        return model, evals_result\n",
    "\n",
    "    def cross_validate(self, params, X, y, n_splits=5, cv_models_dir='cv_models', n_repeats=10): \n",
    "        \"\"\"Enhanced CV with 10 repetitions of 5-fold cross-validation and model saving\"\"\"\n",
    "        Path(cv_models_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        all_cv_results = {\n",
    "            'train_rmse': [], 'val_rmse': [],\n",
    "            'train_r2': [], 'val_r2': [],\n",
    "            'best_iterations': [],\n",
    "            'model_paths': [],\n",
    "            'feature_names': [],\n",
    "            'repeat': [],\n",
    "            'fold': []\n",
    "        }\n",
    "\n",
    "        def process_fold(repeat_idx, fold_idx, train_idx, val_idx):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=X_train.columns.tolist())\n",
    "            dval = xgb.DMatrix(X_val, label=y_val, feature_names=X_train.columns.tolist())\n",
    "\n",
    "            model, _ = self.train_model(params, dtrain, dval)\n",
    "\n",
    "            # Save the CV model\n",
    "            model_path = os.path.join(cv_models_dir, f'cv_model_repeat_{repeat_idx}_fold_{fold_idx}.json')\n",
    "            model.save_model(model_path)\n",
    "\n",
    "            train_pred = model.predict(dtrain)\n",
    "            val_pred = model.predict(dval)\n",
    "\n",
    "            return (\n",
    "                np.sqrt(mean_squared_error(y_train, train_pred)),\n",
    "                np.sqrt(mean_squared_error(y_val, val_pred)),\n",
    "                r2_score(y_train, train_pred),\n",
    "                r2_score(y_val, val_pred),\n",
    "                model.best_iteration if hasattr(model, 'best_iteration') else params.get('num_boost_round', 500),\n",
    "                model_path,\n",
    "                model.feature_names,\n",
    "                repeat_idx,\n",
    "                fold_idx\n",
    "            )\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=self.n_jobs) as executor:\n",
    "            futures = []\n",
    "            for repeat_idx in range(n_repeats):\n",
    "                kf = KFold(n_splits=n_splits, shuffle=True, random_state=self.seed + repeat_idx)\n",
    "                for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "                    futures.append(executor.submit(\n",
    "                        process_fold, repeat_idx, fold_idx, train_idx, val_idx\n",
    "                    ))\n",
    "\n",
    "            for future in futures:\n",
    "                train_rmse, val_rmse, train_r2, val_r2, best_iter, model_path, feature_names, repeat_idx, fold_idx = future.result()\n",
    "                all_cv_results['train_rmse'].append(train_rmse)\n",
    "                all_cv_results['val_rmse'].append(val_rmse)\n",
    "                all_cv_results['train_r2'].append(train_r2)\n",
    "                all_cv_results['val_r2'].append(val_r2)\n",
    "                all_cv_results['best_iterations'].append(best_iter)\n",
    "                all_cv_results['model_paths'].append(model_path)\n",
    "                all_cv_results['feature_names'].append(feature_names)\n",
    "                all_cv_results['repeat'].append(repeat_idx)\n",
    "                all_cv_results['fold'].append(fold_idx)\n",
    "        # Create summary statistics\n",
    "        cv_results_summary = {\n",
    "            'train_rmse_mean': np.mean(all_cv_results['train_rmse']),\n",
    "            'train_rmse_std': np.std(all_cv_results['train_rmse']),\n",
    "            'val_rmse_mean': np.mean(all_cv_results['val_rmse']),\n",
    "            'val_rmse_std': np.std(all_cv_results['val_rmse']),\n",
    "            'train_r2_mean': np.mean(all_cv_results['train_r2']),\n",
    "            'train_r2_std': np.std(all_cv_results['train_r2']),\n",
    "            'val_r2_mean': np.mean(all_cv_results['val_r2']),\n",
    "            'val_r2_std': np.std(all_cv_results['val_r2']),\n",
    "            'best_iterations_mean': np.mean(all_cv_results['best_iterations']),\n",
    "            'best_iterations_std': np.std(all_cv_results['best_iterations']),\n",
    "            'detailed_results': pd.DataFrame(all_cv_results)\n",
    "        }\n",
    "\n",
    "        return cv_results_summary\n",
    "\n",
    "    def evaluate_model(self, model, dtest):\n",
    "        \"\"\"Evaluate model performance on test set\"\"\"\n",
    "        test_pred = model.predict(dtest)\n",
    "        return {\n",
    "            'rmse': np.sqrt(mean_squared_error(dtest.get_label(), test_pred)),\n",
    "            'r2': r2_score(dtest.get_label(), test_pred),\n",
    "            'mae': mean_absolute_error(dtest.get_label(), test_pred)\n",
    "        }, test_pred\n",
    "\n",
    "    def plot_learning_curves(self, evals_result, title_suffix):\n",
    "        \"\"\"Plot training and validation metrics\"\"\"\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        epochs = len(evals_result['train']['rmse'])\n",
    "        plt.plot(range(epochs), evals_result['train']['rmse'], label='Train RMSE')\n",
    "        if 'valid' in evals_result:\n",
    "            plt.plot(range(epochs), evals_result['valid']['rmse'], label='Validation RMSE')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.title(f'Learning Curves - {title_suffix}')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_cv_results(self, cv_results_summary):\n",
    "        \"\"\"Plot enhanced cross-validation results with both original and new visualization\"\"\"\n",
    "        # Check if it's the new summary format or old list format\n",
    "        if isinstance(cv_results_summary, dict) and 'detailed_results' in cv_results_summary:\n",
    "            # New format - use the detailed results\n",
    "            detailed_results = cv_results_summary['detailed_results']\n",
    "            \n",
    "            # Create two visualizations:\n",
    "            # 1. Original visualization (simple line plot for first repeat)\n",
    "            plt.figure(figsize=(20, 10))\n",
    "            \n",
    "            # Plot 1: Original style - first repeat only\n",
    "            plt.subplot(2, 2, 1)\n",
    "            first_repeat = detailed_results[detailed_results['repeat'] == 0]\n",
    "            plt.plot(first_repeat['train_rmse'], 'o-', label='Train RMSE')\n",
    "            plt.plot(first_repeat['val_rmse'], 'o-', label='Validation RMSE')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.title('Cross-Validation RMSE (First Repeat)')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Plot 2: Original style - first repeat R²\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.plot(first_repeat['train_r2'], 'o-', label='Train R²')\n",
    "            plt.plot(first_repeat['val_r2'], 'o-', label='Validation R²')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('R² Score')\n",
    "            plt.title('Cross-Validation R² Scores (First Repeat)')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Plot 3: New visualization - RMSE distribution across all repeats\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.boxplot([detailed_results['train_rmse'], detailed_results['val_rmse']], \n",
    "                       labels=['Train RMSE', 'Validation RMSE'])\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.title('RMSE Distribution across 10x5 CV')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Plot 4: New visualization - R² distribution across all repeats\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.boxplot([detailed_results['train_r2'], detailed_results['val_r2']], \n",
    "                       labels=['Train R²', 'Validation R²'])\n",
    "            plt.ylabel('R² Score')\n",
    "            plt.title('R² Distribution across 10x5 CV')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Print summary statistics\n",
    "            print(\"\\n=== 10x5 Cross-Validation Summary ===\")\n",
    "            print(f\"Average Train RMSE: {cv_results_summary['train_rmse_mean']:.4f} (±{cv_results_summary['train_rmse_std']:.4f})\")\n",
    "            print(f\"Average Validation RMSE: {cv_results_summary['val_rmse_mean']:.4f} (±{cv_results_summary['val_rmse_std']:.4f})\")\n",
    "            print(f\"Average Train R²: {cv_results_summary['train_r2_mean']:.4f} (±{cv_results_summary['train_r2_std']:.4f})\")\n",
    "            print(f\"Average Validation R²: {cv_results_summary['val_r2_mean']:.4f} (±{cv_results_summary['val_r2_std']:.4f})\")\n",
    "            print(f\"Average Best Iterations: {cv_results_summary['best_iterations_mean']:.1f} (±{cv_results_summary['best_iterations_std']:.1f})\")\n",
    "            \n",
    "            # Also print the format that main() expects\n",
    "            print(\"\\n=== 交叉验证结果 (旧格式兼容) ===\")\n",
    "            print(f\"平均训练RMSE: {cv_results_summary['train_rmse_mean']:.4f} (±{cv_results_summary['train_rmse_std']:.4f})\")\n",
    "            print(f\"平均验证RMSE: {cv_results_summary['val_rmse_mean']:.4f} (±{cv_results_summary['val_rmse_std']:.4f})\")\n",
    "            print(f\"平均训练R²: {cv_results_summary['train_r2_mean']:.4f} (±{cv_results_summary['train_r2_std']:.4f})\")\n",
    "            print(f\"平均验证R²: {cv_results_summary['val_r2_mean']:.4f} (±{cv_results_summary['val_r2_std']:.4f})\")\n",
    "            \n",
    "        else:\n",
    "            # Old format - keep original plotting\n",
    "            plt.figure(figsize=(15, 5))\n",
    "\n",
    "            # Plot RMSE\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(cv_results_summary['train_rmse'], 'o-', label='Train RMSE')\n",
    "            plt.plot(cv_results_summary['val_rmse'], 'o-', label='Validation RMSE')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.title('Cross-Validation RMSE')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Plot R2\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(cv_results_summary['train_r2'], 'o-', label='Train R²')\n",
    "            plt.plot(cv_results_summary['val_r2'], 'o-', label='Validation R²')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('R² Score')\n",
    "            plt.title('Cross-Validation R² Scores')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def plot_final_model_performance(self, model, dtest):\n",
    "        \"\"\"Plot actual vs predicted values for test set\"\"\"\n",
    "        test_metrics, test_pred = self.evaluate_model(model, dtest)\n",
    "        y_test = dtest.get_label()\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        # Scatter plot of actual vs predicted\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(y_test, test_pred, alpha=0.5)\n",
    "        plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--r')\n",
    "        plt.xlabel('Actual Values')\n",
    "        plt.ylabel('Predicted Values')\n",
    "        plt.title(f'Actual vs Predicted (R² = {test_metrics[\"r2\"]:.3f})')\n",
    "\n",
    "        # Residual plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        residuals = y_test - test_pred\n",
    "        plt.scatter(test_pred, residuals, alpha=0.5)\n",
    "        plt.axhline(y=0, color='r', linestyle='--')\n",
    "        plt.xlabel('Predicted Values')\n",
    "        plt.ylabel('Residuals')\n",
    "        plt.title('Residual Plot')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_feature_importance(self, model, importance_type='weight', top_n=30):\n",
    "        \"\"\"Plot feature importance without category-specific highlighting\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "      \n",
    "        importance_dict = model.get_score(importance_type=importance_type)\n",
    "        \n",
    "        if not importance_dict:\n",
    "            print(\"No feature importance data available.\")\n",
    "            return None\n",
    "            \n",
    "   \n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': list(importance_dict.keys()),\n",
    "            'importance': list(importance_dict.values())\n",
    "        }).sort_values('importance', ascending=True)\n",
    "        \n",
    "  \n",
    "        if len(importance_df) > top_n:\n",
    "            importance_df = importance_df.tail(top_n)\n",
    "        \n",
    "    \n",
    "        y_pos = np.arange(len(importance_df))\n",
    "        colors = ['lightblue'] * len(importance_df)\n",
    "        \n",
    "        ax.barh(y_pos, importance_df['importance'], color=colors, alpha=0.8)\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(importance_df['feature'])\n",
    "        ax.set_xlabel('Importance')\n",
    "        \n",
    "        title = f'Feature Importance ({importance_type})'\n",
    "        ax.set_title(title)\n",
    "        \n",
    "\n",
    "        lu_type_features = importance_df[importance_df['feature'].str.contains('LUtype', na=False)]\n",
    "        lu_type_importance = lu_type_features['importance'].sum() if not lu_type_features.empty else 0\n",
    "        \n",
    "        ax.text(0.7, 0.95, f'LUtype total: {lu_type_importance:.3f}', \n",
    "                transform=ax.transAxes, fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\"))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return importance_df\n",
    "\n",
    "    def analyze_lutype_importance(self, model, X):\n",
    "        \"\"\"分析LUtype相关特征的重要性，不关注特定类别\"\"\"\n",
    "        importance_dict = model.get_score(importance_type='weight')\n",
    "        \n",
    "        if not importance_dict:\n",
    "            print(\"No feature importance data available.\")\n",
    "            return\n",
    "            \n",
    " \n",
    "        lutype_features = {k: v for k, v in importance_dict.items() if 'LUtype' in k}\n",
    "        other_features = {k: v for k, v in importance_dict.items() if 'LUtype' not in k}\n",
    "        \n",
    "        print(f\"\\n=== LUtype Feature Importance Analysis ===\")\n",
    "        print(f\"Total LUtype-related features: {len(lutype_features)}\")\n",
    "        print(f\"Total importance of LUtype features: {sum(lutype_features.values()):.3f}\")\n",
    "        print(f\"Average importance of LUtype features: {np.mean(list(lutype_features.values())) if lutype_features else 0:.3f}\")\n",
    "        \n",
    "        total_importance = sum(importance_dict.values())\n",
    "        lu_type_percentage = (sum(lutype_features.values()) / total_importance * 100) if total_importance > 0 else 0\n",
    "        \n",
    "        print(f\"\\nLUtype importance percentage: {lu_type_percentage:.2f}%\")\n",
    "        \n",
    "\n",
    "        if lutype_features:\n",
    "            sorted_lutype = sorted(lutype_features.items(), key=lambda x: x[1], reverse=True)\n",
    "            print(f\"\\nTop LUtype-related features:\")\n",
    "            for feature, importance in sorted_lutype[:10]:\n",
    "                print(f\"  {feature}: {importance:.4f}\")\n",
    "        else:\n",
    "            print(\"\\nNo LUtype-related features found in importance scores.\")\n",
    "\n",
    "    def plot_shap_summary(self, model, X, feature_names=None):\n",
    "        \"\"\"Generate SHAP summary plot if SHAP is available\"\"\"\n",
    "        if SHAP_AVAILABLE:\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(X)\n",
    "\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            shap.summary_plot(shap_values, X, feature_names=feature_names)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"SHAP not available. Install with: pip install shap\")\n",
    "\n",
    "    def save_results(self, model, output_dir='results'):\n",
    "        \"\"\"Save all results to disk including feature names\"\"\"\n",
    "        Path(output_dir).mkdir(exist_ok=True)\n",
    "\n",
    "        # Save model\n",
    "        model.save_model(f'{output_dir}/xgb_model.json')\n",
    "\n",
    "        # Save feature names\n",
    "        if self.feature_names is not None:\n",
    "            with open(f'{output_dir}/feature_names.txt', 'w') as f:\n",
    "                f.write('\\n'.join(self.feature_names))\n",
    "\n",
    "        # Save other artifacts\n",
    "        joblib.dump(self.best_params, f'{output_dir}/best_params.pkl')\n",
    "\n",
    "        if self.study:\n",
    "            joblib.dump(self.study, f'{output_dir}/study.pkl')\n",
    "            study_df = self.study.trials_dataframe()\n",
    "            study_df.to_csv(f'{output_dir}/trials.csv', index=False)\n",
    "\n",
    "def detect_outliers_iqr(df, columns, threshold=1.5):\n",
    "    \"\"\"Detect outliers using IQR method\"\"\"\n",
    "    outlier_indices = []\n",
    "    \n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - threshold * IQR\n",
    "            upper_bound = Q3 + threshold * IQR\n",
    "            \n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index\n",
    "            outlier_indices.extend(outliers)\n",
    "            \n",
    "            if len(outliers) > 0:\n",
    "                print(f\"  {col}: Found {len(outliers)} outliers \"\n",
    "                      f\"({len(outliers)/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    return list(set(outlier_indices))\n",
    "\n",
    "def remove_outliers_robust(df, y, columns, method='iqr', threshold=2.0):\n",
    "    \"\"\"Robust outlier handling method\"\"\"\n",
    "    print(\"Starting outlier detection...\")\n",
    "    \n",
    "    if method == 'iqr':\n",
    "        outlier_indices = detect_outliers_iqr(df, columns, threshold)\n",
    "    elif method == 'zscore':\n",
    "        # Z-score method\n",
    "        z_scores = np.abs(stats.zscore(df[columns]))\n",
    "        outlier_indices = np.where(z_scores > threshold)[0]\n",
    "        outlier_indices = list(outlier_indices)\n",
    "    else:\n",
    "        return df, y, []\n",
    "    \n",
    "    print(f\"\\nTotal outliers found: {len(outlier_indices)}\")\n",
    "    \n",
    "    if len(outlier_indices) > 0:\n",
    "        df_clean = df.drop(outlier_indices)\n",
    "        y_clean = y.drop(outlier_indices)\n",
    "        print(f\"Data size after removing outliers: {len(df_clean)} (removed {len(outlier_indices)} samples)\")\n",
    "        return df_clean, y_clean, outlier_indices\n",
    "    \n",
    "    print(\"No outliers found\")\n",
    "    return df, y, []\n",
    "\n",
    "def check_data_leakage(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Check for data leakage\"\"\"\n",
    "    print(\"\\n=== Data Leakage Check ===\")\n",
    "    \n",
    "    # Check for overlap between train and test sets\n",
    "    train_indices = set(X_train.index)\n",
    "    test_indices = set(X_test.index)\n",
    "    overlap = train_indices.intersection(test_indices)\n",
    "    \n",
    "    if overlap:\n",
    "        print(f\"❌ Data leakage detected: {len(overlap)} overlapping samples between train and test sets\")\n",
    "    else:\n",
    "        print(\"✅ No overlap between train and test sets\")\n",
    "    \n",
    "    # Check feature distributions\n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Test set size: {len(X_test)}\")\n",
    "    print(f\"Number of features: {X_train.shape[1]}\")\n",
    "    \n",
    "    return len(overlap) == 0\n",
    "\n",
    "def safe_feature_engineering(X_train, X_test):\n",
    "    \"\"\"Safe feature engineering to avoid data leakage\"\"\"\n",
    "    print(\"Performing safe feature engineering...\")\n",
    "    \n",
    "    # 1. Logarithmic transformation\n",
    "    columns_to_log = ['Lon', 'Lat', 'Age', 'BD', 'pH']\n",
    "    for col in columns_to_log:\n",
    "        if col in X_train.columns:\n",
    "            X_train[col + '_log'] = np.log(X_train[col] + 1e-8)\n",
    "            X_test[col + '_log'] = np.log(X_test[col] + 1e-8)\n",
    "            print(f\"  Created log feature: {col}_log\")\n",
    "    \n",
    "    # 2. Binning (based on training set quantiles)\n",
    "    if 'Altitude' in X_train.columns:\n",
    "        # Use training set to compute bin boundaries\n",
    "        alt_bins = pd.cut(X_train['Altitude'], bins=5, retbins=True)[1]\n",
    "        X_train['Altitude_bins'] = pd.cut(X_train['Altitude'], bins=alt_bins, labels=False)\n",
    "        X_test['Altitude_bins'] = pd.cut(X_test['Altitude'], bins=alt_bins, labels=False)\n",
    "        print(\"  Created binned feature: Altitude_bins\")\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "def augment_continuous_features(X, y, continuous_cols, augmentation_factor=2, noise_scale=0.01, random_state=42):\n",
    "    \"\"\"Augment continuous features with noise - only for training set\"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    n_samples = len(X)\n",
    "    n_augment = int(n_samples * augmentation_factor)\n",
    "\n",
    "    X_augmented = X.copy()\n",
    "    y_augmented = y.copy()\n",
    "\n",
    "    for _ in range(n_augment):\n",
    "        idx = np.random.randint(0, n_samples)\n",
    "        base_sample = X.iloc[idx].copy()\n",
    "\n",
    "        for col in continuous_cols:\n",
    "            std = X[col].std()\n",
    "            noise = np.random.normal(loc=0, scale=std * noise_scale)\n",
    "            if X[col].min() >= 0:\n",
    "                base_sample[col] = max(0, base_sample[col] + noise)\n",
    "            else:\n",
    "                base_sample[col] += noise\n",
    "\n",
    "        X_augmented = X_augmented._append(base_sample, ignore_index=True)\n",
    "        \n",
    "        y_augmented = y_augmented._append(\n",
    "            pd.Series(y.iloc[idx], index=[len(y_augmented)]),  \n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "    return X_augmented, y_augmented\n",
    "\n",
    "def enhanced_load_and_prepare_data(augment=True, augmentation_factor=2, \n",
    "                                 lu_type_importance_boost=3.0, \n",
    "                                 outlier_threshold=2.0):\n",
    "    \"\"\"Fixed data leakage version with outlier handling\"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    dtype_dict = {\n",
    "        'Soillayer': 'int8',\n",
    "        'yi': 'float32'\n",
    "    }\n",
    "\n",
    "    df_clean = pd.read_csv('F:/model/df.clean.yi.csv', dtype=dtype_dict)\n",
    "    data_predictor_VIF = pd.read_csv('F:/model/data.predictor.VIF.yi.csv')\n",
    "\n",
    "    # Select target soil layer\n",
    "    target_layer = \"topsoil\" ###################################################################################SELECT LAYER\n",
    "    df = df_clean[df_clean['Soillayer'] == (1 if target_layer == 'topsoil' else 2)].copy()\n",
    "\n",
    "    # Select features\n",
    "    predictor_columns = data_predictor_VIF['x'].tolist()\n",
    "    valid_x_cols = [col for col in predictor_columns if col != \"Soillayer\" and col in df.columns]\n",
    "\n",
    "    # Data cleaning\n",
    "    for col in valid_x_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    X = df[valid_x_cols].astype('float32').fillna(0)\n",
    "    y = df['yi'].astype('float32')\n",
    "\n",
    "    print(f\"Original data size: {len(X)}\")\n",
    "    \n",
    "    # Outlier detection and handling\n",
    "    continuous_cols = ['Lon', 'Lat', 'Age', 'BD', 'pH', 'Altitude']\n",
    "    continuous_cols = [col for col in continuous_cols if col in X.columns]\n",
    "    \n",
    "    print(\"\\n=== Outlier Handling ===\")\n",
    "    X_clean, y_clean, outliers = remove_outliers_robust(\n",
    "        X, y, continuous_cols, threshold=outlier_threshold\n",
    "    )\n",
    "\n",
    "    # Data splitting\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_clean, y_clean, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # Safe feature engineering\n",
    "    X_train, X_test = safe_feature_engineering(X_train, X_test)\n",
    "\n",
    "    # Data leakage check\n",
    "    check_data_leakage(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # LUtype feature enhancement (only for training set)\n",
    "    if 'LUtype' in X_train.columns:\n",
    "        print(f\"\\n=== LUtype Feature Enhancement ===\")\n",
    "        print(f\"Original LUtype distribution:\")\n",
    "        print(X_train['LUtype'].value_counts().sort_index())\n",
    "        \n",
    "        print(f\"\\nEnhancing LUtype importance with factor: {lu_type_importance_boost}\")\n",
    "        \n",
    "        # Create LUtype feature enhancements\n",
    "        for i in range(int(lu_type_importance_boost) - 1):\n",
    "            lu_type_col_name = f'LUtype_boost_{i+1}'\n",
    "            X_train[lu_type_col_name] = X_train['LUtype']\n",
    "            X_test[lu_type_col_name] = X_test['LUtype']\n",
    "            print(f\"  Created LUtype copy: {lu_type_col_name}\")\n",
    "        \n",
    "        # Create interaction terms between LUtype and other important features\n",
    "        important_features = ['pH', 'BD', 'Age', 'Altitude']\n",
    "        for feature in important_features:\n",
    "            if feature in X_train.columns:\n",
    "                interaction_name = f'LUtype_{feature}_interaction'\n",
    "                X_train[interaction_name] = X_train['LUtype'] * X_train[feature]\n",
    "                X_test[interaction_name] = X_test['LUtype'] * X_test[feature]\n",
    "                print(f\"  Created interaction feature: {interaction_name}\")\n",
    "        \n",
    "        # Create LUtype squared term (non-linear effect)\n",
    "        X_train['LUtype_squared'] = X_train['LUtype'] ** 2\n",
    "        X_test['LUtype_squared'] = X_test['LUtype'] ** 2\n",
    "        print(\"  Created LUtype_squared\")\n",
    "    \n",
    "    # Data augmentation (only for training set)\n",
    "    if augment:\n",
    "        continuous_cols = [\n",
    "            'Lon', 'Lat', 'Age', 'BD', 'pH',\n",
    "            'Lon_log', 'Lat_log', 'Age_log', 'BD_log', 'pH_log',\n",
    "            'Altitude'\n",
    "        ]\n",
    "        continuous_cols = [col for col in continuous_cols if col in X_train.columns]\n",
    "        \n",
    "        print(f\"\\n=== Data Augmentation ===\")\n",
    "        print(f\"Training set size before augmentation: {len(X_train)}\")\n",
    "        X_train, y_train = augment_continuous_features(\n",
    "            X=X_train,  # Only augment training set\n",
    "            y=y_train,  # Only augment training set\n",
    "            continuous_cols=continuous_cols,\n",
    "            augmentation_factor=augmentation_factor,\n",
    "            noise_scale=0.01,  \n",
    "            random_state=42\n",
    "        )\n",
    "        print(f\"Training set size after augmentation: {len(X_train)}\")\n",
    "    else:\n",
    "        print(\"\\nSkipping data augmentation\")\n",
    "\n",
    "    print(f\"\\n=== Final Dataset Statistics ===\")\n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Test set size: {len(X_test)}\")\n",
    "    print(f\"Total number of features: {len(X_train.columns)}\")\n",
    "    \n",
    "    # Statistical feature distribution\n",
    "    lu_type_cols = [col for col in X_train.columns if 'LUtype' in col]\n",
    "    \n",
    "    print(f\"\\nFeature statistics:\")\n",
    "    print(f\"LUtype-related features: {len(lu_type_cols)}\")\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=X_train.columns.tolist())\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test, feature_names=X_train.columns.tolist())\n",
    "\n",
    "    return dtrain, dtest, X, y, X_test, y_test, X_train, y_train\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function with data leakage prevention\"\"\"\n",
    "    outlier_threshold = 2.0  # Outlier detection threshold\n",
    "    \n",
    "    print(\"=== Starting Enhanced XGBoost Modeling (Fixed Data Leakage Version) ===\")\n",
    "    \n",
    "    # Use fixed data processing (with outlier handling and data leakage prevention)\n",
    "    dtrain, dtest, x1, y1, X_test, y_test, X_train, y_train = enhanced_load_and_prepare_data(\n",
    "        augment=True,\n",
    "        augmentation_factor=3,\n",
    "        lu_type_importance_boost=3.0,\n",
    "        outlier_threshold=outlier_threshold\n",
    "    )\n",
    "\n",
    "    tuner = XGBoostTuner(seed=42, n_jobs=17)\n",
    "\n",
    "    # 1. Hyperparameter tuning\n",
    "    print(\"\\n=== Starting Hyperparameter Tuning ===\")\n",
    "    best_params = tuner.tune_hyperparameters(dtrain, n_trials=10)\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "    # 2. Enhanced Cross-validation with 10x5 folds and model saving\n",
    "    print(\"\\n=== Starting 10x5 Cross-Validation ===\")\n",
    "    cv_results_summary = tuner.cross_validate(best_params, X_train, y_train, n_splits=5,\n",
    "                                              cv_models_dir='F:/model/results/cv_models',\n",
    "                                              n_repeats=10)  # 10 repetitions of 5-fold CV\n",
    "    \n",
    "    print(\"\\nSaved CV models:\")\n",
    "    for path in cv_results_summary['detailed_results']['model_paths'][:5]:  # Show first 5\n",
    "        print(f\"- {path}\")\n",
    "    print(f\"... and {len(cv_results_summary['detailed_results']['model_paths']) - 5} more\")\n",
    "    \n",
    "    # Plot enhanced CV results\n",
    "    print(\"\\nPlotting enhanced cross-validation results...\")\n",
    "    tuner.plot_cv_results(cv_results_summary)\n",
    "\n",
    "    # 3. Train final model\n",
    "    optimal_rounds = int(cv_results_summary['best_iterations_mean'])\n",
    "    print(f\"\\nTraining final model with {optimal_rounds} rounds...\")\n",
    "    final_model, evals_result = tuner.train_model(best_params, dtrain, num_boost_round=optimal_rounds)\n",
    "\n",
    "    # Plot learning curves\n",
    "    print(\"\\nPlotting learning curves...\")\n",
    "    tuner.plot_learning_curves(evals_result, \"Final Model\")\n",
    "\n",
    "    # 4. Evaluate and plot final performance\n",
    "    print(\"\\nEvaluating final model...\")\n",
    "    test_metrics, _ = tuner.evaluate_model(final_model, dtest)\n",
    "    print(\"\\n=== Final Test Metrics ===\")\n",
    "    print(f\"RMSE: {test_metrics['rmse']:.4f}\")\n",
    "    print(f\"R²: {test_metrics['r2']:.4f}\")\n",
    "    print(f\"MAE: {test_metrics['mae']:.4f}\")\n",
    "\n",
    "    print(\"\\nPlotting final model performance...\")\n",
    "    tuner.plot_final_model_performance(final_model, dtest)\n",
    "\n",
    "    # 5. Analyze LUtype importance\n",
    "    print(f\"\\nAnalyzing LUtype feature importance...\")\n",
    "    importance_df = tuner.plot_feature_importance(final_model, top_n=35)\n",
    "    \n",
    "    # Detailed analysis of LUtype importance\n",
    "    tuner.analyze_lutype_importance(final_model, X_test)\n",
    "    \n",
    "    # 6. SHAP analysis\n",
    "    if SHAP_AVAILABLE:\n",
    "        print(\"\\nGenerating SHAP summary plot...\")\n",
    "        tuner.plot_shap_summary(final_model, X_test)\n",
    "        \n",
    "    # 7. Save results\n",
    "    print(\"\\nSaving results...\")\n",
    "    tuner.save_results(final_model, 'F:/model/results')\n",
    "    \n",
    "    # Save CV results summary\n",
    "    cv_summary_path = 'F:/model/results/cv_summary.csv'\n",
    "    cv_results_summary['detailed_results'].to_csv(cv_summary_path, index=False)\n",
    "    print(f\"Saved detailed CV results to: {cv_summary_path}\")\n",
    "    \n",
    "    print(f\"\\n=== Model Training Summary ===\")\n",
    "    print(\"✓ Fixed data leakage issues\")\n",
    "    print(\"✓ Added outlier detection and handling\")\n",
    "    print(\"✓ Safe feature engineering (avoided data leakage)\")\n",
    "    print(\"✓ Created multiple LUtype feature copies\")\n",
    "    print(\"✓ Added LUtype interaction features with other important variables\")\n",
    "    print(\"✓ Added LUtype squared term (non-linear effect)\")\n",
    "    print(\"✓ Improved hyperparameter search space for better handling of categorical features\")\n",
    "    print(\"✓ Test set uses original data (no augmentation noise)\")\n",
    "    print(\"✓ Implemented 10 repetitions of 5-fold cross-validation for robust evaluation\")\n",
    "    \n",
    "    print(\"\\n=== Complete! ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6675cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost modeling: passive fractions  in topsoil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import builtins\n",
    "from scipy import stats\n",
    "open = builtins.open\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# SHAP availability check\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SHAP_AVAILABLE = False\n",
    "\n",
    "class XGBoostTuner:\n",
    "    def __init__(self, seed=42, n_jobs=-1):\n",
    "        self.seed = seed\n",
    "        self.n_jobs = n_jobs if n_jobs != -1 else None\n",
    "        self.study = None\n",
    "        self.best_model = None\n",
    "        self.best_params = None\n",
    "        self.feature_names = None  # Store feature names\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_numeric_value(value):\n",
    "        \"\"\"Convert string values to numeric, handling special cases\"\"\"\n",
    "        if pd.isna(value):\n",
    "            return np.nan\n",
    "        if isinstance(value, str):\n",
    "            # Remove any non-numeric characters except minus, decimal point\n",
    "            cleaned = re.sub(r'[^\\d.-]', '', value)\n",
    "            try:\n",
    "                return float(cleaned) if cleaned else np.nan\n",
    "            except ValueError:\n",
    "                return np.nan\n",
    "        return float(value)\n",
    "\n",
    "    def objective(self, trial, dtrain, num_boost_round=500):\n",
    "        \"\"\"Objective function with enhanced regularization\"\"\"\n",
    "        params = {\n",
    "            'eta': trial.suggest_float('eta', 0.005, 0.1, log=True),  # Lower learning rate\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 4),  # Shallower trees\n",
    "            'subsample': trial.suggest_float('subsample', 0.4, 0.7),  # Lower subsampling\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 0.7),  # Lower feature sampling\n",
    "           # 'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.4, 0.7),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 10, 20),  # Higher min child weight\n",
    "            'lambda': trial.suggest_float('lambda', 10, 25.0),  # Stronger L2 regularization\n",
    "            'alpha': trial.suggest_float('alpha', 5.0, 15.0),  # Stronger L1 regularization\n",
    "            'gamma': trial.suggest_float('gamma', 0.5, 2.0),  # Higher pruning parameter\n",
    "            'max_delta_step': trial.suggest_int('max_delta_step', 0, 1),\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'verbosity': 0,\n",
    "            'seed': self.seed,\n",
    "            'nthread': 1\n",
    "        }\n",
    "\n",
    "        cv_results = xgb.cv(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=800,  # More rounds but more conservative early stopping\n",
    "            nfold=5,\n",
    "            metrics='rmse',\n",
    "            early_stopping_rounds=25,  # More conservative early stopping\n",
    "            as_pandas=True,\n",
    "            seed=self.seed,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        # Stronger overfitting penalty\n",
    "        train_rmse = cv_results['train-rmse-mean'].iloc[-1]\n",
    "        val_rmse = cv_results['test-rmse-mean'].iloc[-1]\n",
    "        \n",
    "        # Calculate overfitting degree\n",
    "        overfitting_ratio = (train_rmse - val_rmse) / train_rmse\n",
    "        gap_penalty = max(0, overfitting_ratio) * 0.3  # Stronger penalty\n",
    "        \n",
    "        # Add extra penalty if severe overfitting\n",
    "        if overfitting_ratio > 0.1:\n",
    "            gap_penalty += (overfitting_ratio - 0.1) * 0.5\n",
    "            \n",
    "        return val_rmse + gap_penalty\n",
    "    \n",
    "    def tune_hyperparameters(self, dtrain, n_trials=10):  # Increased number of trials\n",
    "        \"\"\"Hyperparameter tuning focused on generalization\"\"\"\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        \n",
    "        print(\"Tuning hyperparameters with aggressive overfitting prevention...\")\n",
    "        print(\"Using very strong regularization and shallow trees\")\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=self.n_jobs) as executor:\n",
    "            futures = [executor.submit(lambda: study.optimize(\n",
    "                lambda trial: self.objective(trial, dtrain),\n",
    "                n_trials=5,\n",
    "                n_jobs=1\n",
    "            )) for _ in range(n_trials//5)]\n",
    "\n",
    "            for future in futures:\n",
    "                future.result()\n",
    "\n",
    "        self.study = study\n",
    "        self.best_params = study.best_params\n",
    "        self.best_params.update({\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'seed': self.seed,\n",
    "            'nthread': self.n_jobs\n",
    "        })\n",
    "\n",
    "        print(f\"Best parameters found: {self.best_params}\")\n",
    "        return self.best_params\n",
    "\n",
    "\n",
    "    def train_model(self, params, dtrain, dvalid=None, num_boost_round=500):\n",
    "        \"\"\"Train model with focus on preventing overfitting\"\"\"\n",
    "        evals = [(dtrain, 'train')]\n",
    "        if dvalid is not None:\n",
    "            evals.append((dvalid, 'valid'))\n",
    "\n",
    "        evals_result = {}\n",
    "        model = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            evals=evals,\n",
    "            early_stopping_rounds=25,  # More conservative early stopping\n",
    "            verbose_eval=100,  # Reduced output frequency\n",
    "            evals_result=evals_result\n",
    "        )\n",
    "\n",
    "        self.feature_names = dtrain.feature_names\n",
    "        if self.feature_names is None:\n",
    "            self.feature_names = [f'f{i}' for i in range(dtrain.num_col())]\n",
    "            model.feature_names = self.feature_names\n",
    "\n",
    "        return model, evals_result\n",
    "\n",
    "    def cross_validate(self, params, X, y, n_splits=5, cv_models_dir='cv_models', n_repeats=10): \n",
    "        \"\"\"Enhanced CV with 10 repetitions of 5-fold cross-validation and model saving\"\"\"\n",
    "        Path(cv_models_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        all_cv_results = {\n",
    "            'train_rmse': [], 'val_rmse': [],\n",
    "            'train_r2': [], 'val_r2': [],\n",
    "            'best_iterations': [],\n",
    "            'model_paths': [],\n",
    "            'feature_names': [],\n",
    "            'repeat': [],\n",
    "            'fold': []\n",
    "        }\n",
    "\n",
    "        def process_fold(repeat_idx, fold_idx, train_idx, val_idx):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=X_train.columns.tolist())\n",
    "            dval = xgb.DMatrix(X_val, label=y_val, feature_names=X_train.columns.tolist())\n",
    "\n",
    "            model, _ = self.train_model(params, dtrain, dval)\n",
    "\n",
    "            # Save the CV model\n",
    "            model_path = os.path.join(cv_models_dir, f'cv_model_repeat_{repeat_idx}_fold_{fold_idx}.json')\n",
    "            model.save_model(model_path)\n",
    "\n",
    "            train_pred = model.predict(dtrain)\n",
    "            val_pred = model.predict(dval)\n",
    "\n",
    "            return (\n",
    "                np.sqrt(mean_squared_error(y_train, train_pred)),\n",
    "                np.sqrt(mean_squared_error(y_val, val_pred)),\n",
    "                r2_score(y_train, train_pred),\n",
    "                r2_score(y_val, val_pred),\n",
    "                model.best_iteration if hasattr(model, 'best_iteration') else params.get('num_boost_round', 500),\n",
    "                model_path,\n",
    "                model.feature_names,\n",
    "                repeat_idx,\n",
    "                fold_idx\n",
    "            )\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=self.n_jobs) as executor:\n",
    "            futures = []\n",
    "            for repeat_idx in range(n_repeats):\n",
    "                kf = KFold(n_splits=n_splits, shuffle=True, random_state=self.seed + repeat_idx)\n",
    "                for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "                    futures.append(executor.submit(\n",
    "                        process_fold, repeat_idx, fold_idx, train_idx, val_idx\n",
    "                    ))\n",
    "\n",
    "            for future in futures:\n",
    "                train_rmse, val_rmse, train_r2, val_r2, best_iter, model_path, feature_names, repeat_idx, fold_idx = future.result()\n",
    "                all_cv_results['train_rmse'].append(train_rmse)\n",
    "                all_cv_results['val_rmse'].append(val_rmse)\n",
    "                all_cv_results['train_r2'].append(train_r2)\n",
    "                all_cv_results['val_r2'].append(val_r2)\n",
    "                all_cv_results['best_iterations'].append(best_iter)\n",
    "                all_cv_results['model_paths'].append(model_path)\n",
    "                all_cv_results['feature_names'].append(feature_names)\n",
    "                all_cv_results['repeat'].append(repeat_idx)\n",
    "                all_cv_results['fold'].append(fold_idx)\n",
    "        # Create summary statistics\n",
    "        cv_results_summary = {\n",
    "            'train_rmse_mean': np.mean(all_cv_results['train_rmse']),\n",
    "            'train_rmse_std': np.std(all_cv_results['train_rmse']),\n",
    "            'val_rmse_mean': np.mean(all_cv_results['val_rmse']),\n",
    "            'val_rmse_std': np.std(all_cv_results['val_rmse']),\n",
    "            'train_r2_mean': np.mean(all_cv_results['train_r2']),\n",
    "            'train_r2_std': np.std(all_cv_results['train_r2']),\n",
    "            'val_r2_mean': np.mean(all_cv_results['val_r2']),\n",
    "            'val_r2_std': np.std(all_cv_results['val_r2']),\n",
    "            'best_iterations_mean': np.mean(all_cv_results['best_iterations']),\n",
    "            'best_iterations_std': np.std(all_cv_results['best_iterations']),\n",
    "            'detailed_results': pd.DataFrame(all_cv_results)\n",
    "        }\n",
    "\n",
    "        return cv_results_summary\n",
    "\n",
    "    def evaluate_model(self, model, dtest):\n",
    "        \"\"\"Evaluate model performance on test set\"\"\"\n",
    "        test_pred = model.predict(dtest)\n",
    "        return {\n",
    "            'rmse': np.sqrt(mean_squared_error(dtest.get_label(), test_pred)),\n",
    "            'r2': r2_score(dtest.get_label(), test_pred),\n",
    "            'mae': mean_absolute_error(dtest.get_label(), test_pred)\n",
    "        }, test_pred\n",
    "\n",
    "    def plot_learning_curves(self, evals_result, title_suffix):\n",
    "        \"\"\"Plot training and validation metrics\"\"\"\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        epochs = len(evals_result['train']['rmse'])\n",
    "        plt.plot(range(epochs), evals_result['train']['rmse'], label='Train RMSE')\n",
    "        if 'valid' in evals_result:\n",
    "            plt.plot(range(epochs), evals_result['valid']['rmse'], label='Validation RMSE')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.title(f'Learning Curves - {title_suffix}')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_cv_results(self, cv_results_summary):\n",
    "        \"\"\"Plot enhanced cross-validation results with both original and new visualization\"\"\"\n",
    "        # Check if it's the new summary format or old list format\n",
    "        if isinstance(cv_results_summary, dict) and 'detailed_results' in cv_results_summary:\n",
    "            # New format - use the detailed results\n",
    "            detailed_results = cv_results_summary['detailed_results']\n",
    "            \n",
    "            # Create two visualizations:\n",
    "            # 1. Original visualization (simple line plot for first repeat)\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            \n",
    "            # Plot 1: Original style - first repeat only\n",
    "            plt.subplot(2, 2, 1)\n",
    "            first_repeat = detailed_results[detailed_results['repeat'] == 0]\n",
    "            plt.plot(first_repeat['train_rmse'], 'o-', label='Train RMSE')\n",
    "            plt.plot(first_repeat['val_rmse'], 'o-', label='Validation RMSE')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.title('Cross-Validation RMSE (First Repeat)')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Plot 2: Original style - first repeat R²\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.plot(first_repeat['train_r2'], 'o-', label='Train R²')\n",
    "            plt.plot(first_repeat['val_r2'], 'o-', label='Validation R²')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('R² Score')\n",
    "            plt.title('Cross-Validation R² Scores (First Repeat)')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Plot 3: New visualization - RMSE distribution across all repeats\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.boxplot([detailed_results['train_rmse'], detailed_results['val_rmse']], \n",
    "                       labels=['Train RMSE', 'Validation RMSE'])\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.title('RMSE Distribution across 10x5 CV')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Plot 4: New visualization - R² distribution across all repeats\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.boxplot([detailed_results['train_r2'], detailed_results['val_r2']], \n",
    "                       labels=['Train R²', 'Validation R²'])\n",
    "            plt.ylabel('R² Score')\n",
    "            plt.title('R² Distribution across 10x5 CV')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Print summary statistics\n",
    "            print(\"\\n=== 10x5 Cross-Validation Summary ===\")\n",
    "            print(f\"Average Train RMSE: {cv_results_summary['train_rmse_mean']:.4f} (±{cv_results_summary['train_rmse_std']:.4f})\")\n",
    "            print(f\"Average Validation RMSE: {cv_results_summary['val_rmse_mean']:.4f} (±{cv_results_summary['val_rmse_std']:.4f})\")\n",
    "            print(f\"Average Train R²: {cv_results_summary['train_r2_mean']:.4f} (±{cv_results_summary['train_r2_std']:.4f})\")\n",
    "            print(f\"Average Validation R²: {cv_results_summary['val_r2_mean']:.4f} (±{cv_results_summary['val_r2_std']:.4f})\")\n",
    "            print(f\"Average Best Iterations: {cv_results_summary['best_iterations_mean']:.1f} (±{cv_results_summary['best_iterations_std']:.1f})\")\n",
    "            \n",
    "            # Also print the format that main() expects\n",
    "            print(\"\\n=== 交叉验证结果 (旧格式兼容) ===\")\n",
    "            print(f\"平均训练RMSE: {cv_results_summary['train_rmse_mean']:.4f} (±{cv_results_summary['train_rmse_std']:.4f})\")\n",
    "            print(f\"平均验证RMSE: {cv_results_summary['val_rmse_mean']:.4f} (±{cv_results_summary['val_rmse_std']:.4f})\")\n",
    "            print(f\"平均训练R²: {cv_results_summary['train_r2_mean']:.4f} (±{cv_results_summary['train_r2_std']:.4f})\")\n",
    "            print(f\"平均验证R²: {cv_results_summary['val_r2_mean']:.4f} (±{cv_results_summary['val_r2_std']:.4f})\")\n",
    "            \n",
    "        else:\n",
    "            # Old format - keep original plotting\n",
    "            plt.figure(figsize=(15, 5))\n",
    "\n",
    "            # Plot RMSE\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(cv_results_summary['train_rmse'], 'o-', label='Train RMSE')\n",
    "            plt.plot(cv_results_summary['val_rmse'], 'o-', label='Validation RMSE')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.title('Cross-Validation RMSE')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Plot R2\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(cv_results_summary['train_r2'], 'o-', label='Train R²')\n",
    "            plt.plot(cv_results_summary['val_r2'], 'o-', label='Validation R²')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('R² Score')\n",
    "            plt.title('Cross-Validation R² Scores')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def plot_final_model_performance(self, model, dtest):\n",
    "        \"\"\"Plot actual vs predicted values for test set\"\"\"\n",
    "        test_metrics, test_pred = self.evaluate_model(model, dtest)\n",
    "        y_test = dtest.get_label()\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        # Scatter plot of actual vs predicted\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(y_test, test_pred, alpha=0.5)\n",
    "        plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--r')\n",
    "        plt.xlabel('Actual Values')\n",
    "        plt.ylabel('Predicted Values')\n",
    "        plt.title(f'Actual vs Predicted (R² = {test_metrics[\"r2\"]:.3f})')\n",
    "\n",
    "        # Residual plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        residuals = y_test - test_pred\n",
    "        plt.scatter(test_pred, residuals, alpha=0.5)\n",
    "        plt.axhline(y=0, color='r', linestyle='--')\n",
    "        plt.xlabel('Predicted Values')\n",
    "        plt.ylabel('Residuals')\n",
    "        plt.title('Residual Plot')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_feature_importance(self, model, importance_type='weight', top_n=30):\n",
    "        \"\"\"Plot feature importance without category-specific highlighting\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "    \n",
    "        importance_dict = model.get_score(importance_type=importance_type)\n",
    "        \n",
    "        if not importance_dict:\n",
    "            print(\"No feature importance data available.\")\n",
    "            return None\n",
    "            \n",
    "\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': list(importance_dict.keys()),\n",
    "            'importance': list(importance_dict.values())\n",
    "        }).sort_values('importance', ascending=True)\n",
    "        \n",
    "\n",
    "        if len(importance_df) > top_n:\n",
    "            importance_df = importance_df.tail(top_n)\n",
    "        \n",
    "\n",
    "        y_pos = np.arange(len(importance_df))\n",
    "        colors = ['lightblue'] * len(importance_df)\n",
    "        \n",
    "        ax.barh(y_pos, importance_df['importance'], color=colors, alpha=0.8)\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(importance_df['feature'])\n",
    "        ax.set_xlabel('Importance')\n",
    "        \n",
    "        title = f'Feature Importance ({importance_type})'\n",
    "        ax.set_title(title)\n",
    "        \n",
    "\n",
    "        lu_type_features = importance_df[importance_df['feature'].str.contains('LUtype', na=False)]\n",
    "        lu_type_importance = lu_type_features['importance'].sum() if not lu_type_features.empty else 0\n",
    "        \n",
    "        ax.text(0.7, 0.95, f'LUtype total: {lu_type_importance:.3f}', \n",
    "                transform=ax.transAxes, fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\"))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return importance_df\n",
    "\n",
    "    def analyze_lutype_importance(self, model, X):\n",
    "     \n",
    "        importance_dict = model.get_score(importance_type='weight')\n",
    "        \n",
    "        if not importance_dict:\n",
    "            print(\"No feature importance data available.\")\n",
    "            return\n",
    "            \n",
    "\n",
    "        lutype_features = {k: v for k, v in importance_dict.items() if 'LUtype' in k}\n",
    "        other_features = {k: v for k, v in importance_dict.items() if 'LUtype' not in k}\n",
    "        \n",
    "        print(f\"\\n=== LUtype Feature Importance Analysis ===\")\n",
    "        print(f\"Total LUtype-related features: {len(lutype_features)}\")\n",
    "        print(f\"Total importance of LUtype features: {sum(lutype_features.values()):.3f}\")\n",
    "        print(f\"Average importance of LUtype features: {np.mean(list(lutype_features.values())) if lutype_features else 0:.3f}\")\n",
    "        \n",
    "        total_importance = sum(importance_dict.values())\n",
    "        lu_type_percentage = (sum(lutype_features.values()) / total_importance * 100) if total_importance > 0 else 0\n",
    "        \n",
    "        print(f\"\\nLUtype importance percentage: {lu_type_percentage:.2f}%\")\n",
    "        \n",
    "     \n",
    "        if lutype_features:\n",
    "            sorted_lutype = sorted(lutype_features.items(), key=lambda x: x[1], reverse=True)\n",
    "            print(f\"\\nTop LUtype-related features:\")\n",
    "            for feature, importance in sorted_lutype[:10]:\n",
    "                print(f\"  {feature}: {importance:.4f}\")\n",
    "        else:\n",
    "            print(\"\\nNo LUtype-related features found in importance scores.\")\n",
    "\n",
    "    def plot_shap_summary(self, model, X, feature_names=None):\n",
    "        \"\"\"Generate SHAP summary plot if SHAP is available\"\"\"\n",
    "        if SHAP_AVAILABLE:\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(X)\n",
    "\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            shap.summary_plot(shap_values, X, feature_names=feature_names)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"SHAP not available. Install with: pip install shap\")\n",
    "\n",
    "    def save_results(self, model, output_dir='results'):\n",
    "        \"\"\"Save all results to disk including feature names\"\"\"\n",
    "        Path(output_dir).mkdir(exist_ok=True)\n",
    "\n",
    "        # Save model\n",
    "        model.save_model(f'{output_dir}/xgb_model.json')\n",
    "\n",
    "        # Save feature names\n",
    "        if self.feature_names is not None:\n",
    "            with open(f'{output_dir}/feature_names.txt', 'w') as f:\n",
    "                f.write('\\n'.join(self.feature_names))\n",
    "\n",
    "        # Save other artifacts\n",
    "        joblib.dump(self.best_params, f'{output_dir}/best_params.pkl')\n",
    "\n",
    "        if self.study:\n",
    "            joblib.dump(self.study, f'{output_dir}/study.pkl')\n",
    "            study_df = self.study.trials_dataframe()\n",
    "            study_df.to_csv(f'{output_dir}/trials.csv', index=False)\n",
    "\n",
    "def detect_outliers_iqr(df, columns, threshold=1.5):\n",
    "    \"\"\"Detect outliers using IQR method\"\"\"\n",
    "    outlier_indices = []\n",
    "    \n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - threshold * IQR\n",
    "            upper_bound = Q3 + threshold * IQR\n",
    "            \n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index\n",
    "            outlier_indices.extend(outliers)\n",
    "            \n",
    "            if len(outliers) > 0:\n",
    "                print(f\"  {col}: Found {len(outliers)} outliers \"\n",
    "                      f\"({len(outliers)/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    return list(set(outlier_indices))\n",
    "\n",
    "def remove_outliers_robust(df, y, columns, method='iqr', threshold=2.0):\n",
    "    \"\"\"Robust outlier handling method\"\"\"\n",
    "    print(\"Starting outlier detection...\")\n",
    "    \n",
    "    if method == 'iqr':\n",
    "        outlier_indices = detect_outliers_iqr(df, columns, threshold)\n",
    "    elif method == 'zscore':\n",
    "        # Z-score method\n",
    "        z_scores = np.abs(stats.zscore(df[columns]))\n",
    "        outlier_indices = np.where(z_scores > threshold)[0]\n",
    "        outlier_indices = list(outlier_indices)\n",
    "    else:\n",
    "        return df, y, []\n",
    "    \n",
    "    print(f\"\\nTotal outliers found: {len(outlier_indices)}\")\n",
    "    \n",
    "    if len(outlier_indices) > 0:\n",
    "        df_clean = df.drop(outlier_indices)\n",
    "        y_clean = y.drop(outlier_indices)\n",
    "        print(f\"Data size after removing outliers: {len(df_clean)} (removed {len(outlier_indices)} samples)\")\n",
    "        return df_clean, y_clean, outlier_indices\n",
    "    \n",
    "    print(\"No outliers found\")\n",
    "    return df, y, []\n",
    "\n",
    "def check_data_leakage(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Check for data leakage\"\"\"\n",
    "    print(\"\\n=== Data Leakage Check ===\")\n",
    "    \n",
    "    # Check for overlap between train and test sets\n",
    "    train_indices = set(X_train.index)\n",
    "    test_indices = set(X_test.index)\n",
    "    overlap = train_indices.intersection(test_indices)\n",
    "    \n",
    "    if overlap:\n",
    "        print(f\"❌ Data leakage detected: {len(overlap)} overlapping samples between train and test sets\")\n",
    "    else:\n",
    "        print(\"✅ No overlap between train and test sets\")\n",
    "    \n",
    "    # Check feature distributions\n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Test set size: {len(X_test)}\")\n",
    "    print(f\"Number of features: {X_train.shape[1]}\")\n",
    "    \n",
    "    return len(overlap) == 0\n",
    "\n",
    "def safe_feature_engineering(X_train, X_test):\n",
    "    \"\"\"Safe feature engineering to avoid data leakage\"\"\"\n",
    "    print(\"Performing safe feature engineering...\")\n",
    "    \n",
    "    # 1. Logarithmic transformation\n",
    "    columns_to_log = ['Lon', 'Lat', 'Age', 'BD', 'pH']\n",
    "    for col in columns_to_log:\n",
    "        if col in X_train.columns:\n",
    "            X_train[col + '_log'] = np.log(X_train[col] + 1e-8)\n",
    "            X_test[col + '_log'] = np.log(X_test[col] + 1e-8)\n",
    "            print(f\"  Created log feature: {col}_log\")\n",
    "    \n",
    "    # 2. Binning (based on training set quantiles)\n",
    "    if 'Altitude' in X_train.columns:\n",
    "        # Use training set to compute bin boundaries\n",
    "        alt_bins = pd.cut(X_train['Altitude'], bins=5, retbins=True)[1]\n",
    "        X_train['Altitude_bins'] = pd.cut(X_train['Altitude'], bins=alt_bins, labels=False)\n",
    "        X_test['Altitude_bins'] = pd.cut(X_test['Altitude'], bins=alt_bins, labels=False)\n",
    "        print(\"  Created binned feature: Altitude_bins\")\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "def augment_continuous_features(X, y, continuous_cols, augmentation_factor=2, noise_scale=0.01, random_state=42):\n",
    "    \"\"\"\n",
    "    Augment continuous features with noise - with proper index resetting \n",
    "    to prevent alignment issues during training/evaluation.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Reset indices to ensure positional indexing (iloc) matches the index\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    \n",
    "    n_samples = len(X)\n",
    "    n_augment = int(n_samples * augmentation_factor)\n",
    "\n",
    "    augmented_X_list = []\n",
    "    augmented_y_list = []\n",
    "\n",
    "    for _ in range(n_augment):\n",
    "        idx = np.random.randint(0, n_samples)\n",
    "        base_sample = X.iloc[idx].copy()\n",
    "        \n",
    "        # Add noise to specified continuous columns\n",
    "        for col in continuous_cols:\n",
    "            if col in base_sample:\n",
    "                std = X[col].std()\n",
    "                noise = np.random.normal(loc=0, scale=std * noise_scale)\n",
    "                \n",
    "                # Logical check: don't allow negative values for typically positive soil metrics\n",
    "                if col in ['BD', 'Age', 'Altitude'] or 'log' in col:\n",
    "                    base_sample[col] = max(1e-8, base_sample[col] + noise)\n",
    "                else:\n",
    "                    base_sample[col] += noise\n",
    "\n",
    "        augmented_X_list.append(base_sample)\n",
    "        augmented_y_list.append(y.iloc[idx])\n",
    "\n",
    "    # Efficiently combine original and augmented data\n",
    "    X_augmented = pd.concat([X, pd.DataFrame(augmented_X_list)], ignore_index=True)\n",
    "    y_augmented = pd.concat([y, pd.Series(augmented_y_list)], ignore_index=True)\n",
    "\n",
    "    return X_augmented, y_augmented\n",
    "\n",
    "def enhanced_load_and_prepare_data(augment=True, augmentation_factor=2, \n",
    "                                 lu_type_importance_boost=3.0, \n",
    "                                 outlier_threshold=2.0):\n",
    "    \"\"\"Fixed data leakage version with outlier handling\"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    dtype_dict = {\n",
    "        'Soillayer': 'int8',\n",
    "        'yi': 'float32'\n",
    "    }\n",
    "\n",
    "    df_clean = pd.read_csv('F:/model/df.clean.yi.csv', dtype=dtype_dict)\n",
    "    data_predictor_VIF = pd.read_csv('F:/model/data.predictor.VIF.yi.csv')\n",
    "\n",
    "    # Select target soil layer\n",
    "    target_layer = \"topsoil\" ###################################################################################SELECT LAYER\n",
    "    df = df_clean[df_clean['Soillayer'] == (1 if target_layer == 'topsoil' else 2)].copy()\n",
    "\n",
    "    # Select features\n",
    "    predictor_columns = data_predictor_VIF['x'].tolist()\n",
    "    valid_x_cols = [col for col in predictor_columns if col != \"Soillayer\" and col in df.columns]\n",
    "\n",
    "    # Data cleaning\n",
    "    for col in valid_x_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    X = df[valid_x_cols].astype('float32').fillna(0)\n",
    "    y = df['yi'].astype('float32')\n",
    "\n",
    "    print(f\"Original data size: {len(X)}\")\n",
    "    \n",
    "    # Outlier detection and handling\n",
    "    continuous_cols = ['Lon', 'Lat', 'Age', 'BD', 'pH', 'Altitude']\n",
    "    continuous_cols = [col for col in continuous_cols if col in X.columns]\n",
    "    \n",
    "    print(\"\\n=== Outlier Handling ===\")\n",
    "    X_clean, y_clean, outliers = remove_outliers_robust(\n",
    "        X, y, continuous_cols, threshold=outlier_threshold\n",
    "    )\n",
    "\n",
    "    # Data splitting\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_clean, y_clean, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # Safe feature engineering\n",
    "    X_train, X_test = safe_feature_engineering(X_train, X_test)\n",
    "\n",
    "    # Data leakage check\n",
    "    check_data_leakage(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # LUtype feature enhancement (only for training set)\n",
    "    if 'LUtype' in X_train.columns:\n",
    "        print(f\"\\n=== LUtype Feature Enhancement ===\")\n",
    "        print(f\"Original LUtype distribution:\")\n",
    "        print(X_train['LUtype'].value_counts().sort_index())\n",
    "        \n",
    "        print(f\"\\nEnhancing LUtype importance with factor: {lu_type_importance_boost}\")\n",
    "        \n",
    "        # Create LUtype feature enhancements\n",
    "        for i in range(int(lu_type_importance_boost) - 1):\n",
    "            lu_type_col_name = f'LUtype_boost_{i+1}'\n",
    "            X_train[lu_type_col_name] = X_train['LUtype']\n",
    "            X_test[lu_type_col_name] = X_test['LUtype']\n",
    "            print(f\"  Created LUtype copy: {lu_type_col_name}\")\n",
    "        \n",
    "        # Create interaction terms between LUtype and other important features\n",
    "        important_features = ['pH', 'BD', 'Age', 'Altitude']\n",
    "        for feature in important_features:\n",
    "            if feature in X_train.columns:\n",
    "                interaction_name = f'LUtype_{feature}_interaction'\n",
    "                X_train[interaction_name] = X_train['LUtype'] * X_train[feature]\n",
    "                X_test[interaction_name] = X_test['LUtype'] * X_test[feature]\n",
    "                print(f\"  Created interaction feature: {interaction_name}\")\n",
    "        \n",
    "        # Create LUtype squared term (non-linear effect)\n",
    "        X_train['LUtype_squared'] = X_train['LUtype'] ** 2\n",
    "        X_test['LUtype_squared'] = X_test['LUtype'] ** 2\n",
    "        print(\"  Created LUtype_squared\")\n",
    "    \n",
    "    # Data augmentation (only for training set)\n",
    "    if augment:\n",
    "        continuous_cols = [\n",
    "            'Lon', 'Lat', 'Age', 'BD', 'pH',\n",
    "            'Lon_log', 'Lat_log', 'Age_log', 'BD_log', 'pH_log',\n",
    "            'Altitude'\n",
    "        ]\n",
    "        continuous_cols = [col for col in continuous_cols if col in X_train.columns]\n",
    "        \n",
    "        print(f\"\\n=== Data Augmentation ===\")\n",
    "        print(f\"Training set size before augmentation: {len(X_train)}\")\n",
    "        X_train, y_train = augment_continuous_features(\n",
    "            X=X_train,  # Only augment training set\n",
    "            y=y_train,  # Only augment training set\n",
    "            continuous_cols=continuous_cols,\n",
    "            augmentation_factor=augmentation_factor,\n",
    "            noise_scale=0.005,  \n",
    "            random_state=42\n",
    "        )\n",
    "        print(f\"Training set size after augmentation: {len(X_train)}\")\n",
    "    else:\n",
    "        print(\"\\nSkipping data augmentation\")\n",
    "\n",
    "    print(f\"\\n=== Final Dataset Statistics ===\")\n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Test set size: {len(X_test)}\")\n",
    "    print(f\"Total number of features: {len(X_train.columns)}\")\n",
    "    \n",
    "    # Statistical feature distribution\n",
    "    lu_type_cols = [col for col in X_train.columns if 'LUtype' in col]\n",
    "    \n",
    "    print(f\"\\nFeature statistics:\")\n",
    "    print(f\"LUtype-related features: {len(lu_type_cols)}\")\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=X_train.columns.tolist())\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test, feature_names=X_train.columns.tolist())\n",
    "\n",
    "    return dtrain, dtest, X, y, X_test, y_test, X_train, y_train\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function with data leakage prevention\"\"\"\n",
    "    outlier_threshold = 2.0  # Outlier detection threshold\n",
    "    \n",
    "    print(\"=== Starting Enhanced XGBoost Modeling (Fixed Data Leakage Version) ===\")\n",
    "    \n",
    "    # Use fixed data processing (with outlier handling and data leakage prevention)\n",
    "    dtrain, dtest, x1, y1, X_test, y_test, X_train, y_train = enhanced_load_and_prepare_data(\n",
    "        augment=True,\n",
    "        augmentation_factor=3,\n",
    "        lu_type_importance_boost=3.0,\n",
    "        outlier_threshold=outlier_threshold\n",
    "    )\n",
    "\n",
    "    tuner = XGBoostTuner(seed=42, n_jobs=17)\n",
    "\n",
    "    # 1. Hyperparameter tuning\n",
    "    print(\"\\n=== Starting Hyperparameter Tuning ===\")\n",
    "    best_params = tuner.tune_hyperparameters(dtrain, n_trials=10)\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "    # 2. Enhanced Cross-validation with 10x5 folds and model saving\n",
    "    print(\"\\n=== Starting 10x5 Cross-Validation ===\")\n",
    "    cv_results_summary = tuner.cross_validate(best_params, X_train, y_train, n_splits=5,\n",
    "                                              cv_models_dir='F:/model/results/cv_models',\n",
    "                                              n_repeats=10)  # 10 repetitions of 5-fold CV\n",
    "    \n",
    "    print(\"\\nSaved CV models:\")\n",
    "    for path in cv_results_summary['detailed_results']['model_paths'][:5]:  # Show first 5\n",
    "        print(f\"- {path}\")\n",
    "    print(f\"... and {len(cv_results_summary['detailed_results']['model_paths']) - 5} more\")\n",
    "    \n",
    "    # Plot enhanced CV results\n",
    "    print(\"\\nPlotting enhanced cross-validation results...\")\n",
    "    tuner.plot_cv_results(cv_results_summary)\n",
    "\n",
    "    # 3. Train final model\n",
    "    optimal_rounds = int(cv_results_summary['best_iterations_mean'])\n",
    "    print(f\"\\nTraining final model with {optimal_rounds} rounds...\")\n",
    "    final_model, evals_result = tuner.train_model(best_params, dtrain, num_boost_round=optimal_rounds)\n",
    "\n",
    "    # Plot learning curves\n",
    "    print(\"\\nPlotting learning curves...\")\n",
    "    tuner.plot_learning_curves(evals_result, \"Final Model\")\n",
    "\n",
    "    # 4. Evaluate and plot final performance\n",
    "    print(\"\\nEvaluating final model...\")\n",
    "    test_metrics, _ = tuner.evaluate_model(final_model, dtest)\n",
    "    print(\"\\n=== Final Test Metrics ===\")\n",
    "    print(f\"RMSE: {test_metrics['rmse']:.4f}\")\n",
    "    print(f\"R²: {test_metrics['r2']:.4f}\")\n",
    "    print(f\"MAE: {test_metrics['mae']:.4f}\")\n",
    "\n",
    "    print(\"\\nPlotting final model performance...\")\n",
    "    tuner.plot_final_model_performance(final_model, dtest)\n",
    "\n",
    "    # 5. Analyze LUtype importance\n",
    "    print(f\"\\nAnalyzing LUtype feature importance...\")\n",
    "    importance_df = tuner.plot_feature_importance(final_model, top_n=35)\n",
    "    \n",
    "    # Detailed analysis of LUtype importance\n",
    "    tuner.analyze_lutype_importance(final_model, X_test)\n",
    "    \n",
    "    # 6. SHAP analysis\n",
    "    if SHAP_AVAILABLE:\n",
    "        print(\"\\nGenerating SHAP summary plot...\")\n",
    "        tuner.plot_shap_summary(final_model, X_test)\n",
    "        \n",
    "    # 7. Save results\n",
    "    print(\"\\nSaving results...\")\n",
    "    tuner.save_results(final_model, 'F:/model/results')\n",
    "    \n",
    "    # Save CV results summary\n",
    "    cv_summary_path = 'F:/model/results/cv_summary.csv'\n",
    "    cv_results_summary['detailed_results'].to_csv(cv_summary_path, index=False)\n",
    "    print(f\"Saved detailed CV results to: {cv_summary_path}\")\n",
    "    \n",
    "    print(f\"\\n=== Model Training Summary ===\")\n",
    "    print(\"✓ Fixed data leakage issues\")\n",
    "    print(\"✓ Added outlier detection and handling\")\n",
    "    print(\"✓ Safe feature engineering (avoided data leakage)\")\n",
    "    print(\"✓ Created multiple LUtype feature copies\")\n",
    "    print(\"✓ Added LUtype interaction features with other important variables\")\n",
    "    print(\"✓ Added LUtype squared term (non-linear effect)\")\n",
    "    print(\"✓ Improved hyperparameter search space for better handling of categorical features\")\n",
    "    print(\"✓ Test set uses original data (no augmentation noise)\")\n",
    "    print(\"✓ Implemented 10 repetitions of 5-fold cross-validation for robust evaluation\")\n",
    "    \n",
    "    print(\"\\n=== Complete! ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df01b8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost modeling: soil organic carbon in subsoil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import builtins\n",
    "from scipy import stats\n",
    "open = builtins.open\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# SHAP availability check\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SHAP_AVAILABLE = False\n",
    "\n",
    "class XGBoostTuner:\n",
    "    def __init__(self, seed=42, n_jobs=-1):\n",
    "        self.seed = seed\n",
    "        self.n_jobs = n_jobs if n_jobs != -1 else None\n",
    "        self.study = None\n",
    "        self.best_model = None\n",
    "        self.best_params = None\n",
    "        self.feature_names = None  # Store feature names\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_numeric_value(value):\n",
    "        \"\"\"Convert string values to numeric, handling special cases\"\"\"\n",
    "        if pd.isna(value):\n",
    "            return np.nan\n",
    "        if isinstance(value, str):\n",
    "            # Remove any non-numeric characters except minus, decimal point\n",
    "            cleaned = re.sub(r'[^\\d.-]', '', value)\n",
    "            try:\n",
    "                return float(cleaned) if cleaned else np.nan\n",
    "            except ValueError:\n",
    "                return np.nan\n",
    "        return float(value)\n",
    "\n",
    "    def objective(self, trial, dtrain, num_boost_round=500):\n",
    "        \"\"\"Enhanced objective function with stronger overfitting prevention\"\"\"\n",
    "        params = {\n",
    "            'eta': trial.suggest_float('eta', 0.01, 0.15, log=True),  # 更小的学习率\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 4),  # 更浅的树\n",
    "            'subsample': trial.suggest_float('subsample', 0.5, 0.7),  # 降低采样率\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 0.7),  # 降低特征采样\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 5, 20),  # 增加限制\n",
    "            'lambda': trial.suggest_float('lambda', 0.5, 5.0, log=True),  # L2正则化\n",
    "            'alpha': trial.suggest_float('alpha', 0.5, 5.0, log=True),  # L1正则化\n",
    "            'gamma': trial.suggest_float('gamma', 0.1, 1.0),  # 增加剪枝强度\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'verbosity': 0,\n",
    "            'seed': self.seed,\n",
    "            'nthread': 1\n",
    "        }\n",
    "\n",
    "        cv_results = xgb.cv(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=500,  # 减少迭代轮数\n",
    "            nfold=5,\n",
    "            metrics='rmse',\n",
    "            early_stopping_rounds=20,  # 更早的停止\n",
    "            as_pandas=True,\n",
    "            seed=self.seed,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        # Strong overfitting penalty\n",
    "        train_rmse = cv_results['train-rmse-mean'].iloc[-1]\n",
    "        val_rmse = cv_results['test-rmse-mean'].iloc[-1]\n",
    "        \n",
    "        # 计算过拟合程度（更严格的判断）\n",
    "        overfitting_ratio = max(0, (train_rmse - val_rmse) / train_rmse)\n",
    "        \n",
    "        # 更严厉的惩罚\n",
    "        if overfitting_ratio > 0.05:  # 如果过拟合超过5%\n",
    "            penalty = (overfitting_ratio - 0.05) * 2.0\n",
    "            val_rmse += penalty\n",
    "            \n",
    "        # 额外惩罚：如果验证误差比训练误差高太多\n",
    "        if val_rmse > train_rmse * 1.5:  # 验证误差是训练误差的1.5倍以上\n",
    "            val_rmse *= 1.2\n",
    "            \n",
    "        return val_rmse\n",
    "    \n",
    "    def tune_hyperparameters(self, dtrain, n_trials=30):\n",
    "        \"\"\"Hyperparameter tuning focused on generalization\"\"\"\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        \n",
    "        print(\"Tuning hyperparameters with aggressive overfitting prevention...\")\n",
    "        print(\"Using very strong regularization and shallow trees\")\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=self.n_jobs) as executor:\n",
    "            futures = [executor.submit(lambda: study.optimize(\n",
    "                lambda trial: self.objective(trial, dtrain),\n",
    "                n_trials=10,  # 每批10个试验\n",
    "                n_jobs=1\n",
    "            )) for _ in range(max(1, n_trials//10))]\n",
    "\n",
    "            for future in futures:\n",
    "                future.result()\n",
    "\n",
    "        self.study = study\n",
    "        self.best_params = study.best_params\n",
    "        self.best_params.update({\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'seed': self.seed,\n",
    "            'nthread': self.n_jobs\n",
    "        })\n",
    "\n",
    "        print(f\"Best parameters found: {self.best_params}\")\n",
    "        return self.best_params\n",
    "\n",
    "    def train_model(self, params, dtrain, dvalid=None, num_boost_round=500):\n",
    "        \"\"\"Train model with focus on preventing overfitting\"\"\"\n",
    "        evals = [(dtrain, 'train')]\n",
    "        if dvalid is not None:\n",
    "            evals.append((dvalid, 'valid'))\n",
    "\n",
    "        # 确保使用强正则化参数\n",
    "        if 'eta' not in params:\n",
    "            params['eta'] = 0.05\n",
    "        if 'max_depth' not in params:\n",
    "            params['max_depth'] = 3\n",
    "        if 'subsample' not in params:\n",
    "            params['subsample'] = 0.6\n",
    "        if 'colsample_bytree' not in params:\n",
    "            params['colsample_bytree'] = 0.6\n",
    "\n",
    "        evals_result = {}\n",
    "        model = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            evals=evals,\n",
    "            early_stopping_rounds=30,  # 更保守的早停\n",
    "            verbose_eval=50,  # 每50轮输出一次\n",
    "            evals_result=evals_result\n",
    "        )\n",
    "\n",
    "        self.feature_names = dtrain.feature_names\n",
    "        if self.feature_names is None:\n",
    "            self.feature_names = [f'f{i}' for i in range(dtrain.num_col())]\n",
    "            model.feature_names = self.feature_names\n",
    "\n",
    "        return model, evals_result\n",
    "\n",
    "    def cross_validate(self, params, X, y, n_splits=5, cv_models_dir='cv_models', n_repeats=10):\n",
    "        \"\"\"Simplified cross-validation method\"\"\"\n",
    "        Path(cv_models_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        results = {\n",
    "            'train_rmse': [],\n",
    "            'val_rmse': [],\n",
    "            'train_r2': [],\n",
    "            'val_r2': [],\n",
    "            'best_iterations': []\n",
    "        }\n",
    "\n",
    "        print(f\"Performing {n_repeats} repeats of {n_splits}-fold cross-validation...\")\n",
    "        \n",
    "        for repeat in range(n_repeats):\n",
    "            kf = KFold(n_splits=n_splits, shuffle=True, random_state=self.seed + repeat)\n",
    "            \n",
    "            for fold, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "                X_train_fold, X_val_fold = X.iloc[train_idx], X.iloc[val_idx]\n",
    "                y_train_fold, y_val_fold = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "                # 准备DMatrix\n",
    "                dtrain_fold = xgb.DMatrix(X_train_fold, label=y_train_fold, \n",
    "                                        feature_names=X_train_fold.columns.tolist())\n",
    "                dval_fold = xgb.DMatrix(X_val_fold, label=y_val_fold,\n",
    "                                      feature_names=X_train_fold.columns.tolist())\n",
    "\n",
    "                # 训练模型\n",
    "                model, evals_result = self.train_model(params, dtrain_fold, dval_fold, num_boost_round=200)\n",
    "\n",
    "                # 预测和评估\n",
    "                train_pred = model.predict(dtrain_fold)\n",
    "                val_pred = model.predict(dval_fold)\n",
    "\n",
    "                # 记录结果\n",
    "                results['train_rmse'].append(np.sqrt(mean_squared_error(y_train_fold, train_pred)))\n",
    "                results['val_rmse'].append(np.sqrt(mean_squared_error(y_val_fold, val_pred)))\n",
    "                results['train_r2'].append(r2_score(y_train_fold, train_pred))\n",
    "                results['val_r2'].append(r2_score(y_val_fold, val_pred))\n",
    "                results['best_iterations'].append(model.best_iteration if hasattr(model, 'best_iteration') else 200)\n",
    "\n",
    "                # 保存模型\n",
    "                model_path = os.path.join(cv_models_dir, f'model_repeat_{repeat}_fold_{fold}.json')\n",
    "                model.save_model(model_path)\n",
    "\n",
    "        # 计算汇总统计\n",
    "        cv_summary = {\n",
    "            'train_rmse_mean': np.mean(results['train_rmse']),\n",
    "            'train_rmse_std': np.std(results['train_rmse']),\n",
    "            'val_rmse_mean': np.mean(results['val_rmse']),\n",
    "            'val_rmse_std': np.std(results['val_rmse']),\n",
    "            'train_r2_mean': np.mean(results['train_r2']),\n",
    "            'train_r2_std': np.std(results['train_r2']),\n",
    "            'val_r2_mean': np.mean(results['val_r2']),\n",
    "            'val_r2_std': np.std(results['val_r2']),\n",
    "            'best_iterations_mean': np.mean(results['best_iterations']),\n",
    "            'best_iterations_std': np.std(results['best_iterations']),\n",
    "            'detailed_results': pd.DataFrame({\n",
    "                'train_rmse': results['train_rmse'],\n",
    "                'val_rmse': results['val_rmse'],\n",
    "                'train_r2': results['train_r2'],\n",
    "                'val_r2': results['val_r2'],\n",
    "                'best_iteration': results['best_iterations']\n",
    "            })\n",
    "        }\n",
    "\n",
    "        print(f\"\\nCross-validation completed: {len(results['train_rmse'])} folds total\")\n",
    "        return cv_summary\n",
    "\n",
    "    def evaluate_model(self, model, dtest):\n",
    "        \"\"\"Evaluate model performance on test set\"\"\"\n",
    "        test_pred = model.predict(dtest)\n",
    "        y_true = dtest.get_label()\n",
    "        return {\n",
    "            'rmse': np.sqrt(mean_squared_error(y_true, test_pred)),\n",
    "            'r2': r2_score(y_true, test_pred),\n",
    "            'mae': mean_absolute_error(y_true, test_pred)\n",
    "        }, test_pred\n",
    "\n",
    "    def plot_learning_curves(self, evals_result, title_suffix):\n",
    "        \"\"\"Plot training and validation metrics\"\"\"\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        epochs = len(evals_result['train']['rmse'])\n",
    "        plt.plot(range(epochs), evals_result['train']['rmse'], label='Train RMSE')\n",
    "        if 'valid' in evals_result:\n",
    "            plt.plot(range(epochs), evals_result['valid']['rmse'], label='Validation RMSE')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.title(f'Learning Curves - {title_suffix}')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "    def plot_feature_importance(self, model, importance_type='weight', top_n=20):\n",
    "        \"\"\"Plot feature importance\"\"\"\n",
    "        try:\n",
    "            importance_dict = model.get_score(importance_type=importance_type)\n",
    "            \n",
    "            if not importance_dict:\n",
    "                print(\"No feature importance data available.\")\n",
    "                return None\n",
    "                \n",
    "            importance_df = pd.DataFrame({\n",
    "                'feature': list(importance_dict.keys()),\n",
    "                'importance': list(importance_dict.values())\n",
    "            }).sort_values('importance', ascending=True)\n",
    "            \n",
    "            if len(importance_df) > top_n:\n",
    "                importance_df = importance_df.tail(top_n)\n",
    "            \n",
    "            plt.figure(figsize=(10, max(6, len(importance_df) * 0.2)))\n",
    "            y_pos = np.arange(len(importance_df))\n",
    "            plt.barh(y_pos, importance_df['importance'], color='lightblue', alpha=0.8)\n",
    "            plt.yticks(y_pos, importance_df['feature'])\n",
    "            plt.xlabel('Importance')\n",
    "            plt.title(f'Feature Importance ({importance_type}) - Top {top_n}')\n",
    "            plt.grid(True, axis='x', alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            return importance_df\n",
    "        except Exception as e:\n",
    "            print(f\"Error plotting feature importance: {e}\")\n",
    "            return None\n",
    "\n",
    "    def save_results(self, model, output_dir='results'):\n",
    "        \"\"\"Save all results to disk\"\"\"\n",
    "        Path(output_dir).mkdir(exist_ok=True)\n",
    "\n",
    "        # Save model\n",
    "        model.save_model(f'{output_dir}/xgb_model.json')\n",
    "\n",
    "        # Save feature names\n",
    "        if self.feature_names is not None:\n",
    "            with open(f'{output_dir}/feature_names.txt', 'w') as f:\n",
    "                f.write('\\n'.join(self.feature_names))\n",
    "\n",
    "        # Save parameters\n",
    "        if self.best_params:\n",
    "            joblib.dump(self.best_params, f'{output_dir}/best_params.pkl')\n",
    "\n",
    "        print(f\"Results saved to: {output_dir}\")\n",
    "\n",
    "# 辅助函数\n",
    "def detect_outliers_iqr(df, columns, threshold=1.5):\n",
    "    \"\"\"Detect outliers using IQR method\"\"\"\n",
    "    outlier_indices = []\n",
    "    \n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - threshold * IQR\n",
    "            upper_bound = Q3 + threshold * IQR\n",
    "            \n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index\n",
    "            outlier_indices.extend(outliers)\n",
    "            \n",
    "            if len(outliers) > 0:\n",
    "                print(f\"  {col}: Found {len(outliers)} outliers \"\n",
    "                      f\"({len(outliers)/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    return list(set(outlier_indices))\n",
    "\n",
    "def remove_outliers_robust(df, y, columns, method='iqr', threshold=2.0):\n",
    "    \"\"\"Robust outlier handling method\"\"\"\n",
    "    print(\"Starting outlier detection...\")\n",
    "    \n",
    "    if method == 'iqr':\n",
    "        outlier_indices = detect_outliers_iqr(df, columns, threshold)\n",
    "    elif method == 'zscore':\n",
    "        # Z-score method\n",
    "        z_scores = np.abs(stats.zscore(df[columns]))\n",
    "        outlier_indices = np.where(z_scores > threshold)[0]\n",
    "        outlier_indices = list(outlier_indices)\n",
    "    else:\n",
    "        return df, y, []\n",
    "    \n",
    "    print(f\"\\nTotal outliers found: {len(outlier_indices)}\")\n",
    "    \n",
    "    if len(outlier_indices) > 0:\n",
    "        df_clean = df.drop(outlier_indices)\n",
    "        y_clean = y.drop(outlier_indices)\n",
    "        print(f\"Data size after removing outliers: {len(df_clean)} (removed {len(outlier_indices)} samples)\")\n",
    "        return df_clean, y_clean, outlier_indices\n",
    "    \n",
    "    print(\"No outliers found\")\n",
    "    return df, y, []\n",
    "\n",
    "def check_data_leakage(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Check for data leakage\"\"\"\n",
    "    print(\"\\n=== Data Leakage Check ===\")\n",
    "    \n",
    "    # Check for overlap between train and test sets\n",
    "    train_indices = set(X_train.index)\n",
    "    test_indices = set(X_test.index)\n",
    "    overlap = train_indices.intersection(test_indices)\n",
    "    \n",
    "    if overlap:\n",
    "        print(f\"❌ Data leakage detected: {len(overlap)} overlapping samples between train and test sets\")\n",
    "    else:\n",
    "        print(\"✅ No overlap between train and test sets\")\n",
    "    \n",
    "    # Check feature distributions\n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Test set size: {len(X_test)}\")\n",
    "    print(f\"Number of features: {X_train.shape[1]}\")\n",
    "    \n",
    "    return len(overlap) == 0\n",
    "\n",
    "def safe_feature_engineering_simple(X_train, X_test):\n",
    "    \"\"\"Minimal feature engineering to avoid overfitting\"\"\"\n",
    "    print(\"Performing minimal feature engineering...\")\n",
    "    \n",
    "    # 只做最基本的转换\n",
    "    columns_to_log = []\n",
    "    for col in ['BD', 'Age']:\n",
    "        if col in X_train.columns:\n",
    "            X_train[col + '_log'] = np.log(X_train[col] + 1e-8)\n",
    "            X_test[col + '_log'] = np.log(X_test[col] + 1e-8)\n",
    "            print(f\"  Created log feature: {col}_log\")\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "def augment_continuous_features(X, y, continuous_cols, augmentation_factor=1.0, noise_scale=0.002, random_state=42):\n",
    "    \"\"\"\n",
    "    Reduced augmentation with proper index resetting\n",
    "    \"\"\"\n",
    "    if augmentation_factor <= 0:\n",
    "        return X, y\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Reset indices\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    \n",
    "    n_samples = len(X)\n",
    "    n_augment = int(n_samples * augmentation_factor)\n",
    "\n",
    "    if n_augment == 0:\n",
    "        return X, y\n",
    "\n",
    "    augmented_X_list = []\n",
    "    augmented_y_list = []\n",
    "\n",
    "    for _ in range(n_augment):\n",
    "        idx = np.random.randint(0, n_samples)\n",
    "        base_sample = X.iloc[idx].copy()\n",
    "        \n",
    "        # Add minimal noise to specified continuous columns\n",
    "        for col in continuous_cols:\n",
    "            if col in base_sample:\n",
    "                std = X[col].std()\n",
    "                noise = np.random.normal(loc=0, scale=std * noise_scale)\n",
    "                base_sample[col] += noise\n",
    "\n",
    "        augmented_X_list.append(base_sample)\n",
    "        augmented_y_list.append(y.iloc[idx])\n",
    "\n",
    "    # Combine data\n",
    "    X_augmented = pd.concat([X, pd.DataFrame(augmented_X_list)], ignore_index=True)\n",
    "    y_augmented = pd.concat([y, pd.Series(augmented_y_list)], ignore_index=True)\n",
    "\n",
    "    return X_augmented, y_augmented\n",
    "\n",
    "def enhanced_load_and_prepare_data(augment=True, augmentation_factor=1.5, \n",
    "                                 lu_type_importance_boost=1.0,\n",
    "                                 outlier_threshold=2.0,\n",
    "                                 use_simple_features=True):\n",
    "    \"\"\"Data loading with overfitting prevention\"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    dtype_dict = {\n",
    "        'Soillayer': 'int8',\n",
    "        'yi': 'float32'\n",
    "    }\n",
    "\n",
    "    df_clean = pd.read_csv('F:/model/df.clean.yi.csv', dtype=dtype_dict)\n",
    "    data_predictor_VIF = pd.read_csv('F:/model/data.predictor.VIF.yi.csv')\n",
    "\n",
    "    # Select target soil layer\n",
    "    target_layer = \"subsoil\"\n",
    "    df = df_clean[df_clean['Soillayer'] == (1 if target_layer == 'topsoil' else 2)].copy()\n",
    "\n",
    "    # Select features\n",
    "    predictor_columns = data_predictor_VIF['x'].tolist()\n",
    "    valid_x_cols = [col for col in predictor_columns if col != \"Soillayer\" and col in df.columns]\n",
    "    \n",
    "    # 如果是简单特征模式，只保留原始特征\n",
    "    if use_simple_features:\n",
    "        print(\"Using simple feature set (no engineered features)\")\n",
    "        valid_x_cols = [col for col in valid_x_cols if '_log' not in col and '_bins' not in col \n",
    "                       and 'boost' not in col and 'interaction' not in col and 'squared' not in col]\n",
    "\n",
    "    # Data cleaning\n",
    "    for col in valid_x_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    X = df[valid_x_cols].astype('float32').fillna(0)\n",
    "    y = df['yi'].astype('float32')\n",
    "\n",
    "    print(f\"Original data size: {len(X)}\")\n",
    "    print(f\"Number of features: {len(X.columns)}\")\n",
    "    \n",
    "    # Outlier detection and handling\n",
    "    continuous_cols = ['Lon', 'Lat', 'Age', 'BD', 'pH', 'Altitude']\n",
    "    continuous_cols = [col for col in continuous_cols if col in X.columns]\n",
    "    \n",
    "    print(\"\\n=== Outlier Handling ===\")\n",
    "    X_clean, y_clean, outliers = remove_outliers_robust(\n",
    "        X, y, continuous_cols, threshold=outlier_threshold\n",
    "    )\n",
    "\n",
    "    # Data splitting\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_clean, y_clean, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # 可选：简化的特征工程\n",
    "    if not use_simple_features:\n",
    "        X_train, X_test = safe_feature_engineering_simple(X_train, X_test)\n",
    "    \n",
    "    # Data leakage check\n",
    "    check_data_leakage(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # 简化LUtype处理\n",
    "    if 'LUtype' in X_train.columns and not use_simple_features:\n",
    "        print(f\"\\n=== Simple LUtype Feature Enhancement ===\")\n",
    "        print(f\"Original LUtype distribution:\")\n",
    "        print(X_train['LUtype'].value_counts().sort_index())\n",
    "        \n",
    "        # 只创建一个副本，而不是多个\n",
    "        X_train['LUtype_copy'] = X_train['LUtype']\n",
    "        X_test['LUtype_copy'] = X_test['LUtype']\n",
    "        print(\"  Created single LUtype copy\")\n",
    "    \n",
    "    # 减少数据增强\n",
    "    if augment and not use_simple_features:\n",
    "        continuous_cols = [\n",
    "            'Lon', 'Lat', 'Age', 'BD', 'pH', 'Altitude'\n",
    "        ]\n",
    "        continuous_cols = [col for col in continuous_cols if col in X_train.columns]\n",
    "        \n",
    "        print(f\"\\n=== Reduced Data Augmentation ===\")\n",
    "        print(f\"Training set size before augmentation: {len(X_train)}\")\n",
    "        X_train, y_train = augment_continuous_features(\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            continuous_cols=continuous_cols,\n",
    "            augmentation_factor=augmentation_factor,\n",
    "            noise_scale=0.002,\n",
    "            random_state=42\n",
    "        )\n",
    "        print(f\"Training set size after augmentation: {len(X_train)}\")\n",
    "    elif augment and use_simple_features:\n",
    "        print(\"\\nSkipping data augmentation for simple feature mode\")\n",
    "\n",
    "    print(f\"\\n=== Final Dataset Statistics ===\")\n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Test set size: {len(X_test)}\")\n",
    "    print(f\"Total number of features: {len(X_train.columns)}\")\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=X_train.columns.tolist())\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test, feature_names=X_train.columns.tolist())\n",
    "\n",
    "    return dtrain, dtest, X, y, X_test, y_test, X_train, y_train\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function with overfitting prevention\"\"\"\n",
    "    outlier_threshold = 1.5  # 更宽松的异常值阈值\n",
    "    \n",
    "    print(\"=== Starting XGBoost Modeling with Overfitting Prevention ===\")\n",
    "    \n",
    "    # 尝试两种模式：简单特征和增强特征\n",
    "    for mode in ['simple', 'enhanced']:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Running in {mode.upper()} mode\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        use_simple = (mode == 'simple')\n",
    "        \n",
    "        # 加载数据\n",
    "        dtrain, dtest, x1, y1, X_test, y_test, X_train, y_train = enhanced_load_and_prepare_data(\n",
    "            augment=(mode == 'enhanced'),\n",
    "            augmentation_factor=1.5 if mode == 'enhanced' else 0,\n",
    "            lu_type_importance_boost=1.0 if use_simple else 2.0,\n",
    "            outlier_threshold=outlier_threshold,\n",
    "            use_simple_features=use_simple\n",
    "        )\n",
    "\n",
    "        tuner = XGBoostTuner(seed=42, n_jobs=17)\n",
    "\n",
    "        # 1. Hyperparameter tuning\n",
    "        print(\"\\n=== Starting Hyperparameter Tuning ===\")\n",
    "        best_params = tuner.tune_hyperparameters(dtrain, n_trials=30)\n",
    "        print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "        # 2. Cross-validation\n",
    "        print(\"\\n=== Starting 5x5 Cross-Validation ===\")\n",
    "        cv_results_summary = tuner.cross_validate(best_params, X_train, y_train, n_splits=5,\n",
    "                                                  cv_models_dir=f'F:/model/results/cv_models_{mode}',\n",
    "                                                  n_repeats=10)\n",
    "        \n",
    "        # 分析过拟合程度\n",
    "        train_val_gap = cv_results_summary['val_rmse_mean'] - cv_results_summary['train_rmse_mean']\n",
    "        overfitting_ratio = train_val_gap / cv_results_summary['train_rmse_mean']\n",
    "        \n",
    "        print(f\"\\n=== Overfitting Analysis ===\")\n",
    "        print(f\"Train RMSE: {cv_results_summary['train_rmse_mean']:.4f} (±{cv_results_summary['train_rmse_std']:.4f})\")\n",
    "        print(f\"Val RMSE: {cv_results_summary['val_rmse_mean']:.4f} (±{cv_results_summary['val_rmse_std']:.4f})\")\n",
    "        print(f\"Train-Val RMSE gap: {train_val_gap:.4f}\")\n",
    "        print(f\"Overfitting ratio: {overfitting_ratio:.2%}\")\n",
    "        \n",
    "        if overfitting_ratio > 0.3:\n",
    "            print(\"⚠️  Warning: Significant overfitting detected!\")\n",
    "        \n",
    "        # 3. Train final model\n",
    "        optimal_rounds = max(50, int(cv_results_summary['best_iterations_mean'] * 0.8))\n",
    "        print(f\"\\nTraining final model with {optimal_rounds} rounds...\")\n",
    "        final_model, evals_result = tuner.train_model(best_params, dtrain, num_boost_round=optimal_rounds)\n",
    "\n",
    "        # 4. Evaluate\n",
    "        print(\"\\nEvaluating final model...\")\n",
    "        test_metrics, _ = tuner.evaluate_model(final_model, dtest)\n",
    "        \n",
    "        print(f\"\\n=== Results for {mode.upper()} mode ===\")\n",
    "        print(f\"CV Train RMSE: {cv_results_summary['train_rmse_mean']:.4f}\")\n",
    "        print(f\"CV Val RMSE: {cv_results_summary['val_rmse_mean']:.4f}\")\n",
    "        print(f\"Test RMSE: {test_metrics['rmse']:.4f}\")\n",
    "        print(f\"Test R²: {test_metrics['r2']:.4f}\")\n",
    "        print(f\"Generalization gap (Test - CV Val): {test_metrics['rmse'] - cv_results_summary['val_rmse_mean']:.4f}\")\n",
    "        \n",
    "        # 保存结果\n",
    "        output_dir = f'F:/model/results/{mode}'\n",
    "        tuner.save_results(final_model, output_dir)\n",
    "        \n",
    "        # 绘制特征重要性\n",
    "        print(\"\\nPlotting feature importance...\")\n",
    "        importance_df = tuner.plot_feature_importance(final_model, top_n=20)\n",
    "        \n",
    "        # 分析特征\n",
    "        if importance_df is not None:\n",
    "            print(f\"\\nTop 5 most important features:\")\n",
    "            top_features = importance_df.sort_values('importance', ascending=False).head(5)\n",
    "            for idx, row in top_features.iterrows():\n",
    "                print(f\"  {row['feature']}: {row['importance']:.4f}\")\n",
    "        \n",
    "        print(f\"\\nCompleted {mode.upper()} mode\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    print(\"=== All modes completed ===\")\n",
    "    print(\"\\nRecommendation:\")\n",
    "    print(\"1. Compare the results from both modes\")\n",
    "    print(\"2. Choose the model with better generalization (smaller Test-CV gap)\")\n",
    "    print(\"3. Consider using simpler model if overfitting is severe\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e62c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost modeling: passive fractions  in topsoil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import builtins\n",
    "from scipy import stats\n",
    "open = builtins.open\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# SHAP availability check\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SHAP_AVAILABLE = False\n",
    "\n",
    "class XGBoostTuner:\n",
    "    def __init__(self, seed=42, n_jobs=-1):\n",
    "        self.seed = seed\n",
    "        self.n_jobs = n_jobs if n_jobs != -1 else None\n",
    "        self.study = None\n",
    "        self.best_model = None\n",
    "        self.best_params = None\n",
    "        self.feature_names = None  # Store feature names\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_numeric_value(value):\n",
    "        \"\"\"Convert string values to numeric, handling special cases\"\"\"\n",
    "        if pd.isna(value):\n",
    "            return np.nan\n",
    "        if isinstance(value, str):\n",
    "            # Remove any non-numeric characters except minus, decimal point\n",
    "            cleaned = re.sub(r'[^\\d.-]', '', value)\n",
    "            try:\n",
    "                return float(cleaned) if cleaned else np.nan\n",
    "            except ValueError:\n",
    "                return np.nan\n",
    "        return float(value)\n",
    "\n",
    "    def objective(self, trial, dtrain, num_boost_round=500):\n",
    "        \"\"\"Objective function with enhanced regularization\"\"\"\n",
    "        params = {\n",
    "            'eta': trial.suggest_float('eta', 0.005, 0.1, log=True),  # Lower learning rate\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 4),  # Shallower trees\n",
    "            'subsample': trial.suggest_float('subsample', 0.4, 0.7),  # Lower subsampling\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 0.7),  # Lower feature sampling\n",
    "           # 'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.4, 0.7),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 10, 20),  # Higher min child weight\n",
    "            'lambda': trial.suggest_float('lambda', 10, 25.0),  # Stronger L2 regularization\n",
    "            'alpha': trial.suggest_float('alpha', 5.0, 15.0),  # Stronger L1 regularization\n",
    "            'gamma': trial.suggest_float('gamma', 0.5, 2.0),  # Higher pruning parameter\n",
    "            'max_delta_step': trial.suggest_int('max_delta_step', 0, 1),\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'verbosity': 0,\n",
    "            'seed': self.seed,\n",
    "            'nthread': 1\n",
    "        }\n",
    "\n",
    "        cv_results = xgb.cv(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=800,  # More rounds but more conservative early stopping\n",
    "            nfold=5,\n",
    "            metrics='rmse',\n",
    "            early_stopping_rounds=25,  # More conservative early stopping\n",
    "            as_pandas=True,\n",
    "            seed=self.seed,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        # Stronger overfitting penalty\n",
    "        train_rmse = cv_results['train-rmse-mean'].iloc[-1]\n",
    "        val_rmse = cv_results['test-rmse-mean'].iloc[-1]\n",
    "        \n",
    "        # Calculate overfitting degree\n",
    "        overfitting_ratio = (train_rmse - val_rmse) / train_rmse\n",
    "        gap_penalty = max(0, overfitting_ratio) * 0.3  # Stronger penalty\n",
    "        \n",
    "        # Add extra penalty if severe overfitting\n",
    "        if overfitting_ratio > 0.1:\n",
    "            gap_penalty += (overfitting_ratio - 0.1) * 0.5\n",
    "            \n",
    "        return val_rmse + gap_penalty\n",
    "    \n",
    "    def tune_hyperparameters(self, dtrain, n_trials=10):  # Increased number of trials\n",
    "        \"\"\"Hyperparameter tuning focused on generalization\"\"\"\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        \n",
    "        print(\"Tuning hyperparameters with aggressive overfitting prevention...\")\n",
    "        print(\"Using very strong regularization and shallow trees\")\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=self.n_jobs) as executor:\n",
    "            futures = [executor.submit(lambda: study.optimize(\n",
    "                lambda trial: self.objective(trial, dtrain),\n",
    "                n_trials=5,\n",
    "                n_jobs=1\n",
    "            )) for _ in range(n_trials//5)]\n",
    "\n",
    "            for future in futures:\n",
    "                future.result()\n",
    "\n",
    "        self.study = study\n",
    "        self.best_params = study.best_params\n",
    "        self.best_params.update({\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'seed': self.seed,\n",
    "            'nthread': self.n_jobs\n",
    "        })\n",
    "\n",
    "        print(f\"Best parameters found: {self.best_params}\")\n",
    "        return self.best_params\n",
    "\n",
    "\n",
    "    def train_model(self, params, dtrain, dvalid=None, num_boost_round=500):\n",
    "        \"\"\"Train model with focus on preventing overfitting\"\"\"\n",
    "        evals = [(dtrain, 'train')]\n",
    "        if dvalid is not None:\n",
    "            evals.append((dvalid, 'valid'))\n",
    "\n",
    "        evals_result = {}\n",
    "        model = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            evals=evals,\n",
    "            early_stopping_rounds=25,  # More conservative early stopping\n",
    "            verbose_eval=100,  # Reduced output frequency\n",
    "            evals_result=evals_result\n",
    "        )\n",
    "\n",
    "        self.feature_names = dtrain.feature_names\n",
    "        if self.feature_names is None:\n",
    "            self.feature_names = [f'f{i}' for i in range(dtrain.num_col())]\n",
    "            model.feature_names = self.feature_names\n",
    "\n",
    "        return model, evals_result\n",
    "\n",
    "    def cross_validate(self, params, X, y, n_splits=5, cv_models_dir='cv_models', n_repeats=10): \n",
    "        \"\"\"Enhanced CV with 10 repetitions of 5-fold cross-validation and model saving\"\"\"\n",
    "        Path(cv_models_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        all_cv_results = {\n",
    "            'train_rmse': [], 'val_rmse': [],\n",
    "            'train_r2': [], 'val_r2': [],\n",
    "            'best_iterations': [],\n",
    "            'model_paths': [],\n",
    "            'feature_names': [],\n",
    "            'repeat': [],\n",
    "            'fold': []\n",
    "        }\n",
    "\n",
    "        def process_fold(repeat_idx, fold_idx, train_idx, val_idx):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=X_train.columns.tolist())\n",
    "            dval = xgb.DMatrix(X_val, label=y_val, feature_names=X_train.columns.tolist())\n",
    "\n",
    "            model, _ = self.train_model(params, dtrain, dval)\n",
    "\n",
    "            # Save the CV model\n",
    "            model_path = os.path.join(cv_models_dir, f'cv_model_repeat_{repeat_idx}_fold_{fold_idx}.json')\n",
    "            model.save_model(model_path)\n",
    "\n",
    "            train_pred = model.predict(dtrain)\n",
    "            val_pred = model.predict(dval)\n",
    "\n",
    "            return (\n",
    "                np.sqrt(mean_squared_error(y_train, train_pred)),\n",
    "                np.sqrt(mean_squared_error(y_val, val_pred)),\n",
    "                r2_score(y_train, train_pred),\n",
    "                r2_score(y_val, val_pred),\n",
    "                model.best_iteration if hasattr(model, 'best_iteration') else params.get('num_boost_round', 500),\n",
    "                model_path,\n",
    "                model.feature_names,\n",
    "                repeat_idx,\n",
    "                fold_idx\n",
    "            )\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=self.n_jobs) as executor:\n",
    "            futures = []\n",
    "            for repeat_idx in range(n_repeats):\n",
    "                kf = KFold(n_splits=n_splits, shuffle=True, random_state=self.seed + repeat_idx)\n",
    "                for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "                    futures.append(executor.submit(\n",
    "                        process_fold, repeat_idx, fold_idx, train_idx, val_idx\n",
    "                    ))\n",
    "\n",
    "            for future in futures:\n",
    "                train_rmse, val_rmse, train_r2, val_r2, best_iter, model_path, feature_names, repeat_idx, fold_idx = future.result()\n",
    "                all_cv_results['train_rmse'].append(train_rmse)\n",
    "                all_cv_results['val_rmse'].append(val_rmse)\n",
    "                all_cv_results['train_r2'].append(train_r2)\n",
    "                all_cv_results['val_r2'].append(val_r2)\n",
    "                all_cv_results['best_iterations'].append(best_iter)\n",
    "                all_cv_results['model_paths'].append(model_path)\n",
    "                all_cv_results['feature_names'].append(feature_names)\n",
    "                all_cv_results['repeat'].append(repeat_idx)\n",
    "                all_cv_results['fold'].append(fold_idx)\n",
    "        # Create summary statistics\n",
    "        cv_results_summary = {\n",
    "            'train_rmse_mean': np.mean(all_cv_results['train_rmse']),\n",
    "            'train_rmse_std': np.std(all_cv_results['train_rmse']),\n",
    "            'val_rmse_mean': np.mean(all_cv_results['val_rmse']),\n",
    "            'val_rmse_std': np.std(all_cv_results['val_rmse']),\n",
    "            'train_r2_mean': np.mean(all_cv_results['train_r2']),\n",
    "            'train_r2_std': np.std(all_cv_results['train_r2']),\n",
    "            'val_r2_mean': np.mean(all_cv_results['val_r2']),\n",
    "            'val_r2_std': np.std(all_cv_results['val_r2']),\n",
    "            'best_iterations_mean': np.mean(all_cv_results['best_iterations']),\n",
    "            'best_iterations_std': np.std(all_cv_results['best_iterations']),\n",
    "            'detailed_results': pd.DataFrame(all_cv_results)\n",
    "        }\n",
    "\n",
    "        return cv_results_summary\n",
    "\n",
    "    def evaluate_model(self, model, dtest):\n",
    "        \"\"\"Evaluate model performance on test set\"\"\"\n",
    "        test_pred = model.predict(dtest)\n",
    "        return {\n",
    "            'rmse': np.sqrt(mean_squared_error(dtest.get_label(), test_pred)),\n",
    "            'r2': r2_score(dtest.get_label(), test_pred),\n",
    "            'mae': mean_absolute_error(dtest.get_label(), test_pred)\n",
    "        }, test_pred\n",
    "\n",
    "    def plot_learning_curves(self, evals_result, title_suffix):\n",
    "        \"\"\"Plot training and validation metrics\"\"\"\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        epochs = len(evals_result['train']['rmse'])\n",
    "        plt.plot(range(epochs), evals_result['train']['rmse'], label='Train RMSE')\n",
    "        if 'valid' in evals_result:\n",
    "            plt.plot(range(epochs), evals_result['valid']['rmse'], label='Validation RMSE')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.title(f'Learning Curves - {title_suffix}')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_cv_results(self, cv_results_summary):\n",
    "        \"\"\"Plot enhanced cross-validation results with both original and new visualization\"\"\"\n",
    "        # Check if it's the new summary format or old list format\n",
    "        if isinstance(cv_results_summary, dict) and 'detailed_results' in cv_results_summary:\n",
    "            # New format - use the detailed results\n",
    "            detailed_results = cv_results_summary['detailed_results']\n",
    "            \n",
    "            # Create two visualizations:\n",
    "            # 1. Original visualization (simple line plot for first repeat)\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            \n",
    "            # Plot 1: Original style - first repeat only\n",
    "            plt.subplot(2, 2, 1)\n",
    "            first_repeat = detailed_results[detailed_results['repeat'] == 0]\n",
    "            plt.plot(first_repeat['train_rmse'], 'o-', label='Train RMSE')\n",
    "            plt.plot(first_repeat['val_rmse'], 'o-', label='Validation RMSE')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.title('Cross-Validation RMSE (First Repeat)')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Plot 2: Original style - first repeat R²\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.plot(first_repeat['train_r2'], 'o-', label='Train R²')\n",
    "            plt.plot(first_repeat['val_r2'], 'o-', label='Validation R²')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('R² Score')\n",
    "            plt.title('Cross-Validation R² Scores (First Repeat)')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Plot 3: New visualization - RMSE distribution across all repeats\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.boxplot([detailed_results['train_rmse'], detailed_results['val_rmse']], \n",
    "                       labels=['Train RMSE', 'Validation RMSE'])\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.title('RMSE Distribution across 10x5 CV')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Plot 4: New visualization - R² distribution across all repeats\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.boxplot([detailed_results['train_r2'], detailed_results['val_r2']], \n",
    "                       labels=['Train R²', 'Validation R²'])\n",
    "            plt.ylabel('R² Score')\n",
    "            plt.title('R² Distribution across 10x5 CV')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Print summary statistics\n",
    "            print(\"\\n=== 10x5 Cross-Validation Summary ===\")\n",
    "            print(f\"Average Train RMSE: {cv_results_summary['train_rmse_mean']:.4f} (±{cv_results_summary['train_rmse_std']:.4f})\")\n",
    "            print(f\"Average Validation RMSE: {cv_results_summary['val_rmse_mean']:.4f} (±{cv_results_summary['val_rmse_std']:.4f})\")\n",
    "            print(f\"Average Train R²: {cv_results_summary['train_r2_mean']:.4f} (±{cv_results_summary['train_r2_std']:.4f})\")\n",
    "            print(f\"Average Validation R²: {cv_results_summary['val_r2_mean']:.4f} (±{cv_results_summary['val_r2_std']:.4f})\")\n",
    "            print(f\"Average Best Iterations: {cv_results_summary['best_iterations_mean']:.1f} (±{cv_results_summary['best_iterations_std']:.1f})\")\n",
    "            \n",
    "            # Also print the format that main() expects\n",
    "            print(\"\\n=== 交叉验证结果 (旧格式兼容) ===\")\n",
    "            print(f\"平均训练RMSE: {cv_results_summary['train_rmse_mean']:.4f} (±{cv_results_summary['train_rmse_std']:.4f})\")\n",
    "            print(f\"平均验证RMSE: {cv_results_summary['val_rmse_mean']:.4f} (±{cv_results_summary['val_rmse_std']:.4f})\")\n",
    "            print(f\"平均训练R²: {cv_results_summary['train_r2_mean']:.4f} (±{cv_results_summary['train_r2_std']:.4f})\")\n",
    "            print(f\"平均验证R²: {cv_results_summary['val_r2_mean']:.4f} (±{cv_results_summary['val_r2_std']:.4f})\")\n",
    "            \n",
    "        else:\n",
    "            # Old format - keep original plotting\n",
    "            plt.figure(figsize=(15, 5))\n",
    "\n",
    "            # Plot RMSE\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(cv_results_summary['train_rmse'], 'o-', label='Train RMSE')\n",
    "            plt.plot(cv_results_summary['val_rmse'], 'o-', label='Validation RMSE')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.title('Cross-Validation RMSE')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Plot R2\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(cv_results_summary['train_r2'], 'o-', label='Train R²')\n",
    "            plt.plot(cv_results_summary['val_r2'], 'o-', label='Validation R²')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('R² Score')\n",
    "            plt.title('Cross-Validation R² Scores')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def plot_final_model_performance(self, model, dtest):\n",
    "        \"\"\"Plot actual vs predicted values for test set\"\"\"\n",
    "        test_metrics, test_pred = self.evaluate_model(model, dtest)\n",
    "        y_test = dtest.get_label()\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        # Scatter plot of actual vs predicted\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(y_test, test_pred, alpha=0.5)\n",
    "        plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--r')\n",
    "        plt.xlabel('Actual Values')\n",
    "        plt.ylabel('Predicted Values')\n",
    "        plt.title(f'Actual vs Predicted (R² = {test_metrics[\"r2\"]:.3f})')\n",
    "\n",
    "        # Residual plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        residuals = y_test - test_pred\n",
    "        plt.scatter(test_pred, residuals, alpha=0.5)\n",
    "        plt.axhline(y=0, color='r', linestyle='--')\n",
    "        plt.xlabel('Predicted Values')\n",
    "        plt.ylabel('Residuals')\n",
    "        plt.title('Residual Plot')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_feature_importance(self, model, importance_type='weight', top_n=30):\n",
    "        \"\"\"Plot feature importance without category-specific highlighting\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "    \n",
    "        importance_dict = model.get_score(importance_type=importance_type)\n",
    "        \n",
    "        if not importance_dict:\n",
    "            print(\"No feature importance data available.\")\n",
    "            return None\n",
    "            \n",
    "\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': list(importance_dict.keys()),\n",
    "            'importance': list(importance_dict.values())\n",
    "        }).sort_values('importance', ascending=True)\n",
    "        \n",
    "\n",
    "        if len(importance_df) > top_n:\n",
    "            importance_df = importance_df.tail(top_n)\n",
    "        \n",
    "\n",
    "        y_pos = np.arange(len(importance_df))\n",
    "        colors = ['lightblue'] * len(importance_df)\n",
    "        \n",
    "        ax.barh(y_pos, importance_df['importance'], color=colors, alpha=0.8)\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(importance_df['feature'])\n",
    "        ax.set_xlabel('Importance')\n",
    "        \n",
    "        title = f'Feature Importance ({importance_type})'\n",
    "        ax.set_title(title)\n",
    "        \n",
    "\n",
    "        lu_type_features = importance_df[importance_df['feature'].str.contains('LUtype', na=False)]\n",
    "        lu_type_importance = lu_type_features['importance'].sum() if not lu_type_features.empty else 0\n",
    "        \n",
    "        ax.text(0.7, 0.95, f'LUtype total: {lu_type_importance:.3f}', \n",
    "                transform=ax.transAxes, fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\"))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return importance_df\n",
    "\n",
    "    def analyze_lutype_importance(self, model, X):\n",
    "     \n",
    "        importance_dict = model.get_score(importance_type='weight')\n",
    "        \n",
    "        if not importance_dict:\n",
    "            print(\"No feature importance data available.\")\n",
    "            return\n",
    "            \n",
    "\n",
    "        lutype_features = {k: v for k, v in importance_dict.items() if 'LUtype' in k}\n",
    "        other_features = {k: v for k, v in importance_dict.items() if 'LUtype' not in k}\n",
    "        \n",
    "        print(f\"\\n=== LUtype Feature Importance Analysis ===\")\n",
    "        print(f\"Total LUtype-related features: {len(lutype_features)}\")\n",
    "        print(f\"Total importance of LUtype features: {sum(lutype_features.values()):.3f}\")\n",
    "        print(f\"Average importance of LUtype features: {np.mean(list(lutype_features.values())) if lutype_features else 0:.3f}\")\n",
    "        \n",
    "        total_importance = sum(importance_dict.values())\n",
    "        lu_type_percentage = (sum(lutype_features.values()) / total_importance * 100) if total_importance > 0 else 0\n",
    "        \n",
    "        print(f\"\\nLUtype importance percentage: {lu_type_percentage:.2f}%\")\n",
    "        \n",
    "     \n",
    "        if lutype_features:\n",
    "            sorted_lutype = sorted(lutype_features.items(), key=lambda x: x[1], reverse=True)\n",
    "            print(f\"\\nTop LUtype-related features:\")\n",
    "            for feature, importance in sorted_lutype[:10]:\n",
    "                print(f\"  {feature}: {importance:.4f}\")\n",
    "        else:\n",
    "            print(\"\\nNo LUtype-related features found in importance scores.\")\n",
    "\n",
    "    def plot_shap_summary(self, model, X, feature_names=None):\n",
    "        \"\"\"Generate SHAP summary plot if SHAP is available\"\"\"\n",
    "        if SHAP_AVAILABLE:\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(X)\n",
    "\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            shap.summary_plot(shap_values, X, feature_names=feature_names)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"SHAP not available. Install with: pip install shap\")\n",
    "\n",
    "    def save_results(self, model, output_dir='results'):\n",
    "        \"\"\"Save all results to disk including feature names\"\"\"\n",
    "        Path(output_dir).mkdir(exist_ok=True)\n",
    "\n",
    "        # Save model\n",
    "        model.save_model(f'{output_dir}/xgb_model.json')\n",
    "\n",
    "        # Save feature names\n",
    "        if self.feature_names is not None:\n",
    "            with open(f'{output_dir}/feature_names.txt', 'w') as f:\n",
    "                f.write('\\n'.join(self.feature_names))\n",
    "\n",
    "        # Save other artifacts\n",
    "        joblib.dump(self.best_params, f'{output_dir}/best_params.pkl')\n",
    "\n",
    "        if self.study:\n",
    "            joblib.dump(self.study, f'{output_dir}/study.pkl')\n",
    "            study_df = self.study.trials_dataframe()\n",
    "            study_df.to_csv(f'{output_dir}/trials.csv', index=False)\n",
    "\n",
    "def detect_outliers_iqr(df, columns, threshold=1.5):\n",
    "    \"\"\"Detect outliers using IQR method\"\"\"\n",
    "    outlier_indices = []\n",
    "    \n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - threshold * IQR\n",
    "            upper_bound = Q3 + threshold * IQR\n",
    "            \n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index\n",
    "            outlier_indices.extend(outliers)\n",
    "            \n",
    "            if len(outliers) > 0:\n",
    "                print(f\"  {col}: Found {len(outliers)} outliers \"\n",
    "                      f\"({len(outliers)/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    return list(set(outlier_indices))\n",
    "\n",
    "def remove_outliers_robust(df, y, columns, method='iqr', threshold=2.0):\n",
    "    \"\"\"Robust outlier handling method\"\"\"\n",
    "    print(\"Starting outlier detection...\")\n",
    "    \n",
    "    if method == 'iqr':\n",
    "        outlier_indices = detect_outliers_iqr(df, columns, threshold)\n",
    "    elif method == 'zscore':\n",
    "        # Z-score method\n",
    "        z_scores = np.abs(stats.zscore(df[columns]))\n",
    "        outlier_indices = np.where(z_scores > threshold)[0]\n",
    "        outlier_indices = list(outlier_indices)\n",
    "    else:\n",
    "        return df, y, []\n",
    "    \n",
    "    print(f\"\\nTotal outliers found: {len(outlier_indices)}\")\n",
    "    \n",
    "    if len(outlier_indices) > 0:\n",
    "        df_clean = df.drop(outlier_indices)\n",
    "        y_clean = y.drop(outlier_indices)\n",
    "        print(f\"Data size after removing outliers: {len(df_clean)} (removed {len(outlier_indices)} samples)\")\n",
    "        return df_clean, y_clean, outlier_indices\n",
    "    \n",
    "    print(\"No outliers found\")\n",
    "    return df, y, []\n",
    "\n",
    "def check_data_leakage(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Check for data leakage\"\"\"\n",
    "    print(\"\\n=== Data Leakage Check ===\")\n",
    "    \n",
    "    # Check for overlap between train and test sets\n",
    "    train_indices = set(X_train.index)\n",
    "    test_indices = set(X_test.index)\n",
    "    overlap = train_indices.intersection(test_indices)\n",
    "    \n",
    "    if overlap:\n",
    "        print(f\"❌ Data leakage detected: {len(overlap)} overlapping samples between train and test sets\")\n",
    "    else:\n",
    "        print(\"✅ No overlap between train and test sets\")\n",
    "    \n",
    "    # Check feature distributions\n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Test set size: {len(X_test)}\")\n",
    "    print(f\"Number of features: {X_train.shape[1]}\")\n",
    "    \n",
    "    return len(overlap) == 0\n",
    "\n",
    "def safe_feature_engineering(X_train, X_test):\n",
    "    \"\"\"Safe feature engineering to avoid data leakage\"\"\"\n",
    "    print(\"Performing safe feature engineering...\")\n",
    "    \n",
    "    # 1. Logarithmic transformation\n",
    "    columns_to_log = ['Lon', 'Lat', 'Age', 'BD', 'pH']\n",
    "    for col in columns_to_log:\n",
    "        if col in X_train.columns:\n",
    "            X_train[col + '_log'] = np.log(X_train[col] + 1e-8)\n",
    "            X_test[col + '_log'] = np.log(X_test[col] + 1e-8)\n",
    "            print(f\"  Created log feature: {col}_log\")\n",
    "    \n",
    "    # 2. Binning (based on training set quantiles)\n",
    "    if 'Altitude' in X_train.columns:\n",
    "        # Use training set to compute bin boundaries\n",
    "        alt_bins = pd.cut(X_train['Altitude'], bins=5, retbins=True)[1]\n",
    "        X_train['Altitude_bins'] = pd.cut(X_train['Altitude'], bins=alt_bins, labels=False)\n",
    "        X_test['Altitude_bins'] = pd.cut(X_test['Altitude'], bins=alt_bins, labels=False)\n",
    "        print(\"  Created binned feature: Altitude_bins\")\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "def augment_continuous_features(X, y, continuous_cols, augmentation_factor=2, noise_scale=0.01, random_state=42):\n",
    "    \"\"\"\n",
    "    Augment continuous features with noise - with proper index resetting \n",
    "    to prevent alignment issues during training/evaluation.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Reset indices to ensure positional indexing (iloc) matches the index\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    \n",
    "    n_samples = len(X)\n",
    "    n_augment = int(n_samples * augmentation_factor)\n",
    "\n",
    "    augmented_X_list = []\n",
    "    augmented_y_list = []\n",
    "\n",
    "    for _ in range(n_augment):\n",
    "        idx = np.random.randint(0, n_samples)\n",
    "        base_sample = X.iloc[idx].copy()\n",
    "        \n",
    "        # Add noise to specified continuous columns\n",
    "        for col in continuous_cols:\n",
    "            if col in base_sample:\n",
    "                std = X[col].std()\n",
    "                noise = np.random.normal(loc=0, scale=std * noise_scale)\n",
    "                \n",
    "                # Logical check: don't allow negative values for typically positive soil metrics\n",
    "                if col in ['BD', 'Age', 'Altitude'] or 'log' in col:\n",
    "                    base_sample[col] = max(1e-8, base_sample[col] + noise)\n",
    "                else:\n",
    "                    base_sample[col] += noise\n",
    "\n",
    "        augmented_X_list.append(base_sample)\n",
    "        augmented_y_list.append(y.iloc[idx])\n",
    "\n",
    "    # Efficiently combine original and augmented data\n",
    "    X_augmented = pd.concat([X, pd.DataFrame(augmented_X_list)], ignore_index=True)\n",
    "    y_augmented = pd.concat([y, pd.Series(augmented_y_list)], ignore_index=True)\n",
    "\n",
    "    return X_augmented, y_augmented\n",
    "\n",
    "def enhanced_load_and_prepare_data(augment=True, augmentation_factor=2, \n",
    "                                 lu_type_importance_boost=3.0, \n",
    "                                 outlier_threshold=2.0):\n",
    "    \"\"\"Fixed data leakage version with outlier handling\"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    dtype_dict = {\n",
    "        'Soillayer': 'int8',\n",
    "        'yi': 'float32'\n",
    "    }\n",
    "\n",
    "    df_clean = pd.read_csv('F:/model/df.clean.yi.csv', dtype=dtype_dict)\n",
    "    data_predictor_VIF = pd.read_csv('F:/model/data.predictor.VIF.yi.csv')\n",
    "\n",
    "    # Select target soil layer\n",
    "    target_layer = \"topsoil\" ###################################################################################SELECT LAYER\n",
    "    df = df_clean[df_clean['Soillayer'] == (1 if target_layer == 'topsoil' else 2)].copy()\n",
    "\n",
    "    # Select features\n",
    "    predictor_columns = data_predictor_VIF['x'].tolist()\n",
    "    valid_x_cols = [col for col in predictor_columns if col != \"Soillayer\" and col in df.columns]\n",
    "\n",
    "    # Data cleaning\n",
    "    for col in valid_x_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    X = df[valid_x_cols].astype('float32').fillna(0)\n",
    "    y = df['yi'].astype('float32')\n",
    "\n",
    "    print(f\"Original data size: {len(X)}\")\n",
    "    \n",
    "    # Outlier detection and handling\n",
    "    continuous_cols = ['Lon', 'Lat', 'Age', 'BD', 'pH', 'Altitude']\n",
    "    continuous_cols = [col for col in continuous_cols if col in X.columns]\n",
    "    \n",
    "    print(\"\\n=== Outlier Handling ===\")\n",
    "    X_clean, y_clean, outliers = remove_outliers_robust(\n",
    "        X, y, continuous_cols, threshold=outlier_threshold\n",
    "    )\n",
    "\n",
    "    # Data splitting\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_clean, y_clean, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # Safe feature engineering\n",
    "    X_train, X_test = safe_feature_engineering(X_train, X_test)\n",
    "\n",
    "    # Data leakage check\n",
    "    check_data_leakage(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # LUtype feature enhancement (only for training set)\n",
    "    if 'LUtype' in X_train.columns:\n",
    "        print(f\"\\n=== LUtype Feature Enhancement ===\")\n",
    "        print(f\"Original LUtype distribution:\")\n",
    "        print(X_train['LUtype'].value_counts().sort_index())\n",
    "        \n",
    "        print(f\"\\nEnhancing LUtype importance with factor: {lu_type_importance_boost}\")\n",
    "        \n",
    "        # Create LUtype feature enhancements\n",
    "        for i in range(int(lu_type_importance_boost) - 1):\n",
    "            lu_type_col_name = f'LUtype_boost_{i+1}'\n",
    "            X_train[lu_type_col_name] = X_train['LUtype']\n",
    "            X_test[lu_type_col_name] = X_test['LUtype']\n",
    "            print(f\"  Created LUtype copy: {lu_type_col_name}\")\n",
    "        \n",
    "        # Create interaction terms between LUtype and other important features\n",
    "        important_features = ['pH', 'BD', 'Age', 'Altitude']\n",
    "        for feature in important_features:\n",
    "            if feature in X_train.columns:\n",
    "                interaction_name = f'LUtype_{feature}_interaction'\n",
    "                X_train[interaction_name] = X_train['LUtype'] * X_train[feature]\n",
    "                X_test[interaction_name] = X_test['LUtype'] * X_test[feature]\n",
    "                print(f\"  Created interaction feature: {interaction_name}\")\n",
    "        \n",
    "        # Create LUtype squared term (non-linear effect)\n",
    "        X_train['LUtype_squared'] = X_train['LUtype'] ** 2\n",
    "        X_test['LUtype_squared'] = X_test['LUtype'] ** 2\n",
    "        print(\"  Created LUtype_squared\")\n",
    "    \n",
    "    # Data augmentation (only for training set)\n",
    "    if augment:\n",
    "        continuous_cols = [\n",
    "            'Lon', 'Lat', 'Age', 'BD', 'pH',\n",
    "            'Lon_log', 'Lat_log', 'Age_log', 'BD_log', 'pH_log',\n",
    "            'Altitude'\n",
    "        ]\n",
    "        continuous_cols = [col for col in continuous_cols if col in X_train.columns]\n",
    "        \n",
    "        print(f\"\\n=== Data Augmentation ===\")\n",
    "        print(f\"Training set size before augmentation: {len(X_train)}\")\n",
    "        X_train, y_train = augment_continuous_features(\n",
    "            X=X_train,  # Only augment training set\n",
    "            y=y_train,  # Only augment training set\n",
    "            continuous_cols=continuous_cols,\n",
    "            augmentation_factor=augmentation_factor,\n",
    "            noise_scale=0.005,  \n",
    "            random_state=42\n",
    "        )\n",
    "        print(f\"Training set size after augmentation: {len(X_train)}\")\n",
    "    else:\n",
    "        print(\"\\nSkipping data augmentation\")\n",
    "\n",
    "    print(f\"\\n=== Final Dataset Statistics ===\")\n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Test set size: {len(X_test)}\")\n",
    "    print(f\"Total number of features: {len(X_train.columns)}\")\n",
    "    \n",
    "    # Statistical feature distribution\n",
    "    lu_type_cols = [col for col in X_train.columns if 'LUtype' in col]\n",
    "    \n",
    "    print(f\"\\nFeature statistics:\")\n",
    "    print(f\"LUtype-related features: {len(lu_type_cols)}\")\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=X_train.columns.tolist())\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test, feature_names=X_train.columns.tolist())\n",
    "\n",
    "    return dtrain, dtest, X, y, X_test, y_test, X_train, y_train\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function with data leakage prevention\"\"\"\n",
    "    outlier_threshold = 2.0  # Outlier detection threshold\n",
    "    \n",
    "    print(\"=== Starting Enhanced XGBoost Modeling (Fixed Data Leakage Version) ===\")\n",
    "    \n",
    "    # Use fixed data processing (with outlier handling and data leakage prevention)\n",
    "    dtrain, dtest, x1, y1, X_test, y_test, X_train, y_train = enhanced_load_and_prepare_data(\n",
    "        augment=True,\n",
    "        augmentation_factor=3,\n",
    "        lu_type_importance_boost=3.0,\n",
    "        outlier_threshold=outlier_threshold\n",
    "    )\n",
    "\n",
    "    tuner = XGBoostTuner(seed=42, n_jobs=17)\n",
    "\n",
    "    # 1. Hyperparameter tuning\n",
    "    print(\"\\n=== Starting Hyperparameter Tuning ===\")\n",
    "    best_params = tuner.tune_hyperparameters(dtrain, n_trials=10)\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "    # 2. Enhanced Cross-validation with 10x5 folds and model saving\n",
    "    print(\"\\n=== Starting 10x5 Cross-Validation ===\")\n",
    "    cv_results_summary = tuner.cross_validate(best_params, X_train, y_train, n_splits=5,\n",
    "                                              cv_models_dir='F:/model/results/cv_models',\n",
    "                                              n_repeats=10)  # 10 repetitions of 5-fold CV\n",
    "    \n",
    "    print(\"\\nSaved CV models:\")\n",
    "    for path in cv_results_summary['detailed_results']['model_paths'][:5]:  # Show first 5\n",
    "        print(f\"- {path}\")\n",
    "    print(f\"... and {len(cv_results_summary['detailed_results']['model_paths']) - 5} more\")\n",
    "    \n",
    "    # Plot enhanced CV results\n",
    "    print(\"\\nPlotting enhanced cross-validation results...\")\n",
    "    tuner.plot_cv_results(cv_results_summary)\n",
    "\n",
    "    # 3. Train final model\n",
    "    optimal_rounds = int(cv_results_summary['best_iterations_mean'])\n",
    "    print(f\"\\nTraining final model with {optimal_rounds} rounds...\")\n",
    "    final_model, evals_result = tuner.train_model(best_params, dtrain, num_boost_round=optimal_rounds)\n",
    "\n",
    "    # Plot learning curves\n",
    "    print(\"\\nPlotting learning curves...\")\n",
    "    tuner.plot_learning_curves(evals_result, \"Final Model\")\n",
    "\n",
    "    # 4. Evaluate and plot final performance\n",
    "    print(\"\\nEvaluating final model...\")\n",
    "    test_metrics, _ = tuner.evaluate_model(final_model, dtest)\n",
    "    print(\"\\n=== Final Test Metrics ===\")\n",
    "    print(f\"RMSE: {test_metrics['rmse']:.4f}\")\n",
    "    print(f\"R²: {test_metrics['r2']:.4f}\")\n",
    "    print(f\"MAE: {test_metrics['mae']:.4f}\")\n",
    "\n",
    "    print(\"\\nPlotting final model performance...\")\n",
    "    tuner.plot_final_model_performance(final_model, dtest)\n",
    "\n",
    "    # 5. Analyze LUtype importance\n",
    "    print(f\"\\nAnalyzing LUtype feature importance...\")\n",
    "    importance_df = tuner.plot_feature_importance(final_model, top_n=35)\n",
    "    \n",
    "    # Detailed analysis of LUtype importance\n",
    "    tuner.analyze_lutype_importance(final_model, X_test)\n",
    "    \n",
    "    # 6. SHAP analysis\n",
    "    if SHAP_AVAILABLE:\n",
    "        print(\"\\nGenerating SHAP summary plot...\")\n",
    "        tuner.plot_shap_summary(final_model, X_test)\n",
    "        \n",
    "    # 7. Save results\n",
    "    print(\"\\nSaving results...\")\n",
    "    tuner.save_results(final_model, 'F:/model/results')\n",
    "    \n",
    "    # Save CV results summary\n",
    "    cv_summary_path = 'F:/model/results/cv_summary.csv'\n",
    "    cv_results_summary['detailed_results'].to_csv(cv_summary_path, index=False)\n",
    "    print(f\"Saved detailed CV results to: {cv_summary_path}\")\n",
    "    \n",
    "    print(f\"\\n=== Model Training Summary ===\")\n",
    "    print(\"✓ Fixed data leakage issues\")\n",
    "    print(\"✓ Added outlier detection and handling\")\n",
    "    print(\"✓ Safe feature engineering (avoided data leakage)\")\n",
    "    print(\"✓ Created multiple LUtype feature copies\")\n",
    "    print(\"✓ Added LUtype interaction features with other important variables\")\n",
    "    print(\"✓ Added LUtype squared term (non-linear effect)\")\n",
    "    print(\"✓ Improved hyperparameter search space for better handling of categorical features\")\n",
    "    print(\"✓ Test set uses original data (no augmentation noise)\")\n",
    "    print(\"✓ Implemented 10 repetitions of 5-fold cross-validation for robust evaluation\")\n",
    "    \n",
    "    print(\"\\n=== Complete! ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce6acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost modeling: active fractions in subsoil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import builtins\n",
    "from scipy import stats\n",
    "open = builtins.open\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# SHAP availability check\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SHAP_AVAILABLE = False\n",
    "\n",
    "class XGBoostTuner:\n",
    "    def __init__(self, seed=42, n_jobs=-1):\n",
    "        self.seed = seed\n",
    "        self.n_jobs = n_jobs if n_jobs != -1 else None\n",
    "        self.study = None\n",
    "        self.best_model = None\n",
    "        self.best_params = None\n",
    "        self.feature_names = None  # Store feature names\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_numeric_value(value):\n",
    "        \"\"\"Convert string values to numeric, handling special cases\"\"\"\n",
    "        if pd.isna(value):\n",
    "            return np.nan\n",
    "        if isinstance(value, str):\n",
    "            # Remove any non-numeric characters except minus, decimal point\n",
    "            cleaned = re.sub(r'[^\\d.-]', '', value)\n",
    "            try:\n",
    "                return float(cleaned) if cleaned else np.nan\n",
    "            except ValueError:\n",
    "                return np.nan\n",
    "        return float(value)\n",
    "\n",
    "    def objective(self, trial, dtrain, num_boost_round=500):\n",
    "        \"\"\"Objective function with enhanced regularization\"\"\"\n",
    "        params = {\n",
    "            'eta': trial.suggest_float('eta', 0.005, 0.1, log=True),  # Lower learning rate\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 4),  # Shallower trees\n",
    "            'subsample': trial.suggest_float('subsample', 0.4, 0.7),  # Lower subsampling\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 0.7),  # Lower feature sampling\n",
    "            'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.4, 0.7),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 10, 20),  # Higher min child weight\n",
    "            'lambda': trial.suggest_float('lambda', 10, 25.0),  # Stronger L2 regularization\n",
    "            'alpha': trial.suggest_float('alpha', 5.0, 15.0),  # Stronger L1 regularization\n",
    "            'gamma': trial.suggest_float('gamma', 0.5, 2.0),  # Higher pruning parameter\n",
    "            'max_delta_step': trial.suggest_int('max_delta_step', 0, 1),\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'verbosity': 0,\n",
    "            'seed': self.seed,\n",
    "            'nthread': 1\n",
    "        }\n",
    "\n",
    "        cv_results = xgb.cv(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=800,  # More rounds but more conservative early stopping\n",
    "            nfold=5,\n",
    "            metrics='rmse',\n",
    "            early_stopping_rounds=20,  # More conservative early stopping\n",
    "            as_pandas=True,\n",
    "            seed=self.seed,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        # Stronger overfitting penalty\n",
    "        train_rmse = cv_results['train-rmse-mean'].iloc[-1]\n",
    "        val_rmse = cv_results['test-rmse-mean'].iloc[-1]\n",
    "        \n",
    "        # Calculate overfitting degree\n",
    "        overfitting_ratio = (train_rmse - val_rmse) / train_rmse\n",
    "        gap_penalty = max(0, overfitting_ratio) * 0.3  # Stronger penalty\n",
    "        \n",
    "        # Add extra penalty if severe overfitting\n",
    "        if overfitting_ratio > 0.1:\n",
    "            gap_penalty += (overfitting_ratio - 0.1) * 0.5\n",
    "            \n",
    "        return val_rmse + gap_penalty\n",
    "    \n",
    "    def tune_hyperparameters(self, dtrain, n_trials=10):  # Increased number of trials\n",
    "        \"\"\"Hyperparameter tuning focused on generalization\"\"\"\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        \n",
    "        print(\"Tuning hyperparameters with aggressive overfitting prevention...\")\n",
    "        print(\"Using very strong regularization and shallow trees\")\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=self.n_jobs) as executor:\n",
    "            futures = [executor.submit(lambda: study.optimize(\n",
    "                lambda trial: self.objective(trial, dtrain),\n",
    "                n_trials=5,\n",
    "                n_jobs=1\n",
    "            )) for _ in range(n_trials//5)]\n",
    "\n",
    "            for future in futures:\n",
    "                future.result()\n",
    "\n",
    "        self.study = study\n",
    "        self.best_params = study.best_params\n",
    "        self.best_params.update({\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'seed': self.seed,\n",
    "            'nthread': self.n_jobs\n",
    "        })\n",
    "\n",
    "        print(f\"Best parameters found: {self.best_params}\")\n",
    "        return self.best_params\n",
    "\n",
    "\n",
    "    def train_model(self, params, dtrain, dvalid=None, num_boost_round=500):\n",
    "        \"\"\"Train model with focus on preventing overfitting\"\"\"\n",
    "        evals = [(dtrain, 'train')]\n",
    "        if dvalid is not None:\n",
    "            evals.append((dvalid, 'valid'))\n",
    "\n",
    "        evals_result = {}\n",
    "        model = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            evals=evals,\n",
    "            early_stopping_rounds=25,  # More conservative early stopping\n",
    "            verbose_eval=100,  # Reduced output frequency\n",
    "            evals_result=evals_result\n",
    "        )\n",
    "\n",
    "        self.feature_names = dtrain.feature_names\n",
    "        if self.feature_names is None:\n",
    "            self.feature_names = [f'f{i}' for i in range(dtrain.num_col())]\n",
    "            model.feature_names = self.feature_names\n",
    "\n",
    "        return model, evals_result\n",
    "\n",
    "    def cross_validate(self, params, X, y, n_splits=5, cv_models_dir='cv_models', n_repeats=10): \n",
    "        \"\"\"Enhanced CV with 10 repetitions of 5-fold cross-validation and model saving\"\"\"\n",
    "        Path(cv_models_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        all_cv_results = {\n",
    "            'train_rmse': [], 'val_rmse': [],\n",
    "            'train_r2': [], 'val_r2': [],\n",
    "            'best_iterations': [],\n",
    "            'model_paths': [],\n",
    "            'feature_names': [],\n",
    "            'repeat': [],\n",
    "            'fold': []\n",
    "        }\n",
    "\n",
    "        def process_fold(repeat_idx, fold_idx, train_idx, val_idx):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=X_train.columns.tolist())\n",
    "            dval = xgb.DMatrix(X_val, label=y_val, feature_names=X_train.columns.tolist())\n",
    "\n",
    "            model, _ = self.train_model(params, dtrain, dval)\n",
    "\n",
    "            # Save the CV model\n",
    "            model_path = os.path.join(cv_models_dir, f'cv_model_repeat_{repeat_idx}_fold_{fold_idx}.json')\n",
    "            model.save_model(model_path)\n",
    "\n",
    "            train_pred = model.predict(dtrain)\n",
    "            val_pred = model.predict(dval)\n",
    "\n",
    "            return (\n",
    "                np.sqrt(mean_squared_error(y_train, train_pred)),\n",
    "                np.sqrt(mean_squared_error(y_val, val_pred)),\n",
    "                r2_score(y_train, train_pred),\n",
    "                r2_score(y_val, val_pred),\n",
    "                model.best_iteration if hasattr(model, 'best_iteration') else params.get('num_boost_round', 500),\n",
    "                model_path,\n",
    "                model.feature_names,\n",
    "                repeat_idx,\n",
    "                fold_idx\n",
    "            )\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=self.n_jobs) as executor:\n",
    "            futures = []\n",
    "            for repeat_idx in range(n_repeats):\n",
    "                kf = KFold(n_splits=n_splits, shuffle=True, random_state=self.seed + repeat_idx)\n",
    "                for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "                    futures.append(executor.submit(\n",
    "                        process_fold, repeat_idx, fold_idx, train_idx, val_idx\n",
    "                    ))\n",
    "\n",
    "            for future in futures:\n",
    "                train_rmse, val_rmse, train_r2, val_r2, best_iter, model_path, feature_names, repeat_idx, fold_idx = future.result()\n",
    "                all_cv_results['train_rmse'].append(train_rmse)\n",
    "                all_cv_results['val_rmse'].append(val_rmse)\n",
    "                all_cv_results['train_r2'].append(train_r2)\n",
    "                all_cv_results['val_r2'].append(val_r2)\n",
    "                all_cv_results['best_iterations'].append(best_iter)\n",
    "                all_cv_results['model_paths'].append(model_path)\n",
    "                all_cv_results['feature_names'].append(feature_names)\n",
    "                all_cv_results['repeat'].append(repeat_idx)\n",
    "                all_cv_results['fold'].append(fold_idx)\n",
    "        # Create summary statistics\n",
    "        cv_results_summary = {\n",
    "            'train_rmse_mean': np.mean(all_cv_results['train_rmse']),\n",
    "            'train_rmse_std': np.std(all_cv_results['train_rmse']),\n",
    "            'val_rmse_mean': np.mean(all_cv_results['val_rmse']),\n",
    "            'val_rmse_std': np.std(all_cv_results['val_rmse']),\n",
    "            'train_r2_mean': np.mean(all_cv_results['train_r2']),\n",
    "            'train_r2_std': np.std(all_cv_results['train_r2']),\n",
    "            'val_r2_mean': np.mean(all_cv_results['val_r2']),\n",
    "            'val_r2_std': np.std(all_cv_results['val_r2']),\n",
    "            'best_iterations_mean': np.mean(all_cv_results['best_iterations']),\n",
    "            'best_iterations_std': np.std(all_cv_results['best_iterations']),\n",
    "            'detailed_results': pd.DataFrame(all_cv_results)\n",
    "        }\n",
    "\n",
    "        return cv_results_summary\n",
    "\n",
    "    def evaluate_model(self, model, dtest):\n",
    "        \"\"\"Evaluate model performance on test set\"\"\"\n",
    "        test_pred = model.predict(dtest)\n",
    "        return {\n",
    "            'rmse': np.sqrt(mean_squared_error(dtest.get_label(), test_pred)),\n",
    "            'r2': r2_score(dtest.get_label(), test_pred),\n",
    "            'mae': mean_absolute_error(dtest.get_label(), test_pred)\n",
    "        }, test_pred\n",
    "\n",
    "    def plot_learning_curves(self, evals_result, title_suffix):\n",
    "        \"\"\"Plot training and validation metrics\"\"\"\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        epochs = len(evals_result['train']['rmse'])\n",
    "        plt.plot(range(epochs), evals_result['train']['rmse'], label='Train RMSE')\n",
    "        if 'valid' in evals_result:\n",
    "            plt.plot(range(epochs), evals_result['valid']['rmse'], label='Validation RMSE')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.title(f'Learning Curves - {title_suffix}')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_cv_results(self, cv_results_summary):\n",
    "        \"\"\"Plot enhanced cross-validation results with both original and new visualization\"\"\"\n",
    "        # Check if it's the new summary format or old list format\n",
    "        if isinstance(cv_results_summary, dict) and 'detailed_results' in cv_results_summary:\n",
    "            # New format - use the detailed results\n",
    "            detailed_results = cv_results_summary['detailed_results']\n",
    "            \n",
    "            # Create two visualizations:\n",
    "            # 1. Original visualization (simple line plot for first repeat)\n",
    "            plt.figure(figsize=(20, 10))\n",
    "            \n",
    "            # Plot 1: Original style - first repeat only\n",
    "            plt.subplot(2, 2, 1)\n",
    "            first_repeat = detailed_results[detailed_results['repeat'] == 0]\n",
    "            plt.plot(first_repeat['train_rmse'], 'o-', label='Train RMSE')\n",
    "            plt.plot(first_repeat['val_rmse'], 'o-', label='Validation RMSE')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.title('Cross-Validation RMSE (First Repeat)')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Plot 2: Original style - first repeat R²\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.plot(first_repeat['train_r2'], 'o-', label='Train R²')\n",
    "            plt.plot(first_repeat['val_r2'], 'o-', label='Validation R²')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('R² Score')\n",
    "            plt.title('Cross-Validation R² Scores (First Repeat)')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Plot 3: New visualization - RMSE distribution across all repeats\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.boxplot([detailed_results['train_rmse'], detailed_results['val_rmse']], \n",
    "                       labels=['Train RMSE', 'Validation RMSE'])\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.title('RMSE Distribution across 10x5 CV')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Plot 4: New visualization - R² distribution across all repeats\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.boxplot([detailed_results['train_r2'], detailed_results['val_r2']], \n",
    "                       labels=['Train R²', 'Validation R²'])\n",
    "            plt.ylabel('R² Score')\n",
    "            plt.title('R² Distribution across 10x5 CV')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Print summary statistics\n",
    "            print(\"\\n=== 10x5 Cross-Validation Summary ===\")\n",
    "            print(f\"Average Train RMSE: {cv_results_summary['train_rmse_mean']:.4f} (±{cv_results_summary['train_rmse_std']:.4f})\")\n",
    "            print(f\"Average Validation RMSE: {cv_results_summary['val_rmse_mean']:.4f} (±{cv_results_summary['val_rmse_std']:.4f})\")\n",
    "            print(f\"Average Train R²: {cv_results_summary['train_r2_mean']:.4f} (±{cv_results_summary['train_r2_std']:.4f})\")\n",
    "            print(f\"Average Validation R²: {cv_results_summary['val_r2_mean']:.4f} (±{cv_results_summary['val_r2_std']:.4f})\")\n",
    "            print(f\"Average Best Iterations: {cv_results_summary['best_iterations_mean']:.1f} (±{cv_results_summary['best_iterations_std']:.1f})\")\n",
    "            \n",
    "            # Also print the format that main() expects\n",
    "            print(\"\\n=== 交叉验证结果 (旧格式兼容) ===\")\n",
    "            print(f\"平均训练RMSE: {cv_results_summary['train_rmse_mean']:.4f} (±{cv_results_summary['train_rmse_std']:.4f})\")\n",
    "            print(f\"平均验证RMSE: {cv_results_summary['val_rmse_mean']:.4f} (±{cv_results_summary['val_rmse_std']:.4f})\")\n",
    "            print(f\"平均训练R²: {cv_results_summary['train_r2_mean']:.4f} (±{cv_results_summary['train_r2_std']:.4f})\")\n",
    "            print(f\"平均验证R²: {cv_results_summary['val_r2_mean']:.4f} (±{cv_results_summary['val_r2_std']:.4f})\")\n",
    "            \n",
    "        else:\n",
    "            # Old format - keep original plotting\n",
    "            plt.figure(figsize=(15, 5))\n",
    "\n",
    "            # Plot RMSE\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(cv_results_summary['train_rmse'], 'o-', label='Train RMSE')\n",
    "            plt.plot(cv_results_summary['val_rmse'], 'o-', label='Validation RMSE')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.title('Cross-Validation RMSE')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Plot R2\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(cv_results_summary['train_r2'], 'o-', label='Train R²')\n",
    "            plt.plot(cv_results_summary['val_r2'], 'o-', label='Validation R²')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('R² Score')\n",
    "            plt.title('Cross-Validation R² Scores')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def plot_final_model_performance(self, model, dtest):\n",
    "        \"\"\"Plot actual vs predicted values for test set\"\"\"\n",
    "        test_metrics, test_pred = self.evaluate_model(model, dtest)\n",
    "        y_test = dtest.get_label()\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        # Scatter plot of actual vs predicted\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(y_test, test_pred, alpha=0.5)\n",
    "        plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--r')\n",
    "        plt.xlabel('Actual Values')\n",
    "        plt.ylabel('Predicted Values')\n",
    "        plt.title(f'Actual vs Predicted (R² = {test_metrics[\"r2\"]:.3f})')\n",
    "\n",
    "        # Residual plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        residuals = y_test - test_pred\n",
    "        plt.scatter(test_pred, residuals, alpha=0.5)\n",
    "        plt.axhline(y=0, color='r', linestyle='--')\n",
    "        plt.xlabel('Predicted Values')\n",
    "        plt.ylabel('Residuals')\n",
    "        plt.title('Residual Plot')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_feature_importance(self, model, importance_type='weight', top_n=30):\n",
    "        \"\"\"Plot feature importance without category-specific highlighting\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "      \n",
    "        importance_dict = model.get_score(importance_type=importance_type)\n",
    "        \n",
    "        if not importance_dict:\n",
    "            print(\"No feature importance data available.\")\n",
    "            return None\n",
    "            \n",
    "   \n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': list(importance_dict.keys()),\n",
    "            'importance': list(importance_dict.values())\n",
    "        }).sort_values('importance', ascending=True)\n",
    "        \n",
    "  \n",
    "        if len(importance_df) > top_n:\n",
    "            importance_df = importance_df.tail(top_n)\n",
    "        \n",
    "    \n",
    "        y_pos = np.arange(len(importance_df))\n",
    "        colors = ['lightblue'] * len(importance_df)\n",
    "        \n",
    "        ax.barh(y_pos, importance_df['importance'], color=colors, alpha=0.8)\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(importance_df['feature'])\n",
    "        ax.set_xlabel('Importance')\n",
    "        \n",
    "        title = f'Feature Importance ({importance_type})'\n",
    "        ax.set_title(title)\n",
    "        \n",
    "\n",
    "        lu_type_features = importance_df[importance_df['feature'].str.contains('LUtype', na=False)]\n",
    "        lu_type_importance = lu_type_features['importance'].sum() if not lu_type_features.empty else 0\n",
    "        \n",
    "        ax.text(0.7, 0.95, f'LUtype total: {lu_type_importance:.3f}', \n",
    "                transform=ax.transAxes, fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\"))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return importance_df\n",
    "\n",
    "    def analyze_lutype_importance(self, model, X):\n",
    "        \"\"\"分析LUtype相关特征的重要性，不关注特定类别\"\"\"\n",
    "        importance_dict = model.get_score(importance_type='weight')\n",
    "        \n",
    "        if not importance_dict:\n",
    "            print(\"No feature importance data available.\")\n",
    "            return\n",
    "            \n",
    " \n",
    "        lutype_features = {k: v for k, v in importance_dict.items() if 'LUtype' in k}\n",
    "        other_features = {k: v for k, v in importance_dict.items() if 'LUtype' not in k}\n",
    "        \n",
    "        print(f\"\\n=== LUtype Feature Importance Analysis ===\")\n",
    "        print(f\"Total LUtype-related features: {len(lutype_features)}\")\n",
    "        print(f\"Total importance of LUtype features: {sum(lutype_features.values()):.3f}\")\n",
    "        print(f\"Average importance of LUtype features: {np.mean(list(lutype_features.values())) if lutype_features else 0:.3f}\")\n",
    "        \n",
    "        total_importance = sum(importance_dict.values())\n",
    "        lu_type_percentage = (sum(lutype_features.values()) / total_importance * 100) if total_importance > 0 else 0\n",
    "        \n",
    "        print(f\"\\nLUtype importance percentage: {lu_type_percentage:.2f}%\")\n",
    "        \n",
    "\n",
    "        if lutype_features:\n",
    "            sorted_lutype = sorted(lutype_features.items(), key=lambda x: x[1], reverse=True)\n",
    "            print(f\"\\nTop LUtype-related features:\")\n",
    "            for feature, importance in sorted_lutype[:10]:\n",
    "                print(f\"  {feature}: {importance:.4f}\")\n",
    "        else:\n",
    "            print(\"\\nNo LUtype-related features found in importance scores.\")\n",
    "\n",
    "    def plot_shap_summary(self, model, X, feature_names=None):\n",
    "        \"\"\"Generate SHAP summary plot if SHAP is available\"\"\"\n",
    "        if SHAP_AVAILABLE:\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(X)\n",
    "\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            shap.summary_plot(shap_values, X, feature_names=feature_names)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"SHAP not available. Install with: pip install shap\")\n",
    "\n",
    "    def save_results(self, model, output_dir='results'):\n",
    "        \"\"\"Save all results to disk including feature names\"\"\"\n",
    "        Path(output_dir).mkdir(exist_ok=True)\n",
    "\n",
    "        # Save model\n",
    "        model.save_model(f'{output_dir}/xgb_model.json')\n",
    "\n",
    "        # Save feature names\n",
    "        if self.feature_names is not None:\n",
    "            with open(f'{output_dir}/feature_names.txt', 'w') as f:\n",
    "                f.write('\\n'.join(self.feature_names))\n",
    "\n",
    "        # Save other artifacts\n",
    "        joblib.dump(self.best_params, f'{output_dir}/best_params.pkl')\n",
    "\n",
    "        if self.study:\n",
    "            joblib.dump(self.study, f'{output_dir}/study.pkl')\n",
    "            study_df = self.study.trials_dataframe()\n",
    "            study_df.to_csv(f'{output_dir}/trials.csv', index=False)\n",
    "\n",
    "def detect_outliers_iqr(df, columns, threshold=1.5):\n",
    "    \"\"\"Detect outliers using IQR method\"\"\"\n",
    "    outlier_indices = []\n",
    "    \n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - threshold * IQR\n",
    "            upper_bound = Q3 + threshold * IQR\n",
    "            \n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index\n",
    "            outlier_indices.extend(outliers)\n",
    "            \n",
    "            if len(outliers) > 0:\n",
    "                print(f\"  {col}: Found {len(outliers)} outliers \"\n",
    "                      f\"({len(outliers)/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    return list(set(outlier_indices))\n",
    "\n",
    "def remove_outliers_robust(df, y, columns, method='iqr', threshold=2.0):\n",
    "    \"\"\"Robust outlier handling method\"\"\"\n",
    "    print(\"Starting outlier detection...\")\n",
    "    \n",
    "    if method == 'iqr':\n",
    "        outlier_indices = detect_outliers_iqr(df, columns, threshold)\n",
    "    elif method == 'zscore':\n",
    "        # Z-score method\n",
    "        z_scores = np.abs(stats.zscore(df[columns]))\n",
    "        outlier_indices = np.where(z_scores > threshold)[0]\n",
    "        outlier_indices = list(outlier_indices)\n",
    "    else:\n",
    "        return df, y, []\n",
    "    \n",
    "    print(f\"\\nTotal outliers found: {len(outlier_indices)}\")\n",
    "    \n",
    "    if len(outlier_indices) > 0:\n",
    "        df_clean = df.drop(outlier_indices)\n",
    "        y_clean = y.drop(outlier_indices)\n",
    "        print(f\"Data size after removing outliers: {len(df_clean)} (removed {len(outlier_indices)} samples)\")\n",
    "        return df_clean, y_clean, outlier_indices\n",
    "    \n",
    "    print(\"No outliers found\")\n",
    "    return df, y, []\n",
    "\n",
    "def check_data_leakage(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Check for data leakage\"\"\"\n",
    "    print(\"\\n=== Data Leakage Check ===\")\n",
    "    \n",
    "    # Check for overlap between train and test sets\n",
    "    train_indices = set(X_train.index)\n",
    "    test_indices = set(X_test.index)\n",
    "    overlap = train_indices.intersection(test_indices)\n",
    "    \n",
    "    if overlap:\n",
    "        print(f\"❌ Data leakage detected: {len(overlap)} overlapping samples between train and test sets\")\n",
    "    else:\n",
    "        print(\"✅ No overlap between train and test sets\")\n",
    "    \n",
    "    # Check feature distributions\n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Test set size: {len(X_test)}\")\n",
    "    print(f\"Number of features: {X_train.shape[1]}\")\n",
    "    \n",
    "    return len(overlap) == 0\n",
    "\n",
    "def safe_feature_engineering(X_train, X_test):\n",
    "    \"\"\"Safe feature engineering to avoid data leakage\"\"\"\n",
    "    print(\"Performing safe feature engineering...\")\n",
    "    \n",
    "    # 1. Logarithmic transformation\n",
    "    columns_to_log = ['Lon', 'Lat', 'Age', 'BD', 'pH']\n",
    "    for col in columns_to_log:\n",
    "        if col in X_train.columns:\n",
    "            X_train[col + '_log'] = np.log(X_train[col] + 1e-8)\n",
    "            X_test[col + '_log'] = np.log(X_test[col] + 1e-8)\n",
    "            print(f\"  Created log feature: {col}_log\")\n",
    "    \n",
    "    # 2. Binning (based on training set quantiles)\n",
    "    if 'Altitude' in X_train.columns:\n",
    "        # Use training set to compute bin boundaries\n",
    "        alt_bins = pd.cut(X_train['Altitude'], bins=5, retbins=True)[1]\n",
    "        X_train['Altitude_bins'] = pd.cut(X_train['Altitude'], bins=alt_bins, labels=False)\n",
    "        X_test['Altitude_bins'] = pd.cut(X_test['Altitude'], bins=alt_bins, labels=False)\n",
    "        print(\"  Created binned feature: Altitude_bins\")\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "def augment_continuous_features(X, y, continuous_cols, augmentation_factor=2, noise_scale=0.01, random_state=42):\n",
    "    \"\"\"Augment continuous features with noise - only for training set\"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    n_samples = len(X)\n",
    "    n_augment = int(n_samples * augmentation_factor)\n",
    "\n",
    "    X_augmented = X.copy()\n",
    "    y_augmented = y.copy()\n",
    "\n",
    "    for _ in range(n_augment):\n",
    "        idx = np.random.randint(0, n_samples)\n",
    "        base_sample = X.iloc[idx].copy()\n",
    "\n",
    "        for col in continuous_cols:\n",
    "            std = X[col].std()\n",
    "            noise = np.random.normal(loc=0, scale=std * noise_scale)\n",
    "            if X[col].min() >= 0:\n",
    "                base_sample[col] = max(0, base_sample[col] + noise)\n",
    "            else:\n",
    "                base_sample[col] += noise\n",
    "\n",
    "        X_augmented = X_augmented._append(base_sample, ignore_index=True)\n",
    "        \n",
    "        y_augmented = y_augmented._append(\n",
    "            pd.Series(y.iloc[idx], index=[len(y_augmented)]),  \n",
    "            ignore_index=True\n",
    "        )\n",
    "\n",
    "    return X_augmented, y_augmented\n",
    "\n",
    "def enhanced_load_and_prepare_data(augment=True, augmentation_factor=2, \n",
    "                                 lu_type_importance_boost=3.0, \n",
    "                                 outlier_threshold=2.0):\n",
    "    \"\"\"Fixed data leakage version with outlier handling\"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    dtype_dict = {\n",
    "        'Soillayer': 'int8',\n",
    "        'yi': 'float32'\n",
    "    }\n",
    "\n",
    "    df_clean = pd.read_csv('F:/model/df.clean.yi.csv', dtype=dtype_dict)\n",
    "    data_predictor_VIF = pd.read_csv('F:/model/data.predictor.VIF.yi.csv')\n",
    "\n",
    "    # Select target soil layer\n",
    "    target_layer = \"subsoil\" ###################################################################################SELECT LAYER\n",
    "    df = df_clean[df_clean['Soillayer'] == (1 if target_layer == 'topsoil' else 2)].copy()\n",
    "\n",
    "    # Select features\n",
    "    predictor_columns = data_predictor_VIF['x'].tolist()\n",
    "    valid_x_cols = [col for col in predictor_columns if col != \"Soillayer\" and col in df.columns]\n",
    "\n",
    "    # Data cleaning\n",
    "    for col in valid_x_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    X = df[valid_x_cols].astype('float32').fillna(0)\n",
    "    y = df['yi'].astype('float32')\n",
    "\n",
    "    print(f\"Original data size: {len(X)}\")\n",
    "    \n",
    "    # Outlier detection and handling\n",
    "    continuous_cols = ['Lon', 'Lat', 'Age', 'BD', 'pH', 'Altitude']\n",
    "    continuous_cols = [col for col in continuous_cols if col in X.columns]\n",
    "    \n",
    "    print(\"\\n=== Outlier Handling ===\")\n",
    "    X_clean, y_clean, outliers = remove_outliers_robust(\n",
    "        X, y, continuous_cols, threshold=outlier_threshold\n",
    "    )\n",
    "\n",
    "    # Data splitting\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_clean, y_clean, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # Safe feature engineering\n",
    "    X_train, X_test = safe_feature_engineering(X_train, X_test)\n",
    "\n",
    "    # Data leakage check\n",
    "    check_data_leakage(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # LUtype feature enhancement (only for training set)\n",
    "    if 'LUtype' in X_train.columns:\n",
    "        print(f\"\\n=== LUtype Feature Enhancement ===\")\n",
    "        print(f\"Original LUtype distribution:\")\n",
    "        print(X_train['LUtype'].value_counts().sort_index())\n",
    "        \n",
    "        print(f\"\\nEnhancing LUtype importance with factor: {lu_type_importance_boost}\")\n",
    "        \n",
    "        # Create LUtype feature enhancements\n",
    "        for i in range(int(lu_type_importance_boost) - 1):\n",
    "            lu_type_col_name = f'LUtype_boost_{i+1}'\n",
    "            X_train[lu_type_col_name] = X_train['LUtype']\n",
    "            X_test[lu_type_col_name] = X_test['LUtype']\n",
    "            print(f\"  Created LUtype copy: {lu_type_col_name}\")\n",
    "        \n",
    "        # Create interaction terms between LUtype and other important features\n",
    "        important_features = ['pH', 'BD', 'Age', 'Altitude']\n",
    "        for feature in important_features:\n",
    "            if feature in X_train.columns:\n",
    "                interaction_name = f'LUtype_{feature}_interaction'\n",
    "                X_train[interaction_name] = X_train['LUtype'] * X_train[feature]\n",
    "                X_test[interaction_name] = X_test['LUtype'] * X_test[feature]\n",
    "                print(f\"  Created interaction feature: {interaction_name}\")\n",
    "        \n",
    "        # Create LUtype squared term (non-linear effect)\n",
    "        X_train['LUtype_squared'] = X_train['LUtype'] ** 2\n",
    "        X_test['LUtype_squared'] = X_test['LUtype'] ** 2\n",
    "        print(\"  Created LUtype_squared\")\n",
    "    \n",
    "    # Data augmentation (only for training set)\n",
    "    if augment:\n",
    "        continuous_cols = [\n",
    "            'Lon', 'Lat', 'Age', 'BD', 'pH',\n",
    "            'Lon_log', 'Lat_log', 'Age_log', 'BD_log', 'pH_log',\n",
    "            'Altitude'\n",
    "        ]\n",
    "        continuous_cols = [col for col in continuous_cols if col in X_train.columns]\n",
    "        \n",
    "        print(f\"\\n=== Data Augmentation ===\")\n",
    "        print(f\"Training set size before augmentation: {len(X_train)}\")\n",
    "        X_train, y_train = augment_continuous_features(\n",
    "            X=X_train,  # Only augment training set\n",
    "            y=y_train,  # Only augment training set\n",
    "            continuous_cols=continuous_cols,\n",
    "            augmentation_factor=augmentation_factor,\n",
    "            noise_scale=0.01,  \n",
    "            random_state=42\n",
    "        )\n",
    "        print(f\"Training set size after augmentation: {len(X_train)}\")\n",
    "    else:\n",
    "        print(\"\\nSkipping data augmentation\")\n",
    "\n",
    "    print(f\"\\n=== Final Dataset Statistics ===\")\n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Test set size: {len(X_test)}\")\n",
    "    print(f\"Total number of features: {len(X_train.columns)}\")\n",
    "    \n",
    "    # Statistical feature distribution\n",
    "    lu_type_cols = [col for col in X_train.columns if 'LUtype' in col]\n",
    "    \n",
    "    print(f\"\\nFeature statistics:\")\n",
    "    print(f\"LUtype-related features: {len(lu_type_cols)}\")\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=X_train.columns.tolist())\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test, feature_names=X_train.columns.tolist())\n",
    "\n",
    "    return dtrain, dtest, X, y, X_test, y_test, X_train, y_train\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function with data leakage prevention\"\"\"\n",
    "    outlier_threshold = 2.0  # Outlier detection threshold\n",
    "    \n",
    "    print(\"=== Starting Enhanced XGBoost Modeling (Fixed Data Leakage Version) ===\")\n",
    "    \n",
    "    # Use fixed data processing (with outlier handling and data leakage prevention)\n",
    "    dtrain, dtest, x1, y1, X_test, y_test, X_train, y_train = enhanced_load_and_prepare_data(\n",
    "        augment=True,\n",
    "        augmentation_factor=3,\n",
    "        lu_type_importance_boost=3.0,\n",
    "        outlier_threshold=outlier_threshold\n",
    "    )\n",
    "\n",
    "    tuner = XGBoostTuner(seed=42, n_jobs=17)\n",
    "\n",
    "    # 1. Hyperparameter tuning\n",
    "    print(\"\\n=== Starting Hyperparameter Tuning ===\")\n",
    "    best_params = tuner.tune_hyperparameters(dtrain, n_trials=10)\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "    # 2. Enhanced Cross-validation with 10x5 folds and model saving\n",
    "    print(\"\\n=== Starting 10x5 Cross-Validation ===\")\n",
    "    cv_results_summary = tuner.cross_validate(best_params, X_train, y_train, n_splits=5,\n",
    "                                              cv_models_dir='F:/model/results/cv_models',\n",
    "                                              n_repeats=10)  # 10 repetitions of 5-fold CV\n",
    "    \n",
    "    print(\"\\nSaved CV models:\")\n",
    "    for path in cv_results_summary['detailed_results']['model_paths'][:5]:  # Show first 5\n",
    "        print(f\"- {path}\")\n",
    "    print(f\"... and {len(cv_results_summary['detailed_results']['model_paths']) - 5} more\")\n",
    "    \n",
    "    # Plot enhanced CV results\n",
    "    print(\"\\nPlotting enhanced cross-validation results...\")\n",
    "    tuner.plot_cv_results(cv_results_summary)\n",
    "\n",
    "    # 3. Train final model\n",
    "    optimal_rounds = int(cv_results_summary['best_iterations_mean'])\n",
    "    print(f\"\\nTraining final model with {optimal_rounds} rounds...\")\n",
    "    final_model, evals_result = tuner.train_model(best_params, dtrain, num_boost_round=optimal_rounds)\n",
    "\n",
    "    # Plot learning curves\n",
    "    print(\"\\nPlotting learning curves...\")\n",
    "    tuner.plot_learning_curves(evals_result, \"Final Model\")\n",
    "\n",
    "    # 4. Evaluate and plot final performance\n",
    "    print(\"\\nEvaluating final model...\")\n",
    "    test_metrics, _ = tuner.evaluate_model(final_model, dtest)\n",
    "    print(\"\\n=== Final Test Metrics ===\")\n",
    "    print(f\"RMSE: {test_metrics['rmse']:.4f}\")\n",
    "    print(f\"R²: {test_metrics['r2']:.4f}\")\n",
    "    print(f\"MAE: {test_metrics['mae']:.4f}\")\n",
    "\n",
    "    print(\"\\nPlotting final model performance...\")\n",
    "    tuner.plot_final_model_performance(final_model, dtest)\n",
    "\n",
    "    # 5. Analyze LUtype importance\n",
    "    print(f\"\\nAnalyzing LUtype feature importance...\")\n",
    "    importance_df = tuner.plot_feature_importance(final_model, top_n=35)\n",
    "    \n",
    "    # Detailed analysis of LUtype importance\n",
    "    tuner.analyze_lutype_importance(final_model, X_test)\n",
    "    \n",
    "    # 6. SHAP analysis\n",
    "    if SHAP_AVAILABLE:\n",
    "        print(\"\\nGenerating SHAP summary plot...\")\n",
    "        tuner.plot_shap_summary(final_model, X_test)\n",
    "        \n",
    "    # 7. Save results\n",
    "    print(\"\\nSaving results...\")\n",
    "    tuner.save_results(final_model, 'F:/model/results')\n",
    "    \n",
    "    # Save CV results summary\n",
    "    cv_summary_path = 'F:/model/results/cv_summary.csv'\n",
    "    cv_results_summary['detailed_results'].to_csv(cv_summary_path, index=False)\n",
    "    print(f\"Saved detailed CV results to: {cv_summary_path}\")\n",
    "    \n",
    "    print(f\"\\n=== Model Training Summary ===\")\n",
    "    print(\"✓ Fixed data leakage issues\")\n",
    "    print(\"✓ Added outlier detection and handling\")\n",
    "    print(\"✓ Safe feature engineering (avoided data leakage)\")\n",
    "    print(\"✓ Created multiple LUtype feature copies\")\n",
    "    print(\"✓ Added LUtype interaction features with other important variables\")\n",
    "    print(\"✓ Added LUtype squared term (non-linear effect)\")\n",
    "    print(\"✓ Improved hyperparameter search space for better handling of categorical features\")\n",
    "    print(\"✓ Test set uses original data (no augmentation noise)\")\n",
    "    print(\"✓ Implemented 10 repetitions of 5-fold cross-validation for robust evaluation\")\n",
    "    \n",
    "    print(\"\\n=== Complete! ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e907f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost modeling: passive fractions in subsoil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import builtins\n",
    "from scipy import stats\n",
    "open = builtins.open\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# SHAP availability check\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SHAP_AVAILABLE = False\n",
    "\n",
    "class XGBoostTuner:\n",
    "    def __init__(self, seed=42, n_jobs=-1):\n",
    "        self.seed = seed\n",
    "        self.n_jobs = n_jobs if n_jobs != -1 else None\n",
    "        self.study = None\n",
    "        self.best_model = None\n",
    "        self.best_params = None\n",
    "        self.feature_names = None  # Store feature names\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_numeric_value(value):\n",
    "        \"\"\"Convert string values to numeric, handling special cases\"\"\"\n",
    "        if pd.isna(value):\n",
    "            return np.nan\n",
    "        if isinstance(value, str):\n",
    "            # Remove any non-numeric characters except minus, decimal point\n",
    "            cleaned = re.sub(r'[^\\d.-]', '', value)\n",
    "            try:\n",
    "                return float(cleaned) if cleaned else np.nan\n",
    "            except ValueError:\n",
    "                return np.nan\n",
    "        return float(value)\n",
    "\n",
    "    def objective(self, trial, dtrain, num_boost_round=500):\n",
    "        \"\"\"Objective function with enhanced regularization\"\"\"\n",
    "        params = {\n",
    "            'eta': trial.suggest_float('eta', 0.005, 0.1, log=True),  # Lower learning rate\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 4),  # Shallower trees\n",
    "            'subsample': trial.suggest_float('subsample', 0.4, 0.7),  # Lower subsampling\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 0.7),  # Lower feature sampling\n",
    "            'colsample_bylevel': trial.suggest_float('colsample_bylevel', 0.4, 0.7),\n",
    "            'min_child_weight': trial.suggest_int('min_child_weight', 10, 20),  # Higher min child weight\n",
    "            'lambda': trial.suggest_float('lambda', 10, 25.0),  # Stronger L2 regularization\n",
    "            'alpha': trial.suggest_float('alpha', 5.0, 15.0),  # Stronger L1 regularization\n",
    "            'gamma': trial.suggest_float('gamma', 0.5, 2.0),  # Higher pruning parameter\n",
    "            'max_delta_step': trial.suggest_int('max_delta_step', 0, 1),\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'verbosity': 0,\n",
    "            'seed': self.seed,\n",
    "            'nthread': 1\n",
    "        }\n",
    "\n",
    "        cv_results = xgb.cv(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=800,  # More rounds but more conservative early stopping\n",
    "            nfold=5,\n",
    "            metrics='rmse',\n",
    "            early_stopping_rounds=10,  # More conservative early stopping\n",
    "            as_pandas=True,\n",
    "            seed=self.seed,\n",
    "            shuffle=True\n",
    "        )\n",
    "\n",
    "        # Stronger overfitting penalty\n",
    "        train_rmse = cv_results['train-rmse-mean'].iloc[-1]\n",
    "        val_rmse = cv_results['test-rmse-mean'].iloc[-1]\n",
    "        \n",
    "        # Calculate overfitting degree\n",
    "        overfitting_ratio = (train_rmse - val_rmse) / train_rmse\n",
    "        gap_penalty = max(0, overfitting_ratio) * 0.3  # Stronger penalty\n",
    "        \n",
    "        # Add extra penalty if severe overfitting\n",
    "        if overfitting_ratio > 0.1:\n",
    "            gap_penalty += (overfitting_ratio - 0.1) * 0.5\n",
    "            \n",
    "        return val_rmse + gap_penalty\n",
    "    \n",
    "    def tune_hyperparameters(self, dtrain, n_trials=10):  # Increased number of trials\n",
    "        \"\"\"Hyperparameter tuning focused on generalization\"\"\"\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        \n",
    "        print(\"Tuning hyperparameters with aggressive overfitting prevention...\")\n",
    "        print(\"Using very strong regularization and shallow trees\")\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=self.n_jobs) as executor:\n",
    "            futures = [executor.submit(lambda: study.optimize(\n",
    "                lambda trial: self.objective(trial, dtrain),\n",
    "                n_trials=5,\n",
    "                n_jobs=1\n",
    "            )) for _ in range(n_trials//5)]\n",
    "\n",
    "            for future in futures:\n",
    "                future.result()\n",
    "\n",
    "        self.study = study\n",
    "        self.best_params = study.best_params\n",
    "        self.best_params.update({\n",
    "            'objective': 'reg:squarederror',\n",
    "            'eval_metric': 'rmse',\n",
    "            'seed': self.seed,\n",
    "            'nthread': self.n_jobs\n",
    "        })\n",
    "\n",
    "        print(f\"Best parameters found: {self.best_params}\")\n",
    "        return self.best_params\n",
    "\n",
    "\n",
    "    def train_model(self, params, dtrain, dvalid=None, num_boost_round=500):\n",
    "        \"\"\"Train model with focus on preventing overfitting\"\"\"\n",
    "        evals = [(dtrain, 'train')]\n",
    "        if dvalid is not None:\n",
    "            evals.append((dvalid, 'valid'))\n",
    "\n",
    "        evals_result = {}\n",
    "        model = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=num_boost_round,\n",
    "            evals=evals,\n",
    "            early_stopping_rounds=25,  # More conservative early stopping\n",
    "            verbose_eval=100,  # Reduced output frequency\n",
    "            evals_result=evals_result\n",
    "        )\n",
    "\n",
    "        self.feature_names = dtrain.feature_names\n",
    "        if self.feature_names is None:\n",
    "            self.feature_names = [f'f{i}' for i in range(dtrain.num_col())]\n",
    "            model.feature_names = self.feature_names\n",
    "\n",
    "        return model, evals_result\n",
    "\n",
    "    def cross_validate(self, params, X, y, n_splits=5, cv_models_dir='cv_models', n_repeats=10): \n",
    "        \"\"\"Enhanced CV with 10 repetitions of 5-fold cross-validation and model saving\"\"\"\n",
    "        Path(cv_models_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        all_cv_results = {\n",
    "            'train_rmse': [], 'val_rmse': [],\n",
    "            'train_r2': [], 'val_r2': [],\n",
    "            'best_iterations': [],\n",
    "            'model_paths': [],\n",
    "            'feature_names': [],\n",
    "            'repeat': [],\n",
    "            'fold': []\n",
    "        }\n",
    "\n",
    "        def process_fold(repeat_idx, fold_idx, train_idx, val_idx):\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "            dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=X_train.columns.tolist())\n",
    "            dval = xgb.DMatrix(X_val, label=y_val, feature_names=X_train.columns.tolist())\n",
    "\n",
    "            model, _ = self.train_model(params, dtrain, dval)\n",
    "\n",
    "            # Save the CV model\n",
    "            model_path = os.path.join(cv_models_dir, f'cv_model_repeat_{repeat_idx}_fold_{fold_idx}.json')\n",
    "            model.save_model(model_path)\n",
    "\n",
    "            train_pred = model.predict(dtrain)\n",
    "            val_pred = model.predict(dval)\n",
    "\n",
    "            return (\n",
    "                np.sqrt(mean_squared_error(y_train, train_pred)),\n",
    "                np.sqrt(mean_squared_error(y_val, val_pred)),\n",
    "                r2_score(y_train, train_pred),\n",
    "                r2_score(y_val, val_pred),\n",
    "                model.best_iteration if hasattr(model, 'best_iteration') else params.get('num_boost_round', 500),\n",
    "                model_path,\n",
    "                model.feature_names,\n",
    "                repeat_idx,\n",
    "                fold_idx\n",
    "            )\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=self.n_jobs) as executor:\n",
    "            futures = []\n",
    "            for repeat_idx in range(n_repeats):\n",
    "                kf = KFold(n_splits=n_splits, shuffle=True, random_state=self.seed + repeat_idx)\n",
    "                for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X)):\n",
    "                    futures.append(executor.submit(\n",
    "                        process_fold, repeat_idx, fold_idx, train_idx, val_idx\n",
    "                    ))\n",
    "\n",
    "            for future in futures:\n",
    "                train_rmse, val_rmse, train_r2, val_r2, best_iter, model_path, feature_names, repeat_idx, fold_idx = future.result()\n",
    "                all_cv_results['train_rmse'].append(train_rmse)\n",
    "                all_cv_results['val_rmse'].append(val_rmse)\n",
    "                all_cv_results['train_r2'].append(train_r2)\n",
    "                all_cv_results['val_r2'].append(val_r2)\n",
    "                all_cv_results['best_iterations'].append(best_iter)\n",
    "                all_cv_results['model_paths'].append(model_path)\n",
    "                all_cv_results['feature_names'].append(feature_names)\n",
    "                all_cv_results['repeat'].append(repeat_idx)\n",
    "                all_cv_results['fold'].append(fold_idx)\n",
    "        # Create summary statistics\n",
    "        cv_results_summary = {\n",
    "            'train_rmse_mean': np.mean(all_cv_results['train_rmse']),\n",
    "            'train_rmse_std': np.std(all_cv_results['train_rmse']),\n",
    "            'val_rmse_mean': np.mean(all_cv_results['val_rmse']),\n",
    "            'val_rmse_std': np.std(all_cv_results['val_rmse']),\n",
    "            'train_r2_mean': np.mean(all_cv_results['train_r2']),\n",
    "            'train_r2_std': np.std(all_cv_results['train_r2']),\n",
    "            'val_r2_mean': np.mean(all_cv_results['val_r2']),\n",
    "            'val_r2_std': np.std(all_cv_results['val_r2']),\n",
    "            'best_iterations_mean': np.mean(all_cv_results['best_iterations']),\n",
    "            'best_iterations_std': np.std(all_cv_results['best_iterations']),\n",
    "            'detailed_results': pd.DataFrame(all_cv_results)\n",
    "        }\n",
    "\n",
    "        return cv_results_summary\n",
    "\n",
    "    def evaluate_model(self, model, dtest):\n",
    "        \"\"\"Evaluate model performance on test set\"\"\"\n",
    "        test_pred = model.predict(dtest)\n",
    "        return {\n",
    "            'rmse': np.sqrt(mean_squared_error(dtest.get_label(), test_pred)),\n",
    "            'r2': r2_score(dtest.get_label(), test_pred),\n",
    "            'mae': mean_absolute_error(dtest.get_label(), test_pred)\n",
    "        }, test_pred\n",
    "\n",
    "    def plot_learning_curves(self, evals_result, title_suffix):\n",
    "        \"\"\"Plot training and validation metrics\"\"\"\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        epochs = len(evals_result['train']['rmse'])\n",
    "        plt.plot(range(epochs), evals_result['train']['rmse'], label='Train RMSE')\n",
    "        if 'valid' in evals_result:\n",
    "            plt.plot(range(epochs), evals_result['valid']['rmse'], label='Validation RMSE')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('RMSE')\n",
    "        plt.title(f'Learning Curves - {title_suffix}')\n",
    "        plt.show()\n",
    "\n",
    "    def plot_cv_results(self, cv_results_summary):\n",
    "        \"\"\"Plot enhanced cross-validation results with both original and new visualization\"\"\"\n",
    "        # Check if it's the new summary format or old list format\n",
    "        if isinstance(cv_results_summary, dict) and 'detailed_results' in cv_results_summary:\n",
    "            # New format - use the detailed results\n",
    "            detailed_results = cv_results_summary['detailed_results']\n",
    "            \n",
    "            # Create two visualizations:\n",
    "            # 1. Original visualization (simple line plot for first repeat)\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            \n",
    "            # Plot 1: Original style - first repeat only\n",
    "            plt.subplot(2, 2, 1)\n",
    "            first_repeat = detailed_results[detailed_results['repeat'] == 0]\n",
    "            plt.plot(first_repeat['train_rmse'], 'o-', label='Train RMSE')\n",
    "            plt.plot(first_repeat['val_rmse'], 'o-', label='Validation RMSE')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.title('Cross-Validation RMSE (First Repeat)')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Plot 2: Original style - first repeat R²\n",
    "            plt.subplot(2, 2, 2)\n",
    "            plt.plot(first_repeat['train_r2'], 'o-', label='Train R²')\n",
    "            plt.plot(first_repeat['val_r2'], 'o-', label='Validation R²')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('R² Score')\n",
    "            plt.title('Cross-Validation R² Scores (First Repeat)')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Plot 3: New visualization - RMSE distribution across all repeats\n",
    "            plt.subplot(2, 2, 3)\n",
    "            plt.boxplot([detailed_results['train_rmse'], detailed_results['val_rmse']], \n",
    "                       labels=['Train RMSE', 'Validation RMSE'])\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.title('RMSE Distribution across 10x5 CV')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Plot 4: New visualization - R² distribution across all repeats\n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.boxplot([detailed_results['train_r2'], detailed_results['val_r2']], \n",
    "                       labels=['Train R²', 'Validation R²'])\n",
    "            plt.ylabel('R² Score')\n",
    "            plt.title('R² Distribution across 10x5 CV')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Print summary statistics\n",
    "            print(\"\\n=== 10x5 Cross-Validation Summary ===\")\n",
    "            print(f\"Average Train RMSE: {cv_results_summary['train_rmse_mean']:.4f} (±{cv_results_summary['train_rmse_std']:.4f})\")\n",
    "            print(f\"Average Validation RMSE: {cv_results_summary['val_rmse_mean']:.4f} (±{cv_results_summary['val_rmse_std']:.4f})\")\n",
    "            print(f\"Average Train R²: {cv_results_summary['train_r2_mean']:.4f} (±{cv_results_summary['train_r2_std']:.4f})\")\n",
    "            print(f\"Average Validation R²: {cv_results_summary['val_r2_mean']:.4f} (±{cv_results_summary['val_r2_std']:.4f})\")\n",
    "            print(f\"Average Best Iterations: {cv_results_summary['best_iterations_mean']:.1f} (±{cv_results_summary['best_iterations_std']:.1f})\")\n",
    "            \n",
    "            # Also print the format that main() expects\n",
    "            print(\"\\n=== 交叉验证结果 (旧格式兼容) ===\")\n",
    "            print(f\"平均训练RMSE: {cv_results_summary['train_rmse_mean']:.4f} (±{cv_results_summary['train_rmse_std']:.4f})\")\n",
    "            print(f\"平均验证RMSE: {cv_results_summary['val_rmse_mean']:.4f} (±{cv_results_summary['val_rmse_std']:.4f})\")\n",
    "            print(f\"平均训练R²: {cv_results_summary['train_r2_mean']:.4f} (±{cv_results_summary['train_r2_std']:.4f})\")\n",
    "            print(f\"平均验证R²: {cv_results_summary['val_r2_mean']:.4f} (±{cv_results_summary['val_r2_std']:.4f})\")\n",
    "            \n",
    "        else:\n",
    "            # Old format - keep original plotting\n",
    "            plt.figure(figsize=(15, 5))\n",
    "\n",
    "            # Plot RMSE\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.plot(cv_results_summary['train_rmse'], 'o-', label='Train RMSE')\n",
    "            plt.plot(cv_results_summary['val_rmse'], 'o-', label='Validation RMSE')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('RMSE')\n",
    "            plt.title('Cross-Validation RMSE')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            # Plot R2\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(cv_results_summary['train_r2'], 'o-', label='Train R²')\n",
    "            plt.plot(cv_results_summary['val_r2'], 'o-', label='Validation R²')\n",
    "            plt.xlabel('Fold')\n",
    "            plt.ylabel('R² Score')\n",
    "            plt.title('Cross-Validation R² Scores')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    def plot_final_model_performance(self, model, dtest):\n",
    "        \"\"\"Plot actual vs predicted values for test set\"\"\"\n",
    "        test_metrics, test_pred = self.evaluate_model(model, dtest)\n",
    "        y_test = dtest.get_label()\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        # Scatter plot of actual vs predicted\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.scatter(y_test, test_pred, alpha=0.5)\n",
    "        plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], '--r')\n",
    "        plt.xlabel('Actual Values')\n",
    "        plt.ylabel('Predicted Values')\n",
    "        plt.title(f'Actual vs Predicted (R² = {test_metrics[\"r2\"]:.3f})')\n",
    "\n",
    "        # Residual plot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        residuals = y_test - test_pred\n",
    "        plt.scatter(test_pred, residuals, alpha=0.5)\n",
    "        plt.axhline(y=0, color='r', linestyle='--')\n",
    "        plt.xlabel('Predicted Values')\n",
    "        plt.ylabel('Residuals')\n",
    "        plt.title('Residual Plot')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    def plot_feature_importance(self, model, importance_type='weight', top_n=30):\n",
    "        \"\"\"Plot feature importance without category-specific highlighting\"\"\"\n",
    "        fig, ax = plt.subplots(figsize=(12, 10))\n",
    "        \n",
    "    \n",
    "        importance_dict = model.get_score(importance_type=importance_type)\n",
    "        \n",
    "        if not importance_dict:\n",
    "            print(\"No feature importance data available.\")\n",
    "            return None\n",
    "            \n",
    "\n",
    "        importance_df = pd.DataFrame({\n",
    "            'feature': list(importance_dict.keys()),\n",
    "            'importance': list(importance_dict.values())\n",
    "        }).sort_values('importance', ascending=True)\n",
    "        \n",
    "\n",
    "        if len(importance_df) > top_n:\n",
    "            importance_df = importance_df.tail(top_n)\n",
    "        \n",
    "\n",
    "        y_pos = np.arange(len(importance_df))\n",
    "        colors = ['lightblue'] * len(importance_df)\n",
    "        \n",
    "        ax.barh(y_pos, importance_df['importance'], color=colors, alpha=0.8)\n",
    "        ax.set_yticks(y_pos)\n",
    "        ax.set_yticklabels(importance_df['feature'])\n",
    "        ax.set_xlabel('Importance')\n",
    "        \n",
    "        title = f'Feature Importance ({importance_type})'\n",
    "        ax.set_title(title)\n",
    "        \n",
    "\n",
    "        lu_type_features = importance_df[importance_df['feature'].str.contains('LUtype', na=False)]\n",
    "        lu_type_importance = lu_type_features['importance'].sum() if not lu_type_features.empty else 0\n",
    "        \n",
    "        ax.text(0.7, 0.95, f'LUtype total: {lu_type_importance:.3f}', \n",
    "                transform=ax.transAxes, fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\"))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return importance_df\n",
    "\n",
    "    def analyze_lutype_importance(self, model, X):\n",
    "     \n",
    "        importance_dict = model.get_score(importance_type='weight')\n",
    "        \n",
    "        if not importance_dict:\n",
    "            print(\"No feature importance data available.\")\n",
    "            return\n",
    "            \n",
    "\n",
    "        lutype_features = {k: v for k, v in importance_dict.items() if 'LUtype' in k}\n",
    "        other_features = {k: v for k, v in importance_dict.items() if 'LUtype' not in k}\n",
    "        \n",
    "        print(f\"\\n=== LUtype Feature Importance Analysis ===\")\n",
    "        print(f\"Total LUtype-related features: {len(lutype_features)}\")\n",
    "        print(f\"Total importance of LUtype features: {sum(lutype_features.values()):.3f}\")\n",
    "        print(f\"Average importance of LUtype features: {np.mean(list(lutype_features.values())) if lutype_features else 0:.3f}\")\n",
    "        \n",
    "        total_importance = sum(importance_dict.values())\n",
    "        lu_type_percentage = (sum(lutype_features.values()) / total_importance * 100) if total_importance > 0 else 0\n",
    "        \n",
    "        print(f\"\\nLUtype importance percentage: {lu_type_percentage:.2f}%\")\n",
    "        \n",
    "     \n",
    "        if lutype_features:\n",
    "            sorted_lutype = sorted(lutype_features.items(), key=lambda x: x[1], reverse=True)\n",
    "            print(f\"\\nTop LUtype-related features:\")\n",
    "            for feature, importance in sorted_lutype[:10]:\n",
    "                print(f\"  {feature}: {importance:.4f}\")\n",
    "        else:\n",
    "            print(\"\\nNo LUtype-related features found in importance scores.\")\n",
    "\n",
    "    def plot_shap_summary(self, model, X, feature_names=None):\n",
    "        \"\"\"Generate SHAP summary plot if SHAP is available\"\"\"\n",
    "        if SHAP_AVAILABLE:\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(X)\n",
    "\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            shap.summary_plot(shap_values, X, feature_names=feature_names)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"SHAP not available. Install with: pip install shap\")\n",
    "\n",
    "    def save_results(self, model, output_dir='results'):\n",
    "        \"\"\"Save all results to disk including feature names\"\"\"\n",
    "        Path(output_dir).mkdir(exist_ok=True)\n",
    "\n",
    "        # Save model\n",
    "        model.save_model(f'{output_dir}/xgb_model.json')\n",
    "\n",
    "        # Save feature names\n",
    "        if self.feature_names is not None:\n",
    "            with open(f'{output_dir}/feature_names.txt', 'w') as f:\n",
    "                f.write('\\n'.join(self.feature_names))\n",
    "\n",
    "        # Save other artifacts\n",
    "        joblib.dump(self.best_params, f'{output_dir}/best_params.pkl')\n",
    "\n",
    "        if self.study:\n",
    "            joblib.dump(self.study, f'{output_dir}/study.pkl')\n",
    "            study_df = self.study.trials_dataframe()\n",
    "            study_df.to_csv(f'{output_dir}/trials.csv', index=False)\n",
    "\n",
    "def detect_outliers_iqr(df, columns, threshold=1.5):\n",
    "    \"\"\"Detect outliers using IQR method\"\"\"\n",
    "    outlier_indices = []\n",
    "    \n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - threshold * IQR\n",
    "            upper_bound = Q3 + threshold * IQR\n",
    "            \n",
    "            outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)].index\n",
    "            outlier_indices.extend(outliers)\n",
    "            \n",
    "            if len(outliers) > 0:\n",
    "                print(f\"  {col}: Found {len(outliers)} outliers \"\n",
    "                      f\"({len(outliers)/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    return list(set(outlier_indices))\n",
    "\n",
    "def remove_outliers_robust(df, y, columns, method='iqr', threshold=2.0):\n",
    "    \"\"\"Robust outlier handling method\"\"\"\n",
    "    print(\"Starting outlier detection...\")\n",
    "    \n",
    "    if method == 'iqr':\n",
    "        outlier_indices = detect_outliers_iqr(df, columns, threshold)\n",
    "    elif method == 'zscore':\n",
    "        # Z-score method\n",
    "        z_scores = np.abs(stats.zscore(df[columns]))\n",
    "        outlier_indices = np.where(z_scores > threshold)[0]\n",
    "        outlier_indices = list(outlier_indices)\n",
    "    else:\n",
    "        return df, y, []\n",
    "    \n",
    "    print(f\"\\nTotal outliers found: {len(outlier_indices)}\")\n",
    "    \n",
    "    if len(outlier_indices) > 0:\n",
    "        df_clean = df.drop(outlier_indices)\n",
    "        y_clean = y.drop(outlier_indices)\n",
    "        print(f\"Data size after removing outliers: {len(df_clean)} (removed {len(outlier_indices)} samples)\")\n",
    "        return df_clean, y_clean, outlier_indices\n",
    "    \n",
    "    print(\"No outliers found\")\n",
    "    return df, y, []\n",
    "\n",
    "def check_data_leakage(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Check for data leakage\"\"\"\n",
    "    print(\"\\n=== Data Leakage Check ===\")\n",
    "    \n",
    "    # Check for overlap between train and test sets\n",
    "    train_indices = set(X_train.index)\n",
    "    test_indices = set(X_test.index)\n",
    "    overlap = train_indices.intersection(test_indices)\n",
    "    \n",
    "    if overlap:\n",
    "        print(f\"❌ Data leakage detected: {len(overlap)} overlapping samples between train and test sets\")\n",
    "    else:\n",
    "        print(\"✅ No overlap between train and test sets\")\n",
    "    \n",
    "    # Check feature distributions\n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Test set size: {len(X_test)}\")\n",
    "    print(f\"Number of features: {X_train.shape[1]}\")\n",
    "    \n",
    "    return len(overlap) == 0\n",
    "\n",
    "def safe_feature_engineering(X_train, X_test):\n",
    "    \"\"\"Safe feature engineering to avoid data leakage\"\"\"\n",
    "    print(\"Performing safe feature engineering...\")\n",
    "    \n",
    "    # 1. Logarithmic transformation\n",
    "    columns_to_log = ['Lon', 'Lat', 'Age', 'BD', 'pH']\n",
    "    for col in columns_to_log:\n",
    "        if col in X_train.columns:\n",
    "            X_train[col + '_log'] = np.log(X_train[col] + 1e-8)\n",
    "            X_test[col + '_log'] = np.log(X_test[col] + 1e-8)\n",
    "            print(f\"  Created log feature: {col}_log\")\n",
    "    \n",
    "    # 2. Binning (based on training set quantiles)\n",
    "    if 'Altitude' in X_train.columns:\n",
    "        # Use training set to compute bin boundaries\n",
    "        alt_bins = pd.cut(X_train['Altitude'], bins=5, retbins=True)[1]\n",
    "        X_train['Altitude_bins'] = pd.cut(X_train['Altitude'], bins=alt_bins, labels=False)\n",
    "        X_test['Altitude_bins'] = pd.cut(X_test['Altitude'], bins=alt_bins, labels=False)\n",
    "        print(\"  Created binned feature: Altitude_bins\")\n",
    "    \n",
    "    return X_train, X_test\n",
    "\n",
    "def augment_continuous_features(X, y, continuous_cols, augmentation_factor=2, noise_scale=0.005, random_state=42):\n",
    "    \"\"\"\n",
    "    Augment continuous features with noise - with proper index resetting \n",
    "    to prevent alignment issues during training/evaluation.\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Reset indices to ensure positional indexing (iloc) matches the index\n",
    "    X = X.reset_index(drop=True)\n",
    "    y = y.reset_index(drop=True)\n",
    "    \n",
    "    n_samples = len(X)\n",
    "    n_augment = int(n_samples * augmentation_factor)\n",
    "\n",
    "    augmented_X_list = []\n",
    "    augmented_y_list = []\n",
    "\n",
    "    for _ in range(n_augment):\n",
    "        idx = np.random.randint(0, n_samples)\n",
    "        base_sample = X.iloc[idx].copy()\n",
    "        \n",
    "        # Add noise to specified continuous columns\n",
    "        for col in continuous_cols:\n",
    "            if col in base_sample:\n",
    "                std = X[col].std()\n",
    "                noise = np.random.normal(loc=0, scale=std * noise_scale)\n",
    "                \n",
    "                # Logical check: don't allow negative values for typically positive soil metrics\n",
    "                if col in ['BD', 'Age', 'Altitude'] or 'log' in col:\n",
    "                    base_sample[col] = max(1e-8, base_sample[col] + noise)\n",
    "                else:\n",
    "                    base_sample[col] += noise\n",
    "\n",
    "        augmented_X_list.append(base_sample)\n",
    "        augmented_y_list.append(y.iloc[idx])\n",
    "\n",
    "    # Efficiently combine original and augmented data\n",
    "    X_augmented = pd.concat([X, pd.DataFrame(augmented_X_list)], ignore_index=True)\n",
    "    y_augmented = pd.concat([y, pd.Series(augmented_y_list)], ignore_index=True)\n",
    "\n",
    "    return X_augmented, y_augmented\n",
    "\n",
    "def enhanced_load_and_prepare_data(augment=True, augmentation_factor=2, \n",
    "                                 lu_type_importance_boost=3.0, \n",
    "                                 outlier_threshold=2.0):\n",
    "    \"\"\"Fixed data leakage version with outlier handling\"\"\"\n",
    "    \n",
    "    # Load data\n",
    "    dtype_dict = {\n",
    "        'Soillayer': 'int8',\n",
    "        'yi': 'float32'\n",
    "    }\n",
    "\n",
    "    df_clean = pd.read_csv('F:/model/df.clean.yi.csv', dtype=dtype_dict)\n",
    "    data_predictor_VIF = pd.read_csv('F:/model/data.predictor.VIF.yi.csv')\n",
    "\n",
    "    # Select target soil layer\n",
    "    target_layer = \"subsoil\" ###################################################################################SELECT LAYER\n",
    "    df = df_clean[df_clean['Soillayer'] == (1 if target_layer == 'topsoil' else 2)].copy()\n",
    "\n",
    "    # Select features\n",
    "    predictor_columns = data_predictor_VIF['x'].tolist()\n",
    "    valid_x_cols = [col for col in predictor_columns if col != \"Soillayer\" and col in df.columns]\n",
    "\n",
    "    # Data cleaning\n",
    "    for col in valid_x_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    X = df[valid_x_cols].astype('float32').fillna(0)\n",
    "    y = df['yi'].astype('float32')\n",
    "\n",
    "    print(f\"Original data size: {len(X)}\")\n",
    "    \n",
    "    # Outlier detection and handling\n",
    "    continuous_cols = ['Lon', 'Lat', 'Age', 'BD', 'pH', 'Altitude']\n",
    "    continuous_cols = [col for col in continuous_cols if col in X.columns]\n",
    "    \n",
    "    print(\"\\n=== Outlier Handling ===\")\n",
    "    X_clean, y_clean, outliers = remove_outliers_robust(\n",
    "        X, y, continuous_cols, threshold=outlier_threshold\n",
    "    )\n",
    "\n",
    "    # Data splitting\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_clean, y_clean, test_size=0.3, random_state=42\n",
    "    )\n",
    "\n",
    "    # Safe feature engineering\n",
    "    X_train, X_test = safe_feature_engineering(X_train, X_test)\n",
    "\n",
    "    # Data leakage check\n",
    "    check_data_leakage(X_train, X_test, y_train, y_test)\n",
    "\n",
    "    # LUtype feature enhancement (only for training set)\n",
    "    if 'LUtype' in X_train.columns:\n",
    "        print(f\"\\n=== LUtype Feature Enhancement ===\")\n",
    "        print(f\"Original LUtype distribution:\")\n",
    "        print(X_train['LUtype'].value_counts().sort_index())\n",
    "        \n",
    "        print(f\"\\nEnhancing LUtype importance with factor: {lu_type_importance_boost}\")\n",
    "        \n",
    "        # Create LUtype feature enhancements\n",
    "        for i in range(int(lu_type_importance_boost) - 1):\n",
    "            lu_type_col_name = f'LUtype_boost_{i+1}'\n",
    "            X_train[lu_type_col_name] = X_train['LUtype']\n",
    "            X_test[lu_type_col_name] = X_test['LUtype']\n",
    "            print(f\"  Created LUtype copy: {lu_type_col_name}\")\n",
    "        \n",
    "        # Create interaction terms between LUtype and other important features\n",
    "        important_features = ['pH', 'BD', 'Age', 'Altitude']\n",
    "        for feature in important_features:\n",
    "            if feature in X_train.columns:\n",
    "                interaction_name = f'LUtype_{feature}_interaction'\n",
    "                X_train[interaction_name] = X_train['LUtype'] * X_train[feature]\n",
    "                X_test[interaction_name] = X_test['LUtype'] * X_test[feature]\n",
    "                print(f\"  Created interaction feature: {interaction_name}\")\n",
    "        \n",
    "        # Create LUtype squared term (non-linear effect)\n",
    "        X_train['LUtype_squared'] = X_train['LUtype'] ** 2\n",
    "        X_test['LUtype_squared'] = X_test['LUtype'] ** 2\n",
    "        print(\"  Created LUtype_squared\")\n",
    "    \n",
    "    # Data augmentation (only for training set)\n",
    "    if augment:\n",
    "        continuous_cols = [\n",
    "            'Lon', 'Lat', 'Age', 'BD', 'pH',\n",
    "            'Lon_log', 'Lat_log', 'Age_log', 'BD_log', 'pH_log',\n",
    "            'Altitude'\n",
    "        ]\n",
    "        continuous_cols = [col for col in continuous_cols if col in X_train.columns]\n",
    "        \n",
    "        print(f\"\\n=== Data Augmentation ===\")\n",
    "        print(f\"Training set size before augmentation: {len(X_train)}\")\n",
    "        X_train, y_train = augment_continuous_features(\n",
    "            X=X_train,  # Only augment training set\n",
    "            y=y_train,  # Only augment training set\n",
    "            continuous_cols=continuous_cols,\n",
    "            augmentation_factor=augmentation_factor,\n",
    "            noise_scale=0.005,  \n",
    "            random_state=42\n",
    "        )\n",
    "        print(f\"Training set size after augmentation: {len(X_train)}\")\n",
    "    else:\n",
    "        print(\"\\nSkipping data augmentation\")\n",
    "\n",
    "    print(f\"\\n=== Final Dataset Statistics ===\")\n",
    "    print(f\"Training set size: {len(X_train)}\")\n",
    "    print(f\"Test set size: {len(X_test)}\")\n",
    "    print(f\"Total number of features: {len(X_train.columns)}\")\n",
    "    \n",
    "    # Statistical feature distribution\n",
    "    lu_type_cols = [col for col in X_train.columns if 'LUtype' in col]\n",
    "    \n",
    "    print(f\"\\nFeature statistics:\")\n",
    "    print(f\"LUtype-related features: {len(lu_type_cols)}\")\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=X_train.columns.tolist())\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test, feature_names=X_train.columns.tolist())\n",
    "\n",
    "    return dtrain, dtest, X, y, X_test, y_test, X_train, y_train\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function with data leakage prevention\"\"\"\n",
    "    outlier_threshold = 1.0  # Outlier detection threshold\n",
    "    \n",
    "    print(\"=== Starting Enhanced XGBoost Modeling (Fixed Data Leakage Version) ===\")\n",
    "    \n",
    "    # Use fixed data processing (with outlier handling and data leakage prevention)\n",
    "    dtrain, dtest, x1, y1, X_test, y_test, X_train, y_train = enhanced_load_and_prepare_data(\n",
    "        augment=True,\n",
    "        augmentation_factor=3,\n",
    "        lu_type_importance_boost=3.0,\n",
    "        outlier_threshold=outlier_threshold\n",
    "    )\n",
    "\n",
    "    tuner = XGBoostTuner(seed=42, n_jobs=17)\n",
    "\n",
    "    # 1. Hyperparameter tuning\n",
    "    print(\"\\n=== Starting Hyperparameter Tuning ===\")\n",
    "    best_params = tuner.tune_hyperparameters(dtrain, n_trials=10)\n",
    "    print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "    # 2. Enhanced Cross-validation with 10x5 folds and model saving\n",
    "    print(\"\\n=== Starting 10x5 Cross-Validation ===\")\n",
    "    cv_results_summary = tuner.cross_validate(best_params, X_train, y_train, n_splits=5,\n",
    "                                              cv_models_dir='F:/model/results/cv_models',\n",
    "                                              n_repeats=10)  # 10 repetitions of 5-fold CV\n",
    "    \n",
    "    print(\"\\nSaved CV models:\")\n",
    "    for path in cv_results_summary['detailed_results']['model_paths'][:5]:  # Show first 5\n",
    "        print(f\"- {path}\")\n",
    "    print(f\"... and {len(cv_results_summary['detailed_results']['model_paths']) - 5} more\")\n",
    "    \n",
    "    # Plot enhanced CV results\n",
    "    print(\"\\nPlotting enhanced cross-validation results...\")\n",
    "    tuner.plot_cv_results(cv_results_summary)\n",
    "\n",
    "    # 3. Train final model\n",
    "    optimal_rounds = int(cv_results_summary['best_iterations_mean'])\n",
    "    print(f\"\\nTraining final model with {optimal_rounds} rounds...\")\n",
    "    final_model, evals_result = tuner.train_model(best_params, dtrain, num_boost_round=optimal_rounds)\n",
    "\n",
    "    # Plot learning curves\n",
    "    print(\"\\nPlotting learning curves...\")\n",
    "    tuner.plot_learning_curves(evals_result, \"Final Model\")\n",
    "\n",
    "    # 4. Evaluate and plot final performance\n",
    "    print(\"\\nEvaluating final model...\")\n",
    "    test_metrics, _ = tuner.evaluate_model(final_model, dtest)\n",
    "    print(\"\\n=== Final Test Metrics ===\")\n",
    "    print(f\"RMSE: {test_metrics['rmse']:.4f}\")\n",
    "    print(f\"R²: {test_metrics['r2']:.4f}\")\n",
    "    print(f\"MAE: {test_metrics['mae']:.4f}\")\n",
    "\n",
    "    print(\"\\nPlotting final model performance...\")\n",
    "    tuner.plot_final_model_performance(final_model, dtest)\n",
    "\n",
    "    # 5. Analyze LUtype importance\n",
    "    print(f\"\\nAnalyzing LUtype feature importance...\")\n",
    "    importance_df = tuner.plot_feature_importance(final_model, top_n=35)\n",
    "    \n",
    "    # Detailed analysis of LUtype importance\n",
    "    tuner.analyze_lutype_importance(final_model, X_test)\n",
    "    \n",
    "    # 6. SHAP analysis\n",
    "    if SHAP_AVAILABLE:\n",
    "        print(\"\\nGenerating SHAP summary plot...\")\n",
    "        tuner.plot_shap_summary(final_model, X_test)\n",
    "        \n",
    "    # 7. Save results\n",
    "    print(\"\\nSaving results...\")\n",
    "    tuner.save_results(final_model, 'F:/model/results')\n",
    "    \n",
    "    # Save CV results summary\n",
    "    cv_summary_path = 'F:/model/results/cv_summary.csv'\n",
    "    cv_results_summary['detailed_results'].to_csv(cv_summary_path, index=False)\n",
    "    print(f\"Saved detailed CV results to: {cv_summary_path}\")\n",
    "    \n",
    "    print(f\"\\n=== Model Training Summary ===\")\n",
    "    print(\"✓ Fixed data leakage issues\")\n",
    "    print(\"✓ Added outlier detection and handling\")\n",
    "    print(\"✓ Safe feature engineering (avoided data leakage)\")\n",
    "    print(\"✓ Created multiple LUtype feature copies\")\n",
    "    print(\"✓ Added LUtype interaction features with other important variables\")\n",
    "    print(\"✓ Added LUtype squared term (non-linear effect)\")\n",
    "    print(\"✓ Improved hyperparameter search space for better handling of categorical features\")\n",
    "    print(\"✓ Test set uses original data (no augmentation noise)\")\n",
    "    print(\"✓ Implemented 10 repetitions of 5-fold cross-validation for robust evaluation\")\n",
    "    \n",
    "    print(\"\\n=== Complete! ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d8139d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current climate mapping: topsoil\n",
    "import os\n",
    "import gc\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import xgboost as xgb\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ===================== Configuration =====================\n",
    "MODEL_PATH = 'F:/model/results/sixth/passive_top/xgb_model.json'# replace with 'active_sub','SOC_sub','passive_sub'\n",
    "FEATURE_NAMES_PATH = 'F:/model/results/sixth/passive_top/feature_names.txt'# replace with 'active_sub','SOC_sub','passive_sub'\n",
    "FEATURE_CSV_PATH = 'F:/model/Mapping_select_features.csv'# replace with correspongding SOC fractions and soil layers\n",
    "INPUT_TIF_FOLDER = 'F:/cleaned_tifs_no_extremes_iqr'\n",
    "OUTPUT_TIF_PATH = f'F:/model/results/passive_top.tif'# replace with 'active_sub','SOC_sub','passive_sub'\n",
    "\n",
    "\n",
    "N_JOBS = 4\n",
    "CHUNK_SIZE = 500\n",
    "# Threshold for NoData values (anything outside this range is treated as NaN)\n",
    "EXTREME_THRESHOLD = 1e10 \n",
    "# ======================================================\n",
    "\n",
    "MODEL_TO_TIF_MAP = {\n",
    "    'BD': 't_bd', 'pH': 't_ph', 'Sand': 't_sand', 'Silt': 't_silt',\n",
    "    'Clay': 't_clay', 'TC': 't_oc', 'TN': 'TN13', 'TK': 'TK13',\n",
    "    'Altitude': 'Altitude', 'Lon': 'Lon', 'Lat': 'Lat', 'Age': 'Age',\n",
    "    'LUtype': 'LUtype', 'Vegetype': 'Vege_type', 'Recovmode': 'Recovery_mode'\n",
    "}\n",
    "\n",
    "TIF_TO_MODEL_MAP = {v: k for k, v in MODEL_TO_TIF_MAP.items()}\n",
    "KEY_FEATURES = ['LUtype', 'Altitude', 'Lon', 'Lat', 'BD', 'pH', 'Vegetype', 'Recovmode']\n",
    "\n",
    "def clean_extreme_values(array):\n",
    "    \"\"\"Replaces infinity and extreme NoData placeholders with NaN\"\"\"\n",
    "    if array is None: return None\n",
    "    # Handle infinities\n",
    "    array = np.where(np.isinf(array), np.nan, array)\n",
    "    # Handle extreme scientific notation (e.g., -3.4e+38)\n",
    "    array = np.where(np.abs(array) > EXTREME_THRESHOLD, np.nan, array)\n",
    "    return array\n",
    "\n",
    "def check_data_quality(df_chunk, model_feature_names):\n",
    "    issues = []\n",
    "    for feat in model_feature_names:\n",
    "        if feat in df_chunk.columns:\n",
    "            data = df_chunk[feat].values\n",
    "            nan_count = np.sum(np.isnan(data))\n",
    "            if nan_count > 0:\n",
    "                issues.append(f\"{feat}: {nan_count} NaN values\")\n",
    "            \n",
    "            finite_mask = np.isfinite(data)\n",
    "            if np.any(finite_mask):\n",
    "                finite_data = data[finite_mask]\n",
    "                issues.append(f\"{feat}: Range [{finite_data.min():.2f}, {finite_data.max():.2f}]\")\n",
    "    return issues\n",
    "\n",
    "def load_tif_to_chunk(feat_name, tif_folder, chunk_start, chunk_end, ref_shape, coords_x, coords_y):\n",
    "    tif_filename = None\n",
    "    if feat_name in MODEL_TO_TIF_MAP:\n",
    "        tif_base = MODEL_TO_TIF_MAP[feat_name]\n",
    "        tif_filename = f\"{tif_base}.tif\"\n",
    "    elif f\"{feat_name}.tif\" in os.listdir(tif_folder):\n",
    "        tif_filename = f\"{feat_name}.tif\"\n",
    "    \n",
    "    if not tif_filename: return None\n",
    "    tif_path = os.path.join(tif_folder, tif_filename)\n",
    "    if not os.path.exists(tif_path): return None\n",
    "\n",
    "    try:\n",
    "        with rxr.open_rasterio(tif_path, masked=True) as da:\n",
    "            da_squeezed = da.squeeze()\n",
    "            if feat_name in ['Lon', 'Lat'] or MODEL_TO_TIF_MAP.get(feat_name) in ['Lon', 'Lat']:\n",
    "                if 'Lon' in feat_name or MODEL_TO_TIF_MAP.get(feat_name) == 'Lon':\n",
    "                    chunk_values = np.tile(coords_x.values, (chunk_end - chunk_start, 1))\n",
    "                    model_feat_name = 'Lon'\n",
    "                else:\n",
    "                    lat_values = coords_y.isel(y=slice(chunk_start, chunk_end)).values.reshape(-1, 1)\n",
    "                    chunk_values = np.tile(lat_values, (1, ref_shape[1]))\n",
    "                    model_feat_name = 'Lat'\n",
    "            else:\n",
    "                chunk_values = da_squeezed.isel(y=slice(chunk_start, chunk_end)).values\n",
    "                model_feat_name = TIF_TO_MODEL_MAP.get(feat_name, feat_name)\n",
    "\n",
    "            if np.ma.is_masked(chunk_values):\n",
    "                chunk_values = chunk_values.filled(np.nan)\n",
    "            \n",
    "            # CRITICAL: Clean the data immediately after loading\n",
    "            flat_values = chunk_values.reshape(-1).astype(np.float32)\n",
    "            flat_values = clean_extreme_values(flat_values)\n",
    "            \n",
    "            return (model_feat_name, flat_values)\n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ Error loading {tif_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_dynamic_features(chunk_data, model_feature_names):\n",
    "    if not chunk_data: return {}\n",
    "    first_key = next(iter(chunk_data))\n",
    "    array_shape = chunk_data[first_key].shape\n",
    "    \n",
    "    lu_data = chunk_data.get('LUtype', np.zeros(array_shape, dtype=np.float32))\n",
    "    lu_data_filled = np.where(np.isnan(lu_data), 0, lu_data)\n",
    "    \n",
    "    # Example interactions\n",
    "    enhancements = {\n",
    "        'LUtype_boost_1': lu_data_filled,\n",
    "        'LUtype_boost_2': lu_data_filled * 2,\n",
    "        'LUtype_squared': lu_data_filled ** 2\n",
    "    }\n",
    "    \n",
    "    for name, data in enhancements.items():\n",
    "        if name in model_feature_names:\n",
    "            chunk_data[name] = data\n",
    "\n",
    "    interaction_pairs = [('pH', 'LUtype_pH_interaction'), ('BD', 'LUtype_BD_interaction')]\n",
    "    for base, inter in interaction_pairs:\n",
    "        if inter in model_feature_names:\n",
    "            base_data = chunk_data.get(base, np.zeros(array_shape))\n",
    "            base_filled = np.where(np.isnan(base_data), 0, base_data)\n",
    "            chunk_data[inter] = lu_data_filled * base_filled\n",
    "\n",
    "    for feat in model_feature_names:\n",
    "        if feat not in chunk_data:\n",
    "            chunk_data[feat] = np.zeros(array_shape, dtype=np.float32)\n",
    "    return chunk_data\n",
    "\n",
    "def load_model_feature_names():\n",
    "    if os.path.exists(FEATURE_NAMES_PATH):\n",
    "        with open(FEATURE_NAMES_PATH, 'r') as f:\n",
    "            return [line.strip() for line in f.readlines() if line.strip()]\n",
    "    xgb_model = xgb.Booster(); xgb_model.load_model(MODEL_PATH)\n",
    "    return xgb_model.feature_names\n",
    "\n",
    "def conservative_process():\n",
    "    model_feature_names = load_model_feature_names()\n",
    "    \n",
    "    ref_tif_path = os.path.join(INPUT_TIF_FOLDER, \"Altitude.tif\")\n",
    "    ref_da = rxr.open_rasterio(ref_tif_path, masked=True).squeeze()\n",
    "    ref_shape = ref_da.shape\n",
    "    coords_x, coords_y = ref_da['x'], ref_da['y']\n",
    "    \n",
    "    xgb_model = xgb.Booster(); xgb_model.load_model(MODEL_PATH)\n",
    "    result_array = np.full(ref_shape, np.nan, dtype=np.float32)\n",
    "    \n",
    "    for chunk_start in range(0, ref_shape[0], CHUNK_SIZE):\n",
    "        chunk_end = min(chunk_start + CHUNK_SIZE, ref_shape[0])\n",
    "        total_pixels = (chunk_end - chunk_start) * ref_shape[1]\n",
    "        print(f\"\\n🚀 Processing Rows {chunk_start}-{chunk_end}\")\n",
    "\n",
    "        chunk_data = {}\n",
    "        for feat in set(KEY_FEATURES + model_feature_names):\n",
    "            loaded = load_tif_to_chunk(feat, INPUT_TIF_FOLDER, chunk_start, chunk_end, ref_shape, coords_x, coords_y)\n",
    "            if loaded: chunk_data[loaded[0]] = loaded[1]\n",
    "\n",
    "        chunk_data = create_dynamic_features(chunk_data, model_feature_names)\n",
    "        \n",
    "        # Build mask based on key features being valid (not NaN)\n",
    "        complete_mask = np.ones(total_pixels, dtype=bool)\n",
    "        for feat in KEY_FEATURES:\n",
    "            if feat in chunk_data:\n",
    "                \n",
    "                complete_mask &= (~np.isnan(chunk_data[feat]))\n",
    "        \n",
    "        indices = np.where(complete_mask)[0]\n",
    "        if len(indices) == 0: continue\n",
    "\n",
    "        # Prepare DataFrame\n",
    "        df_chunk = pd.DataFrame({f: chunk_data[f] for f in model_feature_names})\n",
    "        valid_df = df_chunk.iloc[indices].fillna(0) # XGBoost prefers 0 or a specific value for missing\n",
    "        \n",
    "        # Predict\n",
    "        dtest = xgb.DMatrix(valid_df.values, feature_names=model_feature_names)\n",
    "        preds = xgb_model.predict(dtest)\n",
    "        \n",
    "        # Remap to 2D\n",
    "        global_indices = (np.arange(total_pixels) + (chunk_start * ref_shape[1]))[indices]\n",
    "        result_array[global_indices // ref_shape[1], global_indices % ref_shape[1]] = preds\n",
    "        \n",
    "        gc.collect()\n",
    "\n",
    "    # Save\n",
    "    out_da = xr.DataArray(result_array, coords={\"y\": coords_y, \"x\": coords_x}, dims=(\"y\", \"x\"))\n",
    "    out_da.rio.to_raster(OUTPUT_TIF_PATH, compress=\"LZW\", nodata=np.nan)\n",
    "    print(f\"✅ Success! Saved to {OUTPUT_TIF_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    conservative_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a30826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current climate mapping: subsoil\n",
    "import os\n",
    "import gc\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import xgboost as xgb\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ===================== Configuration =====================\n",
    "MODEL_PATH = 'F:/model/results/xgb_model.json'# replace with 'active_sub','SOC_sub','passive_sub'\n",
    "FEATURE_NAMES_PATH = 'F:/model/results/feature_names.txt'# replace with 'active_sub','SOC_sub','passive_sub'\n",
    "FEATURE_CSV_PATH = 'F:/model/Mapping_select_features.csv'# replace with correspongding SOC fractions and soil layers\n",
    "INPUT_TIF_FOLDER = 'F:/cleaned_tifs_no_extremes_iqr'\n",
    "OUTPUT_TIF_PATH = f'F:/model/results/passive_sub.tif'# replace with 'active_sub','SOC_sub','passive_sub'\n",
    "\n",
    "\n",
    "N_JOBS = 4\n",
    "CHUNK_SIZE = 500\n",
    "# Threshold for NoData values (anything outside this range is treated as NaN)\n",
    "EXTREME_THRESHOLD = 1e10 \n",
    "# ======================================================\n",
    "\n",
    "MODEL_TO_TIF_MAP = {\n",
    "    'BD': 's_bd', 'pH': 's_ph', 'Sand': 's_sand', 'Silt': 's_silt',\n",
    "    'Clay': 's_clay', 'TC': 's_oc', 'TN': 'TN46', 'TK': 'TK46',\n",
    "    'Altitude': 'Altitude', 'Lon': 'Lon', 'Lat': 'Lat', 'Age': 'Age',\n",
    "    'LUtype': 'LUtype', 'Vegetype': 'Vege_type', 'Recovmode': 'Recovery_mode'\n",
    "}\n",
    "\n",
    "TIF_TO_MODEL_MAP = {v: k for k, v in MODEL_TO_TIF_MAP.items()}\n",
    "KEY_FEATURES = ['LUtype', 'Altitude', 'Lon', 'Lat', 'BD', 'pH', 'Vegetype', 'Recovmode']\n",
    "\n",
    "def clean_extreme_values(array):\n",
    "    \"\"\"Replaces infinity and extreme NoData placeholders with NaN\"\"\"\n",
    "    if array is None: return None\n",
    "    # Handle infinities\n",
    "    array = np.where(np.isinf(array), np.nan, array)\n",
    "    # Handle extreme scientific notation (e.g., -3.4e+38)\n",
    "    array = np.where(np.abs(array) > EXTREME_THRESHOLD, np.nan, array)\n",
    "    return array\n",
    "\n",
    "def check_data_quality(df_chunk, model_feature_names):\n",
    "    issues = []\n",
    "    for feat in model_feature_names:\n",
    "        if feat in df_chunk.columns:\n",
    "            data = df_chunk[feat].values\n",
    "            nan_count = np.sum(np.isnan(data))\n",
    "            if nan_count > 0:\n",
    "                issues.append(f\"{feat}: {nan_count} NaN values\")\n",
    "            \n",
    "            finite_mask = np.isfinite(data)\n",
    "            if np.any(finite_mask):\n",
    "                finite_data = data[finite_mask]\n",
    "                issues.append(f\"{feat}: Range [{finite_data.min():.2f}, {finite_data.max():.2f}]\")\n",
    "    return issues\n",
    "\n",
    "def load_tif_to_chunk(feat_name, tif_folder, chunk_start, chunk_end, ref_shape, coords_x, coords_y):\n",
    "    tif_filename = None\n",
    "    if feat_name in MODEL_TO_TIF_MAP:\n",
    "        tif_base = MODEL_TO_TIF_MAP[feat_name]\n",
    "        tif_filename = f\"{tif_base}.tif\"\n",
    "    elif f\"{feat_name}.tif\" in os.listdir(tif_folder):\n",
    "        tif_filename = f\"{feat_name}.tif\"\n",
    "    \n",
    "    if not tif_filename: return None\n",
    "    tif_path = os.path.join(tif_folder, tif_filename)\n",
    "    if not os.path.exists(tif_path): return None\n",
    "\n",
    "    try:\n",
    "        with rxr.open_rasterio(tif_path, masked=True) as da:\n",
    "            da_squeezed = da.squeeze()\n",
    "            if feat_name in ['Lon', 'Lat'] or MODEL_TO_TIF_MAP.get(feat_name) in ['Lon', 'Lat']:\n",
    "                if 'Lon' in feat_name or MODEL_TO_TIF_MAP.get(feat_name) == 'Lon':\n",
    "                    chunk_values = np.tile(coords_x.values, (chunk_end - chunk_start, 1))\n",
    "                    model_feat_name = 'Lon'\n",
    "                else:\n",
    "                    lat_values = coords_y.isel(y=slice(chunk_start, chunk_end)).values.reshape(-1, 1)\n",
    "                    chunk_values = np.tile(lat_values, (1, ref_shape[1]))\n",
    "                    model_feat_name = 'Lat'\n",
    "            else:\n",
    "                chunk_values = da_squeezed.isel(y=slice(chunk_start, chunk_end)).values\n",
    "                model_feat_name = TIF_TO_MODEL_MAP.get(feat_name, feat_name)\n",
    "\n",
    "            if np.ma.is_masked(chunk_values):\n",
    "                chunk_values = chunk_values.filled(np.nan)\n",
    "            \n",
    "            # CRITICAL: Clean the data immediately after loading\n",
    "            flat_values = chunk_values.reshape(-1).astype(np.float32)\n",
    "            flat_values = clean_extreme_values(flat_values)\n",
    "            \n",
    "            return (model_feat_name, flat_values)\n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ Error loading {tif_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_dynamic_features(chunk_data, model_feature_names):\n",
    "    if not chunk_data: return {}\n",
    "    first_key = next(iter(chunk_data))\n",
    "    array_shape = chunk_data[first_key].shape\n",
    "    \n",
    "    lu_data = chunk_data.get('LUtype', np.zeros(array_shape, dtype=np.float32))\n",
    "    lu_data_filled = np.where(np.isnan(lu_data), 0, lu_data)\n",
    "    \n",
    "    # Example interactions\n",
    "    enhancements = {\n",
    "        'LUtype_boost_1': lu_data_filled,\n",
    "        'LUtype_boost_2': lu_data_filled * 2,\n",
    "        'LUtype_squared': lu_data_filled ** 2\n",
    "    }\n",
    "    \n",
    "    for name, data in enhancements.items():\n",
    "        if name in model_feature_names:\n",
    "            chunk_data[name] = data\n",
    "\n",
    "    interaction_pairs = [('pH', 'LUtype_pH_interaction'), ('BD', 'LUtype_BD_interaction')]\n",
    "    for base, inter in interaction_pairs:\n",
    "        if inter in model_feature_names:\n",
    "            base_data = chunk_data.get(base, np.zeros(array_shape))\n",
    "            base_filled = np.where(np.isnan(base_data), 0, base_data)\n",
    "            chunk_data[inter] = lu_data_filled * base_filled\n",
    "\n",
    "    for feat in model_feature_names:\n",
    "        if feat not in chunk_data:\n",
    "            chunk_data[feat] = np.zeros(array_shape, dtype=np.float32)\n",
    "    return chunk_data\n",
    "\n",
    "def load_model_feature_names():\n",
    "    if os.path.exists(FEATURE_NAMES_PATH):\n",
    "        with open(FEATURE_NAMES_PATH, 'r') as f:\n",
    "            return [line.strip() for line in f.readlines() if line.strip()]\n",
    "    xgb_model = xgb.Booster(); xgb_model.load_model(MODEL_PATH)\n",
    "    return xgb_model.feature_names\n",
    "\n",
    "def conservative_process():\n",
    "    model_feature_names = load_model_feature_names()\n",
    "    \n",
    "    ref_tif_path = os.path.join(INPUT_TIF_FOLDER, \"Altitude.tif\")\n",
    "    ref_da = rxr.open_rasterio(ref_tif_path, masked=True).squeeze()\n",
    "    ref_shape = ref_da.shape\n",
    "    coords_x, coords_y = ref_da['x'], ref_da['y']\n",
    "    \n",
    "    xgb_model = xgb.Booster(); xgb_model.load_model(MODEL_PATH)\n",
    "    result_array = np.full(ref_shape, np.nan, dtype=np.float32)\n",
    "    \n",
    "    for chunk_start in range(0, ref_shape[0], CHUNK_SIZE):\n",
    "        chunk_end = min(chunk_start + CHUNK_SIZE, ref_shape[0])\n",
    "        total_pixels = (chunk_end - chunk_start) * ref_shape[1]\n",
    "        print(f\"\\n🚀 Processing Rows {chunk_start}-{chunk_end}\")\n",
    "\n",
    "        chunk_data = {}\n",
    "        for feat in set(KEY_FEATURES + model_feature_names):\n",
    "            loaded = load_tif_to_chunk(feat, INPUT_TIF_FOLDER, chunk_start, chunk_end, ref_shape, coords_x, coords_y)\n",
    "            if loaded: chunk_data[loaded[0]] = loaded[1]\n",
    "\n",
    "        chunk_data = create_dynamic_features(chunk_data, model_feature_names)\n",
    "        \n",
    "        # Build mask based on key features being valid (not NaN)\n",
    "        complete_mask = np.ones(total_pixels, dtype=bool)\n",
    "        for feat in KEY_FEATURES:\n",
    "            if feat in chunk_data:\n",
    "                complete_mask &= (~np.isnan(chunk_data[feat]))\n",
    "        \n",
    "        indices = np.where(complete_mask)[0]\n",
    "        if len(indices) == 0: continue\n",
    "\n",
    "        # Prepare DataFrame\n",
    "        df_chunk = pd.DataFrame({f: chunk_data[f] for f in model_feature_names})\n",
    "        valid_df = df_chunk.iloc[indices].fillna(0) # XGBoost prefers 0 or a specific value for missing\n",
    "        \n",
    "        # Predict\n",
    "        dtest = xgb.DMatrix(valid_df.values, feature_names=model_feature_names)\n",
    "        preds = xgb_model.predict(dtest)\n",
    "        \n",
    "        # Remap to 2D\n",
    "        global_indices = (np.arange(total_pixels) + (chunk_start * ref_shape[1]))[indices]\n",
    "        result_array[global_indices // ref_shape[1], global_indices % ref_shape[1]] = preds\n",
    "        \n",
    "        gc.collect()\n",
    "\n",
    "    # Save\n",
    "    out_da = xr.DataArray(result_array, coords={\"y\": coords_y, \"x\": coords_x}, dims=(\"y\", \"x\"))\n",
    "    out_da.rio.to_raster(OUTPUT_TIF_PATH, compress=\"LZW\", nodata=np.nan)\n",
    "    print(f\"✅ Success! Saved to {OUTPUT_TIF_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    conservative_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afcd954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# future climate mapping: topsoil\n",
    "import os\n",
    "import gc\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import xgboost as xgb\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ===================== Configuration =====================\n",
    "MODEL_PATH = 'F:/model/results/sixth/passive_top/xgb_model.json'# replace with 'active_top','SOC_top','passive_top'\n",
    "FEATURE_NAMES_PATH = 'F:/model/results/sixth/passive_top/feature_names.txt'# replace with 'active_top','SOC_top','passive_top'\n",
    "FEATURE_CSV_PATH = 'F:/model/Mapping_select_features.csv'# replace with 'active_top','SOC_top','passive_top'\n",
    "INPUT_TIF_FOLDER = 'F:/cleaned_tifs_no_extremes_iqr'\n",
    "OUTPUT_TIF_PATH = f'F:/model/results/passive_top_future.tif'# replace with 'active_top','SOC_top','passive_top'\n",
    "\n",
    "\n",
    "N_JOBS = 4\n",
    "CHUNK_SIZE = 500\n",
    "# Threshold for NoData values (anything outside this range is treated as NaN)\n",
    "EXTREME_THRESHOLD = 1e10 \n",
    "# ======================================================\n",
    "\n",
    "MODEL_TO_TIF_MAP = {\n",
    "    'BD': 't_bd', 'pH': 't_ph', 'Sand': 't_sand', 'Silt': 't_silt',\n",
    "    'Clay': 't_clay', 'TC': 't_oc', 'TN': 'TN13', 'TK': 'TK13',\n",
    "    'Altitude': 'Altitude', 'Lon': 'Lon', 'Lat': 'Lat', \n",
    "    'LUtype': 'LUtype', 'Vegetype': 'Vege_type', 'Recovmode': 'Recovery_mode',\n",
    "        'Age_plus100': 'Age',\n",
    "        'wc_BIO1_MAT': 'MAT',\n",
    "        'wc_BIO2': 'bio2',\n",
    "        'wc_BIO3': 'bio3',\n",
    "        'wc_BIO4': 'bio4',\n",
    "        'wc_BIO5': 'bio5',\n",
    "        'wc_BIO6': 'bio6',\n",
    "        'wc_BIO7': 'bio7',\n",
    "        'wc_BIO8': 'bio8',\n",
    "        'wc_BIO9': 'bio9',\n",
    "        'wc_BIO10': 'bio10',\n",
    "        'wc_BIO11': 'bio11',\n",
    "        'wc_BIO12_MAP': 'MAP',\n",
    "        'wc_BIO13': 'bio13',\n",
    "        'wc_BIO14': 'bio14',\n",
    "        'wc_BIO15': 'bio15',\n",
    "        'wc_BIO16': 'bio16',\n",
    "        'wc_BIO17': 'bio17',\n",
    "        'wc_BIO18': 'bio18',\n",
    "        'wc_BIO19': 'bio19'\n",
    "}\n",
    "\n",
    "TIF_TO_MODEL_MAP = {v: k for k, v in MODEL_TO_TIF_MAP.items()}\n",
    "KEY_FEATURES = ['LUtype', 'Altitude', 'Lon', 'Lat', 'BD', 'pH', 'Vegetype', 'Recovmode']\n",
    "\n",
    "def clean_extreme_values(array):\n",
    "    \"\"\"Replaces infinity and extreme NoData placeholders with NaN\"\"\"\n",
    "    if array is None: return None\n",
    "    # Handle infinities\n",
    "    array = np.where(np.isinf(array), np.nan, array)\n",
    "    # Handle extreme scientific notation (e.g., -3.4e+38)\n",
    "    array = np.where(np.abs(array) > EXTREME_THRESHOLD, np.nan, array)\n",
    "    return array\n",
    "\n",
    "def check_data_quality(df_chunk, model_feature_names):\n",
    "    issues = []\n",
    "    for feat in model_feature_names:\n",
    "        if feat in df_chunk.columns:\n",
    "            data = df_chunk[feat].values\n",
    "            nan_count = np.sum(np.isnan(data))\n",
    "            if nan_count > 0:\n",
    "                issues.append(f\"{feat}: {nan_count} NaN values\")\n",
    "            \n",
    "            finite_mask = np.isfinite(data)\n",
    "            if np.any(finite_mask):\n",
    "                finite_data = data[finite_mask]\n",
    "                issues.append(f\"{feat}: Range [{finite_data.min():.2f}, {finite_data.max():.2f}]\")\n",
    "    return issues\n",
    "\n",
    "def load_tif_to_chunk(feat_name, tif_folder, chunk_start, chunk_end, ref_shape, coords_x, coords_y):\n",
    "    tif_filename = None\n",
    "    if feat_name in MODEL_TO_TIF_MAP:\n",
    "        tif_base = MODEL_TO_TIF_MAP[feat_name]\n",
    "        tif_filename = f\"{tif_base}.tif\"\n",
    "    elif f\"{feat_name}.tif\" in os.listdir(tif_folder):\n",
    "        tif_filename = f\"{feat_name}.tif\"\n",
    "    \n",
    "    if not tif_filename: return None\n",
    "    tif_path = os.path.join(tif_folder, tif_filename)\n",
    "    if not os.path.exists(tif_path): return None\n",
    "\n",
    "    try:\n",
    "        with rxr.open_rasterio(tif_path, masked=True) as da:\n",
    "            da_squeezed = da.squeeze()\n",
    "            if feat_name in ['Lon', 'Lat'] or MODEL_TO_TIF_MAP.get(feat_name) in ['Lon', 'Lat']:\n",
    "                if 'Lon' in feat_name or MODEL_TO_TIF_MAP.get(feat_name) == 'Lon':\n",
    "                    chunk_values = np.tile(coords_x.values, (chunk_end - chunk_start, 1))\n",
    "                    model_feat_name = 'Lon'\n",
    "                else:\n",
    "                    lat_values = coords_y.isel(y=slice(chunk_start, chunk_end)).values.reshape(-1, 1)\n",
    "                    chunk_values = np.tile(lat_values, (1, ref_shape[1]))\n",
    "                    model_feat_name = 'Lat'\n",
    "            else:\n",
    "                chunk_values = da_squeezed.isel(y=slice(chunk_start, chunk_end)).values\n",
    "                model_feat_name = TIF_TO_MODEL_MAP.get(feat_name, feat_name)\n",
    "\n",
    "            if np.ma.is_masked(chunk_values):\n",
    "                chunk_values = chunk_values.filled(np.nan)\n",
    "            \n",
    "            # CRITICAL: Clean the data immediately after loading\n",
    "            flat_values = chunk_values.reshape(-1).astype(np.float32)\n",
    "            flat_values = clean_extreme_values(flat_values)\n",
    "            \n",
    "            return (model_feat_name, flat_values)\n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ Error loading {tif_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_dynamic_features(chunk_data, model_feature_names):\n",
    "    if not chunk_data: return {}\n",
    "    first_key = next(iter(chunk_data))\n",
    "    array_shape = chunk_data[first_key].shape\n",
    "    \n",
    "    lu_data = chunk_data.get('LUtype', np.zeros(array_shape, dtype=np.float32))\n",
    "    lu_data_filled = np.where(np.isnan(lu_data), 0, lu_data)\n",
    "    \n",
    "    # Example interactions\n",
    "    enhancements = {\n",
    "        'LUtype_boost_1': lu_data_filled,\n",
    "        'LUtype_boost_2': lu_data_filled * 2,\n",
    "        'LUtype_squared': lu_data_filled ** 2\n",
    "    }\n",
    "    \n",
    "    for name, data in enhancements.items():\n",
    "        if name in model_feature_names:\n",
    "            chunk_data[name] = data\n",
    "\n",
    "    interaction_pairs = [('pH', 'LUtype_pH_interaction'), ('BD', 'LUtype_BD_interaction')]\n",
    "    for base, inter in interaction_pairs:\n",
    "        if inter in model_feature_names:\n",
    "            base_data = chunk_data.get(base, np.zeros(array_shape))\n",
    "            base_filled = np.where(np.isnan(base_data), 0, base_data)\n",
    "            chunk_data[inter] = lu_data_filled * base_filled\n",
    "\n",
    "    for feat in model_feature_names:\n",
    "        if feat not in chunk_data:\n",
    "            chunk_data[feat] = np.zeros(array_shape, dtype=np.float32)\n",
    "    return chunk_data\n",
    "\n",
    "def load_model_feature_names():\n",
    "    if os.path.exists(FEATURE_NAMES_PATH):\n",
    "        with open(FEATURE_NAMES_PATH, 'r') as f:\n",
    "            return [line.strip() for line in f.readlines() if line.strip()]\n",
    "    xgb_model = xgb.Booster(); xgb_model.load_model(MODEL_PATH)\n",
    "    return xgb_model.feature_names\n",
    "\n",
    "def conservative_process():\n",
    "    model_feature_names = load_model_feature_names()\n",
    "    \n",
    "    ref_tif_path = os.path.join(INPUT_TIF_FOLDER, \"Altitude.tif\")\n",
    "    ref_da = rxr.open_rasterio(ref_tif_path, masked=True).squeeze()\n",
    "    ref_shape = ref_da.shape\n",
    "    coords_x, coords_y = ref_da['x'], ref_da['y']\n",
    "    \n",
    "    xgb_model = xgb.Booster(); xgb_model.load_model(MODEL_PATH)\n",
    "    result_array = np.full(ref_shape, np.nan, dtype=np.float32)\n",
    "    \n",
    "    for chunk_start in range(0, ref_shape[0], CHUNK_SIZE):\n",
    "        chunk_end = min(chunk_start + CHUNK_SIZE, ref_shape[0])\n",
    "        total_pixels = (chunk_end - chunk_start) * ref_shape[1]\n",
    "        print(f\"\\n🚀 Processing Rows {chunk_start}-{chunk_end}\")\n",
    "\n",
    "        chunk_data = {}\n",
    "        for feat in set(KEY_FEATURES + model_feature_names):\n",
    "            loaded = load_tif_to_chunk(feat, INPUT_TIF_FOLDER, chunk_start, chunk_end, ref_shape, coords_x, coords_y)\n",
    "            if loaded: chunk_data[loaded[0]] = loaded[1]\n",
    "\n",
    "        chunk_data = create_dynamic_features(chunk_data, model_feature_names)\n",
    "        \n",
    "        # Build mask based on key features being valid (not NaN)\n",
    "        complete_mask = np.ones(total_pixels, dtype=bool)\n",
    "        for feat in KEY_FEATURES:\n",
    "            if feat in chunk_data:\n",
    "                \n",
    "                complete_mask &= (~np.isnan(chunk_data[feat]))\n",
    "        \n",
    "        indices = np.where(complete_mask)[0]\n",
    "        if len(indices) == 0: continue\n",
    "\n",
    "        # Prepare DataFrame\n",
    "        df_chunk = pd.DataFrame({f: chunk_data[f] for f in model_feature_names})\n",
    "        valid_df = df_chunk.iloc[indices].fillna(0) # XGBoost prefers 0 or a specific value for missing\n",
    "        \n",
    "        # Predict\n",
    "        dtest = xgb.DMatrix(valid_df.values, feature_names=model_feature_names)\n",
    "        preds = xgb_model.predict(dtest)\n",
    "        \n",
    "        # Remap to 2D\n",
    "        global_indices = (np.arange(total_pixels) + (chunk_start * ref_shape[1]))[indices]\n",
    "        result_array[global_indices // ref_shape[1], global_indices % ref_shape[1]] = preds\n",
    "        \n",
    "        gc.collect()\n",
    "\n",
    "    # Save\n",
    "    out_da = xr.DataArray(result_array, coords={\"y\": coords_y, \"x\": coords_x}, dims=(\"y\", \"x\"))\n",
    "    out_da.rio.to_raster(OUTPUT_TIF_PATH, compress=\"LZW\", nodata=np.nan)\n",
    "    print(f\"✅ Success! Saved to {OUTPUT_TIF_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    conservative_process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0904ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# future climate mapping: subsoil\n",
    "import os\n",
    "import gc\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import xgboost as xgb\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ===================== Configuration =====================\n",
    "MODEL_PATH = 'F:/model/results/sixth/active_sub/xgb_model.json'# replace with 'active_sub','SOC_sub','passive_sub'\n",
    "FEATURE_NAMES_PATH = 'F:/model/results/sixth/active_sub/feature_names.txt'# replace with 'active_sub','SOC_sub','passive_sub'\n",
    "FEATURE_CSV_PATH = 'F:/model/Mapping_select_features.csv'\n",
    "INPUT_TIF_FOLDER = 'F:/cleaned_tifs_no_extremes_iqr'\n",
    "OUTPUT_TIF_PATH = f'F:/model/results/active_sub_future.tif'# replace with 'active_sub','SOC_sub','passive_sub'\n",
    "\n",
    "\n",
    "N_JOBS = 4\n",
    "CHUNK_SIZE = 500\n",
    "# Threshold for NoData values (anything outside this range is treated as NaN)\n",
    "EXTREME_THRESHOLD = 1e10 \n",
    "# ======================================================\n",
    "\n",
    "MODEL_TO_TIF_MAP = {\n",
    "    'BD': 's_bd', 'pH': 's_ph', 'Sand': 's_sand', 'Silt': 's_silt',\n",
    "    'Clay': 's_clay', 'TC': 's_oc', 'TN': 'TN46', 'TK': 'TK46',\n",
    "    'Altitude': 'Altitude', 'Lon': 'Lon', 'Lat': 'Lat', \n",
    "    'LUtype': 'LUtype', 'Vegetype': 'Vege_type', 'Recovmode': 'Recovery_mode',\n",
    "        'Age_plus100': 'Age',\n",
    "        'wc_BIO1_MAT': 'MAT',\n",
    "        'wc_BIO2': 'bio2',\n",
    "        'wc_BIO3': 'bio3',\n",
    "        'wc_BIO4': 'bio4',\n",
    "        'wc_BIO5': 'bio5',\n",
    "        'wc_BIO6': 'bio6',\n",
    "        'wc_BIO7': 'bio7',\n",
    "        'wc_BIO8': 'bio8',\n",
    "        'wc_BIO9': 'bio9',\n",
    "        'wc_BIO10': 'bio10',\n",
    "        'wc_BIO11': 'bio11',\n",
    "        'wc_BIO12_MAP': 'MAP',\n",
    "        'wc_BIO13': 'bio13',\n",
    "        'wc_BIO14': 'bio14',\n",
    "        'wc_BIO15': 'bio15',\n",
    "        'wc_BIO16': 'bio16',\n",
    "        'wc_BIO17': 'bio17',\n",
    "        'wc_BIO18': 'bio18',\n",
    "        'wc_BIO19': 'bio19'\n",
    "\n",
    "}\n",
    "\n",
    "TIF_TO_MODEL_MAP = {v: k for k, v in MODEL_TO_TIF_MAP.items()}\n",
    "KEY_FEATURES = ['LUtype', 'Altitude', 'Lon', 'Lat', 'BD', 'pH', 'Vegetype', 'Recovmode']\n",
    "\n",
    "def clean_extreme_values(array):\n",
    "    \"\"\"Replaces infinity and extreme NoData placeholders with NaN\"\"\"\n",
    "    if array is None: return None\n",
    "    # Handle infinities\n",
    "    array = np.where(np.isinf(array), np.nan, array)\n",
    "    # Handle extreme scientific notation (e.g., -3.4e+38)\n",
    "    array = np.where(np.abs(array) > EXTREME_THRESHOLD, np.nan, array)\n",
    "    return array\n",
    "\n",
    "def check_data_quality(df_chunk, model_feature_names):\n",
    "    issues = []\n",
    "    for feat in model_feature_names:\n",
    "        if feat in df_chunk.columns:\n",
    "            data = df_chunk[feat].values\n",
    "            nan_count = np.sum(np.isnan(data))\n",
    "            if nan_count > 0:\n",
    "                issues.append(f\"{feat}: {nan_count} NaN values\")\n",
    "            \n",
    "            finite_mask = np.isfinite(data)\n",
    "            if np.any(finite_mask):\n",
    "                finite_data = data[finite_mask]\n",
    "                issues.append(f\"{feat}: Range [{finite_data.min():.2f}, {finite_data.max():.2f}]\")\n",
    "    return issues\n",
    "\n",
    "def load_tif_to_chunk(feat_name, tif_folder, chunk_start, chunk_end, ref_shape, coords_x, coords_y):\n",
    "    tif_filename = None\n",
    "    if feat_name in MODEL_TO_TIF_MAP:\n",
    "        tif_base = MODEL_TO_TIF_MAP[feat_name]\n",
    "        tif_filename = f\"{tif_base}.tif\"\n",
    "    elif f\"{feat_name}.tif\" in os.listdir(tif_folder):\n",
    "        tif_filename = f\"{feat_name}.tif\"\n",
    "    \n",
    "    if not tif_filename: return None\n",
    "    tif_path = os.path.join(tif_folder, tif_filename)\n",
    "    if not os.path.exists(tif_path): return None\n",
    "\n",
    "    try:\n",
    "        with rxr.open_rasterio(tif_path, masked=True) as da:\n",
    "            da_squeezed = da.squeeze()\n",
    "            if feat_name in ['Lon', 'Lat'] or MODEL_TO_TIF_MAP.get(feat_name) in ['Lon', 'Lat']:\n",
    "                if 'Lon' in feat_name or MODEL_TO_TIF_MAP.get(feat_name) == 'Lon':\n",
    "                    chunk_values = np.tile(coords_x.values, (chunk_end - chunk_start, 1))\n",
    "                    model_feat_name = 'Lon'\n",
    "                else:\n",
    "                    lat_values = coords_y.isel(y=slice(chunk_start, chunk_end)).values.reshape(-1, 1)\n",
    "                    chunk_values = np.tile(lat_values, (1, ref_shape[1]))\n",
    "                    model_feat_name = 'Lat'\n",
    "            else:\n",
    "                chunk_values = da_squeezed.isel(y=slice(chunk_start, chunk_end)).values\n",
    "                model_feat_name = TIF_TO_MODEL_MAP.get(feat_name, feat_name)\n",
    "\n",
    "            if np.ma.is_masked(chunk_values):\n",
    "                chunk_values = chunk_values.filled(np.nan)\n",
    "            \n",
    "            # CRITICAL: Clean the data immediately after loading\n",
    "            flat_values = chunk_values.reshape(-1).astype(np.float32)\n",
    "            flat_values = clean_extreme_values(flat_values)\n",
    "            \n",
    "            return (model_feat_name, flat_values)\n",
    "    except Exception as e:\n",
    "        print(f\"    ❌ Error loading {tif_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_dynamic_features(chunk_data, model_feature_names):\n",
    "    if not chunk_data: return {}\n",
    "    first_key = next(iter(chunk_data))\n",
    "    array_shape = chunk_data[first_key].shape\n",
    "    \n",
    "    lu_data = chunk_data.get('LUtype', np.zeros(array_shape, dtype=np.float32))\n",
    "    lu_data_filled = np.where(np.isnan(lu_data), 0, lu_data)\n",
    "    \n",
    "    # Example interactions\n",
    "    enhancements = {\n",
    "        'LUtype_boost_1': lu_data_filled,\n",
    "        'LUtype_boost_2': lu_data_filled * 2,\n",
    "        'LUtype_squared': lu_data_filled ** 2\n",
    "    }\n",
    "    \n",
    "    for name, data in enhancements.items():\n",
    "        if name in model_feature_names:\n",
    "            chunk_data[name] = data\n",
    "\n",
    "    interaction_pairs = [('pH', 'LUtype_pH_interaction'), ('BD', 'LUtype_BD_interaction')]\n",
    "    for base, inter in interaction_pairs:\n",
    "        if inter in model_feature_names:\n",
    "            base_data = chunk_data.get(base, np.zeros(array_shape))\n",
    "            base_filled = np.where(np.isnan(base_data), 0, base_data)\n",
    "            chunk_data[inter] = lu_data_filled * base_filled\n",
    "\n",
    "    for feat in model_feature_names:\n",
    "        if feat not in chunk_data:\n",
    "            chunk_data[feat] = np.zeros(array_shape, dtype=np.float32)\n",
    "    return chunk_data\n",
    "\n",
    "def load_model_feature_names():\n",
    "    if os.path.exists(FEATURE_NAMES_PATH):\n",
    "        with open(FEATURE_NAMES_PATH, 'r') as f:\n",
    "            return [line.strip() for line in f.readlines() if line.strip()]\n",
    "    xgb_model = xgb.Booster(); xgb_model.load_model(MODEL_PATH)\n",
    "    return xgb_model.feature_names\n",
    "\n",
    "def conservative_process():\n",
    "    model_feature_names = load_model_feature_names()\n",
    "    \n",
    "    ref_tif_path = os.path.join(INPUT_TIF_FOLDER, \"Altitude.tif\")\n",
    "    ref_da = rxr.open_rasterio(ref_tif_path, masked=True).squeeze()\n",
    "    ref_shape = ref_da.shape\n",
    "    coords_x, coords_y = ref_da['x'], ref_da['y']\n",
    "    \n",
    "    xgb_model = xgb.Booster(); xgb_model.load_model(MODEL_PATH)\n",
    "    result_array = np.full(ref_shape, np.nan, dtype=np.float32)\n",
    "    \n",
    "    for chunk_start in range(0, ref_shape[0], CHUNK_SIZE):\n",
    "        chunk_end = min(chunk_start + CHUNK_SIZE, ref_shape[0])\n",
    "        total_pixels = (chunk_end - chunk_start) * ref_shape[1]\n",
    "        print(f\"\\n🚀 Processing Rows {chunk_start}-{chunk_end}\")\n",
    "\n",
    "        chunk_data = {}\n",
    "        for feat in set(KEY_FEATURES + model_feature_names):\n",
    "            loaded = load_tif_to_chunk(feat, INPUT_TIF_FOLDER, chunk_start, chunk_end, ref_shape, coords_x, coords_y)\n",
    "            if loaded: chunk_data[loaded[0]] = loaded[1]\n",
    "\n",
    "        chunk_data = create_dynamic_features(chunk_data, model_feature_names)\n",
    "        \n",
    "        # Build mask based on key features being valid (not NaN)\n",
    "        complete_mask = np.ones(total_pixels, dtype=bool)\n",
    "        for feat in KEY_FEATURES:\n",
    "            if feat in chunk_data:\n",
    "                complete_mask &= (~np.isnan(chunk_data[feat]))\n",
    "        \n",
    "        indices = np.where(complete_mask)[0]\n",
    "        if len(indices) == 0: continue\n",
    "\n",
    "        # Prepare DataFrame\n",
    "        df_chunk = pd.DataFrame({f: chunk_data[f] for f in model_feature_names})\n",
    "        valid_df = df_chunk.iloc[indices].fillna(0) # XGBoost prefers 0 or a specific value for missing\n",
    "        \n",
    "        # Predict\n",
    "        dtest = xgb.DMatrix(valid_df.values, feature_names=model_feature_names)\n",
    "        preds = xgb_model.predict(dtest)\n",
    "        \n",
    "        # Remap to 2D\n",
    "        global_indices = (np.arange(total_pixels) + (chunk_start * ref_shape[1]))[indices]\n",
    "        result_array[global_indices // ref_shape[1], global_indices % ref_shape[1]] = preds\n",
    "        \n",
    "        gc.collect()\n",
    "\n",
    "    # Save\n",
    "    out_da = xr.DataArray(result_array, coords={\"y\": coords_y, \"x\": coords_x}, dims=(\"y\", \"x\"))\n",
    "    out_da.rio.to_raster(OUTPUT_TIF_PATH, compress=\"LZW\", nodata=np.nan)\n",
    "    print(f\"✅ Success! Saved to {OUTPUT_TIF_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    conservative_process()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (my_venv)",
   "language": "python",
   "name": "my_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
